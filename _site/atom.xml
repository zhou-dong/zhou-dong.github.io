<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Dong</title>
 <link href="http://zhou-dong.github.io/" rel="self"/>
 <link href="http://zhou-dong.github.io"/>
 <updated>2016-02-24T21:57:05-06:00</updated>
 <id>http://zhou-dong.github.io</id>
 <author>
   <name>Dong Zhou</name>
   <email>82224165@qq.com</email>
 </author>

 
 <entry>
   <title>GO WEST</title>
   <link href="http://zhou-dong.github.io/2016/02/24/go-west"/>
   <updated>2016-02-24T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2016/02/24/go-west</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Add System Call In Linux (Elementary)</title>
   <link href="http://zhou-dong.github.io/linux/2016/02/02/linux-kernel"/>
   <updated>2016-02-02T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/linux/2016/02/02/linux-kernel</id>
   <content type="html">
&lt;ul&gt;
  &lt;li&gt;Machine: Apple Mac&lt;/li&gt;
  &lt;li&gt;OS: OS X EL Capitan&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;full-screen-of-elementary--os-in-vitual-box&quot;&gt;Full Screen of Elementary  OS in Vitual Box&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;run code:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;
cd /media/
sudo mkdir /cdrom/
sudo mount /dev/sr0 /media/cdrom
cd /media/cdrom
sudo ./VBoxLinuxAdditions.run
sudo reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;add-system-call&quot;&gt;Add System Call&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;download linux kernel in &lt;a href=&quot;https://www.kernel.org/&quot;&gt;kernel.org&lt;/a&gt;  (my version is: 3.2.76)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;
cd /Downloads
sudo mv linux-3.2.76.tar.xz /usr/src/.
cd /usr/src/
sudo xz -d linux-3.2.76.tar.xz
sudo tar -xvf linux-3.2.76.tar
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Add system call function&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;
sudo vim /usr/src/linux-3.2.76/kernel/sys.c
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;c&quot;&gt;
asmlinkage int sys_add2(int i, int j)
{
    return i + j;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Regist on system&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;
sudo vim usr/src/linux-3.2.76/arch/x86/kernel/syscall_table_32.S
    .long sys_add2
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Add system call parameter&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;c&quot;&gt;
sudo vim /usr/src/linux-3.2.76/arch/x86/include/asm/unistd_64.h

#define __NR_add2           xxx (update numer +=1)
__SYSCALL(__NR_add2, sys_add2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;c&quot;&gt;
sudo vim /usr/src/linux-3.2.76/arch/x86/include/asm/unistd_32.h

#define __NR_add2           xxx (update numer +=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;complie&quot;&gt;complie&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;
cd  /usr/src/linux-3.2.76
sudo apt-get install libncurses5-dev
sudo make localmodconfig
sudo make -j N(optimize compile speed, core number + 1)
sudo make modules_install
sudo make install
sudo reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;test&quot;&gt;Test&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;c&quot;&gt;
#include&lt;stdio.h&gt;
#include&lt;errno.h&gt;

#define __NR_add2  312   //(xxx updated number)

int main()
{
    int a,b;
    printf(“Input Two Number To Kernel Space\n”);
    printf(“Input a  ”);
    scanf(“%d”,&amp;amp;a);
    printf(“Input b  ”);
    scanf(“%d”,&amp;amp;b);
    printf(&quot;%d\n&quot;, syscall(__NR_add2, a,b)) ;
    return 0;
}

&lt;/errno.h&gt;&lt;/stdio.h&gt;&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Digital Image Fundamentals</title>
   <link href="http://zhou-dong.github.io/2016/01/25/intro"/>
   <updated>2016-01-25T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2016/01/25/intro</id>
   <content type="html">&lt;p&gt;Computer vision is a field that includes methods for acquiring, processing, analyzing, and understanding images and, in general, high-dimensional data from the real world in order to produce numerical or symbolic information, e.g., in the forms of decisions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling: digitizing the coordinate values &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Quantization: digitizing the amplitude values&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Image resolution: the largest number of discernible line pairs per unit distance &lt;/li&gt;
  &lt;li&gt;Intensity resolution: the smallest discernible change in intensity level, usually refer to the number of bits used to quantize intensity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Histograms&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A histogram is a graph. A graph that shows frequency of anything. Usually histogram have bars that represent frequency of occurring of data in the whole data set.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Histogram of an image, like other histograms also shows frequency. But an image histogram, shows frequency of pixels intensity values. In an image histogram, the x axis shows the gray level intensities and the y axis shows the frequency of these intensities.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Prepare Computer Vision</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/12/15/prepare_computer_vision"/>
   <updated>2015-12-15T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/12/15/prepare_computer_vision</id>
   <content type="html">
&lt;p&gt;Linear Algebra Resources&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;http://joshua.smcvt.edu/linearalgebra/book.pdf&lt;/li&gt;
  &lt;li&gt;http://www.cns.nyu.edu/~eero/NOTES/geomLinAlg.pdf&lt;/li&gt;
  &lt;li&gt;http://alumni.media.mit.edu/~maov/classes/vision09/lect/02_LinearAlgebraReview.pdf&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Computer Vision Videos:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;https://www.youtube.com/watch?v=715uLCHt4jE&lt;/li&gt;
  &lt;li&gt;http://videolectures.net/ssll09_hartley_covi/&lt;/li&gt;
  &lt;li&gt;http://videolectures.net/mlss08au_lucey_linv/&lt;/li&gt;
  &lt;li&gt;http://videolectures.net/mlss04_blake_cv/&lt;/li&gt;
  &lt;li&gt;http://videolectures.net/aop09_farinella_pricv/&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other Computer Vision course pages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;http://www.cs.ucf.edu/~bagci/teaching/computervision15.html&lt;/li&gt;
  &lt;li&gt;http://www.cs.cornell.edu/courses/cs4670/2013fa/lectures/lectures.html&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;http://alumni.media.mit.edu/~maov/classes/vision09/syllabus.html&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;resolution: 分辨率&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;sampleing: choose or delete pixels&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;quantization: quantize the pixels&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;noise: different from its neighbors&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;image-and-video-compress&quot;&gt;Image and video compress&lt;/h3&gt;

&lt;p&gt;For those interested, the slides presented in the videos for this module can be downloaded here: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://d396qusza40orc.cloudfront.net/phoenixassets/ml-foundations/deeplearning-annotated.pdf&quot;&gt;deeplearning-annotated.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some useful papers on computer vision:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SIFT &lt;a href=&quot;http://www.cs.ubc.ca/~lowe/papers/iccv99.pdf&quot;&gt;Lowe ‘99&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Spin Images &lt;a href=&quot;https://www.ri.cmu.edu/pub_files/pub2/johnson_andrew_1997_3/johnson_andrew_1997_3.pdf&quot;&gt;Johnson &amp;amp; Herbert ‘99&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Textons &lt;a href=&quot;http://www.cs.berkeley.edu/~malik/papers/LM-3dtexton.pdf&quot;&gt;Malik et al. ‘99&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;RIFT &lt;a href=&quot;https://hal.inria.fr/inria-00548530/document&quot;&gt;Lazebnik ‘04&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GLOH &lt;a href=&quot;http://lear.inrialpes.fr/pubs/2005/MS05/mikolajczyk_pami05.pdf&quot;&gt;Mikolajczyk &amp;amp; Schmid ‘05&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;HoG &lt;a href=&quot;http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf&quot;&gt;Dalal &amp;amp; Triggs ‘05&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;SURF &lt;a href=&quot;http://www.vision.ee.ethz.ch/~surf/eccv06.pdf&quot;&gt;Bay et al. ‘06&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ImageNet &lt;a href=&quot;http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf&quot;&gt;Krizhevsky ‘12&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;neutral-network&quot;&gt;Neutral Network&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;http://www.intechopen.com/source/html/11772/media/image29.jpg&quot; alt=&quot;neural network&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;神经网络的每个部分其实就是Logistic Regression，很多个Logistic Regression组合在一个就是神经网络的一个layer&lt;/li&gt;
  &lt;li&gt;多个layer组合在一个构成一个神经网络&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;computer vision&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;找出图片中的pattern或者是特征&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Data Image Compression</title>
   <link href="http://zhou-dong.github.io/2015/12/04/code"/>
   <updated>2015-12-04T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/12/04/code</id>
   <content type="html">&lt;p&gt;Huffman coding&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Are all pixels equal?&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Data Stream Analyze</title>
   <link href="http://zhou-dong.github.io/2015/12/04/code"/>
   <updated>2015-12-04T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/12/04/code</id>
   <content type="html">&lt;pre&gt;
&lt;code&gt;

Socket.prototype.onpacket = function(packet){
  debug(&#39;got packet %j&#39;, packet);
  switch (packet.type) {
    case parser.EVENT:
      this.onevent(packet);
      break;

    case parser.BINARY_EVENT:
      this.onevent(packet);
      break;

    case parser.ACK:
      this.onack(packet);
      break;

    case parser.BINARY_ACK:
      this.onack(packet);
      break;

    case parser.DISCONNECT:
      this.ondisconnect();
      break;

    case parser.ERROR:
      this.emit(&#39;error&#39;, packet.data);
  }
};

Socket.prototype.onevent = function(packet){
  var args = packet.data || [];
  debug(&#39;emitting event %j&#39;, args);

  if (null != packet.id) {
    debug(&#39;attaching ack callback to event&#39;);
    args.push(this.ack(packet.id));
  }

  emit.apply(this, args);
};


function Client(server, conn){
  this.server = server;
  this.conn = conn;
  this.encoder = new parser.Encoder();
  this.decoder = new parser.Decoder();
  this.id = conn.id;
  this.request = conn.request;
  this.setup();
  this.sockets = {};
  this.nsps = {};
  this.connectBuffer = [];
}

&lt;/code&gt;
&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Technology From Computer Architecture to Cloud Computing</title>
   <link href="http://zhou-dong.github.io/2015/11/27/computer-architecture-and-cloud-computing"/>
   <updated>2015-11-27T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/11/27/computer-architecture-and-cloud-computing</id>
   <content type="html">
&lt;h4 id=&quot;abstract&quot;&gt;ABSTRACT&lt;/h4&gt;

&lt;p&gt;There are lots of same technology ideas between single computer architecture and cloud Computing system(Distributed system). We will discuss these ideas in these area:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Abstractions of the computer system and the abstractions of the distribution system.&lt;/li&gt;
  &lt;li&gt;How Queue implemented both the threads control in the single computer and balance control in the cloud computing.&lt;/li&gt;
  &lt;li&gt;The ideas of the File system between the Linux system and distribution system(HDFS, GFS).&lt;/li&gt;
  &lt;li&gt;Data communication between GPU, memory and project, database.&lt;/li&gt;
  &lt;li&gt;notify idea in thread control and zookeeper in Hadoop system.&lt;/li&gt;
  &lt;li&gt;pipeline in CPU and big data, example: photo OCR&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;No matter build a single computer or cloud system, basically people use the same idea.  &lt;/p&gt;

&lt;h4 id=&quot;same-knowledge&quot;&gt;Same knowledge&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Abstraction
    &lt;ul&gt;
      &lt;li&gt;How people use abstraction to define different lays of the system.&lt;/li&gt;
      &lt;li&gt;Abstraction is always the most important idea in building the system, not only computer architecture, but all the things, by the way I believe the humans’ history is the abstractions history, we abstract the nature and the world. We abstract more level of the nature, humans become more intelligent.&lt;/li&gt;
      &lt;li&gt;In the computer system, we abstract the computer into:
        &lt;ol&gt;
          &lt;li&gt;hardware&lt;/li&gt;
          &lt;li&gt;operating system&lt;/li&gt;
          &lt;li&gt;software&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;other way the abstract computer
        &lt;ol&gt;
          &lt;li&gt;instruction set&lt;/li&gt;
          &lt;li&gt;operating system api&lt;/li&gt;
          &lt;li&gt;virtual machine api&lt;/li&gt;
          &lt;li&gt;modern language&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Clouding computing system
        &lt;ol&gt;
          &lt;li&gt;File system(HDFS,GFS)&lt;/li&gt;
          &lt;li&gt;Database: HBase, Bigtable&lt;/li&gt;
          &lt;li&gt;Database API&lt;/li&gt;
          &lt;li&gt;Service API&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Add cache to every level to optimize system.
    &lt;ul&gt;
      &lt;li&gt;We been study that there are several levels cache in the computer system, like L1, L2, L3, Main Memory.&lt;/li&gt;
      &lt;li&gt;In the cloud computing also need several level cache to optimize the system.&lt;/li&gt;
      &lt;li&gt;Cache in project(Ehcache), Embedded Cache(LevelDB), distributed Cache(Redis), and so on…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Queue implemented in the threads control and balance control in the cloud.
    &lt;ul&gt;
      &lt;li&gt;thread control is one of the most important part in CPU development, it has been evolved several methods.&lt;/li&gt;
      &lt;li&gt;Now we use the priority queue to control the “context switch”.&lt;/li&gt;
      &lt;li&gt;how queue be implemented in the thread control of the CPU&lt;/li&gt;
      &lt;li&gt;In Clouding computing, queue also very very important, queue is implemented in every where.&lt;/li&gt;
      &lt;li&gt;balance the request: Facebook’s beanstalk&lt;/li&gt;
      &lt;li&gt;balance the log system: Fafka in Linkedin&lt;/li&gt;
      &lt;li&gt;zookeeper in Hadoop&lt;/li&gt;
      &lt;li&gt;control the command: MapReduce command control&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;File system of the Linux system and distribution system(HDFS, GFS).
    &lt;ul&gt;
      &lt;li&gt;Hadoop system use the same idea of the Linux system.&lt;/li&gt;
      &lt;li&gt;Even use all most the same command to operate.&lt;/li&gt;
      &lt;li&gt;Hadoop fs -ls /home/&lt;/li&gt;
      &lt;li&gt;ls /home/&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data communication between GPU, memory and project, database.
    &lt;ul&gt;
      &lt;li&gt;We been discuss so much during the class.&lt;/li&gt;
      &lt;li&gt;But in the database system, people use the same ideas to Create, Read, Update, Delete the data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;pipeline in CPU and big data, example: photo OCR
    &lt;ul&gt;
      &lt;li&gt;We beed discuss how important the pipeline in operating system.&lt;/li&gt;
      &lt;li&gt;pipeline also very important in distributed system.&lt;/li&gt;
      &lt;li&gt;shopping cart steps&lt;/li&gt;
      &lt;li&gt;order steps&lt;/li&gt;
      &lt;li&gt;photo OCR&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;future&quot;&gt;Future&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;GPU plus Map Reduce&lt;/li&gt;
  &lt;li&gt;Low level of mongoDB let operating system control the thread for it.&lt;/li&gt;
  &lt;li&gt;HDFS is based on Linux file system.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The use the same ideas to build different level of the system, and then combine them to a large system, to make the system more powerful.&lt;/p&gt;

&lt;p&gt;Future is join all these ideas together to optimize the whole system, like GPU plus Map Reduce, HDFS with Linux file system(ext3). Because of abstraction, people in different levels to optimize the system, they are not disturbed each other, but they can use ideas from the other levels to optimize their work. So no matter which level have good ideas or solutions will be implemented in other level. &lt;/p&gt;

&lt;h4 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;In our area, every part they always have same idea, if we can master one of the idea, I believe we can make our selves better.&lt;/p&gt;

&lt;p&gt;From operation system, hardware of computer to the cloud, there are some many commons ideas between. And these ideas are the basic knowledge of computer science.&lt;/p&gt;

&lt;p&gt;The ideas between computer architecture and cloud Computing or distributed system. More I think all the ideas between technology are same. If we like or interest something, just word hard for it.&lt;/p&gt;

&lt;p&gt;Computer science is an great major, it’s not only need thinking things logically but also need us do it manually which is by our hand.&lt;/p&gt;

&lt;p&gt;The creative is not only invent the totally new things, but standing on the shoulders of giants and step forward. Wish after we leaned the basic ideas, we could create our own cool things, to make the world a little different.&lt;/p&gt;

&lt;p&gt;Add more informatino of Computer Architecture.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Prepared For Jobs</title>
   <link href="http://zhou-dong.github.io/2015/11/19/find-jobs"/>
   <updated>2015-11-19T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/11/19/find-jobs</id>
   <content type="html">&lt;p&gt;Basic Algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;string&lt;/li&gt;
  &lt;li&gt;array&lt;/li&gt;
  &lt;li&gt;linked list&lt;/li&gt;
  &lt;li&gt;stack&lt;/li&gt;
  &lt;li&gt;queue&lt;/li&gt;
  &lt;li&gt;Sort&lt;/li&gt;
  &lt;li&gt;Tree&lt;/li&gt;
  &lt;li&gt;graph&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cracking the code interview&lt;/p&gt;

&lt;p&gt;LeetCode&lt;/p&gt;

&lt;p&gt;Java&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basic&lt;/li&gt;
  &lt;li&gt;Java 8 Feature&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Effective Java&lt;/p&gt;

&lt;p&gt;Clean Code&lt;/p&gt;

&lt;p&gt;Refactoring&lt;/p&gt;

&lt;p&gt;Design pattern&lt;/p&gt;

&lt;p&gt;Architecture&lt;/p&gt;

&lt;p&gt;Machine Learning&lt;/p&gt;

&lt;p&gt;Search Engineering technology&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Linear Regression&lt;/li&gt;
  &lt;li&gt;Logistic Regression&lt;/li&gt;
  &lt;li&gt;Normal Equation&lt;/li&gt;
  &lt;li&gt;Overfitting vs. Under fitting&lt;/li&gt;
  &lt;li&gt;Support Vector Machine (SVM)&lt;/li&gt;
  &lt;li&gt;Neural Network&lt;/li&gt;
  &lt;li&gt;K-Means&lt;/li&gt;
  &lt;li&gt;Principal Component Analysis (PCA)&lt;/li&gt;
  &lt;li&gt;Evaluating Learning Algorithm&lt;/li&gt;
  &lt;li&gt;Anomaly Detection&lt;/li&gt;
  &lt;li&gt;Collaborative Filtering&lt;/li&gt;
  &lt;li&gt;Photo OCR&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Evaluating Learning Algorithm</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/17/evaluate-learning-algorithm"/>
   <updated>2015-11-17T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/17/evaluate-learning-algorithm</id>
   <content type="html">&lt;p&gt;Cross Validation&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;randomly shuffle or reorder the data&lt;/li&gt;
  &lt;li&gt;partial data into training set and test set&lt;/li&gt;
  &lt;li&gt;learn parameter from training data&lt;/li&gt;
  &lt;li&gt;computer test set error&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Model Selection (choose polynomial degree)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;use different polynomial degree to train data&lt;/li&gt;
  &lt;li&gt;use test set to find which degree is most fit the data&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Split data into three pieces (Train/Validation/Test Sets)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Training Set (60%)&lt;/li&gt;
  &lt;li&gt;Cross Validation Set (20%)&lt;/li&gt;
  &lt;li&gt;Test Set (20%)&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;Bias vs. Variance&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bias (underfit)
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;J_{cv} (\theta) \approx J_{train} (\theta)&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Variance (overfit)
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;J_{cv} (\theta) &gt;&gt; J_{train} (\theta)&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Regularization and Bias/Variance&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;choose different &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; in cost function&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;Cross-validation for detecting and preventing overfitting&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://qph.is.quoracdn.net/main-qimg-33774ab551d31370fbe2a4fa57286781?convert_to_webp=true&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Training size and Cross-validation Size&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://1.bp.blogspot.com/-ii5sPXFN0K4/T9Wrs34LiHI/AAAAAAAAAwI/K6Eu-97LY1A/s1600/p2.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If Learning Algorithm is suffer from overfitting(high Variance), getting more data is likely to help.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://4.bp.blogspot.com/-uWXoQpZpdOs/T9WvcIcjpCI/AAAAAAAAAwc/Hr3pn8RPQz4/s1600/p3.png&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Building a Spam Classifier</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/17/building-spam-classifier"/>
   <updated>2015-11-17T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/17/building-spam-classifier</id>
   <content type="html">&lt;p&gt;How to spend your time to make it have low error?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Collect lots of data&lt;/li&gt;
  &lt;li&gt;Develop sophisticated features based on email routing information (for email header)&lt;/li&gt;
  &lt;li&gt;Develop sophisticated features for message body. e.g. (should “discount” or “discounts” be treated as same word)?&lt;/li&gt;
  &lt;li&gt;Develop sophisticated algorithm to detect misspelling.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Error Analysis&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Start with a simple algorithm that you can improve quickly. Implement it and test it on cross-validation data.&lt;/li&gt;
  &lt;li&gt;Plot learning curves to decide if more data, more features, etc. are likely to help.&lt;/li&gt;
  &lt;li&gt;Error Analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Error Analysis:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;manually examine the errors.&lt;/li&gt;
  &lt;li&gt;what cues you think would have helped the algorithm classifier them correctly.&lt;/li&gt;
  &lt;li&gt;can use “Porter stemmer”?&lt;/li&gt;
  &lt;li&gt;Distinguish upper vs. lower case?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Error Metrics for Skewed Classes&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;precision/recall&lt;/li&gt;
  &lt;li&gt;precision 查准率&lt;/li&gt;
  &lt;li&gt;recall 查全率&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Trading Off Precision and Recall&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在precision和recall之间找到平衡点。&lt;/li&gt;
  &lt;li&gt;F score: &lt;script type=&quot;math/tex&quot;&gt;2\frac{PR}{P+R}&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Data For Machine Learning&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Not only need more data, but also need more features&lt;/li&gt;
  &lt;li&gt;If with limited features, even the data set is large, could be under fitting.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Large Scale Machine Learning</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/15/large-scale-machine-learning"/>
   <updated>2015-11-15T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/15/large-scale-machine-learning</id>
   <content type="html">&lt;p&gt;Batch Gradient Descent&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;classic way to do gradient descent&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Stochastic Gradient Descent&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Randomly shuffle dataset&lt;/li&gt;
  &lt;li&gt;Repeat for {i := 1,…,m} update the &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Mini-Batch Gradient Descent&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Randomly shuffle dataset&lt;/li&gt;
  &lt;li&gt;Repeat for {i := 1,11,21,..,m}, every time use b items to update the &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Stochastic Gradient Descent Convergence&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\alpha = \frac{const1}{iterationNumber + const2}
&lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;online-learning&quot;&gt;Online Learning&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;method：
    &lt;ul&gt;
      &lt;li&gt;可以借鉴Stochastic Gradient Descent（随机梯度下降）的思想。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;scenario:
    &lt;ul&gt;
      &lt;li&gt;Large data streaming coming into the application&lt;/li&gt;
      &lt;li&gt;Calculate one time then throw away&lt;/li&gt;
      &lt;li&gt;weight of different features were changed with times&lt;/li&gt;
      &lt;li&gt;大量的数据源源不断的流入系统中&lt;/li&gt;
      &lt;li&gt;One time process&lt;/li&gt;
      &lt;li&gt;随着时间的变化，不同的feature的权重会发生变化。（比如以前买汽车的话，马力比比重高，现在是否节能的比重更高）。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;online-learning-ctr-click-through-rate&quot;&gt;在搜索中使用online learning (CTR: CLICK THROUGH RATE)&lt;/h5&gt;

&lt;ol&gt;
  &lt;li&gt;features choose
    &lt;ul&gt;
      &lt;li&gt;关键字与query的匹配程度&lt;/li&gt;
      &lt;li&gt;用户的搜索历史&lt;/li&gt;
      &lt;li&gt;facets&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Implement Online Learning
    &lt;ul&gt;
      &lt;li&gt;根据用户的query返回用户搜素的结果&lt;/li&gt;
      &lt;li&gt;统计用户对搜索结果的点击结果&lt;/li&gt;
      &lt;li&gt;根据用户的点击为（0/1），来训练不同feature的weight。&lt;/li&gt;
      &lt;li&gt;可以使用Mini-Batch Gradient Descent&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;map-reduce-and-data-parallelism&quot;&gt;Map Reduce and Data Parallelism&lt;/h4&gt;

&lt;p&gt;可以使用Map-Reduce来实现Mini-Batch Gradient Descent&lt;/p&gt;

&lt;p&gt;可利用多核的优势在一台电脑上运行Map-Reduce，效果也会不错，因为现在的电脑都是多核的.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Anomaly Detection</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/13/anomaly-detection"/>
   <updated>2015-11-13T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/13/anomaly-detection</id>
   <content type="html">&lt;script type=&quot;math/tex; mode=display&quot;&gt;
x_1 \approx N(\mu_1, \sigma_1^2)
\\
x_2 \approx N(\mu_2, \sigma_2^2)
\\
x_3 \approx N(\mu_3, \sigma_3^2)
\\
\vdots
\\
x_n \approx N(\mu_n, \sigma_n^2)
\\
p(x) = p(x_1| \mu_1, \sigma_1^2)p(x_2| \mu_2, \sigma_2^2)p(x_3| \mu_3, \sigma_3^2) \cdots p(x_n| \mu_n, \sigma_n^2)
\\
=\prod_{j=1}^n p(x_j| \mu_j, \sigma_j^2)
&lt;/script&gt;

&lt;h4 id=&quot;anomaly-detection-algorithm&quot;&gt;Anomaly Detection Algorithm&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Choose features &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; that you think might be indicative of anomalous example.&lt;/li&gt;
  &lt;li&gt;Fit parameters &lt;script type=&quot;math/tex&quot;&gt;\mu_1,...,\mu_n, \ \sigma_1^2,...,\sigma_n^2&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_j = \frac{1}{m} \sum_{i=1}^m x_j^{(i)}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma_j^2 = \frac{1}{m} \sum_{i=1}^m (x_j^{(i)} - \mu)^2 &lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Given new example x,  compute p(x):
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x)=\prod_{j=1}^n p(x_j| \mu_j, \sigma_j^2)&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Anomaly if &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
 p(x) &lt; \varepsilon  %]]&gt;&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;multivariate-gaussian-distribution&quot;&gt;Multivariate Gaussian Distribution&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Don’t model &lt;script type=&quot;math/tex&quot;&gt;p(x_1) \ , p(x_2), \  p(x_n)&lt;/script&gt; one by one.&lt;/li&gt;
  &lt;li&gt;Model &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt; all in one go.&lt;/li&gt;
  &lt;li&gt;parameters:
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\mu \in R^n&lt;/script&gt; vector&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\Sigma \in R^{n \times n}&lt;/script&gt; Covariance Matrix&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在统计学与概率论中，协方差矩阵（也称离差矩阵、方差-协方差矩阵）是一个矩阵，其 i, j 位置的元素是第 i 个与第 j 个随机向量（即随机变量构成的向量）之间的协方差。这是从标量随机变量到高维度随机向量的自然推广。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;original model is the special case of multivariate Gaussian Model&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;gaussian-distribution&quot;&gt;Gaussian Distribution&lt;/h4&gt;

&lt;p&gt;Say &lt;script type=&quot;math/tex&quot;&gt;x \in R&lt;/script&gt; if x is a distributed Gaussian with mean &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt;, variance &lt;script type=&quot;math/tex&quot;&gt;\sigma^2&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;其中&lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt;是控制曲线的中心点，&lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; standard deviation&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;是控制曲线的宽度&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;

P(x| \mu, \sigma^2) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\\
\mu = \frac{1}{m} \sum_{i=1}^m x^{(i)}
\\
\sigma^2 = \frac{1}{m} \sum_{i=1}^m (x^{(i)}-\mu)^2
&lt;/script&gt;

&lt;h4 id=&quot;transform-other-data-distribution-to-gaussian-distribution&quot;&gt;Transform other data distribution to Gaussian Distribution&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
x_2 \leftarrow log(x_2 + c)\\
x_3 \leftarrow \sqrt{x_2}
&lt;/script&gt;
</content>
 </entry>
 
 <entry>
   <title>Principal Component Analysis (PCA)</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/11/pca"/>
   <updated>2015-11-11T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/11/pca</id>
   <content type="html">&lt;h4 id=&quot;should-apply-pca-only-on-training-set&quot;&gt;Should apply PCA only on training set.&lt;/h4&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;motivation&quot;&gt;Motivation:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Data Compression&lt;/li&gt;
  &lt;li&gt;Data Visualization&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;在图片识别中，可以使用PCA来对图片做降维&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;pca-problem-formulation&quot;&gt;PCA Problem Formulation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Minimize the projection error.&lt;/li&gt;
  &lt;li&gt;PCA is not linear regression.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;pca-algorithm&quot;&gt;PCA Algorithm&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Mean normalization&lt;/li&gt;
  &lt;li&gt;covariance matrix&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\Sigma = \frac{1}{m}\sum_{i=1}^n(x^{(i)})(x^{(i)})^T
&lt;/script&gt;

&lt;p&gt;Compute “eigenvector” of matrix &lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;[U,S,V] = svd(Sigma)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;SVD&lt;/code&gt;: singular value decomposition&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
U \in R^{n \times n}
&lt;/script&gt;

&lt;p&gt;Reconstruction from compressed representation&lt;/p&gt;

&lt;p&gt;Choosing K:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;99% of variance is retained&lt;/li&gt;
  &lt;li&gt;from k=1 to k=m&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;降维：把多个类似的维度合并成一个。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Recommender Systems</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/09/recommender-systems"/>
   <updated>2015-11-09T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/09/recommender-systems</id>
   <content type="html">&lt;h4 id=&quot;content-based-recommender-systems-&quot;&gt;Content-based Recommender Systems （基于内容的商品推荐）&lt;/h4&gt;

&lt;h5 id=&quot;section&quot;&gt;相当于对每个人的记录做线性回归&lt;/h5&gt;

&lt;h5 id=&quot;problem-formulation&quot;&gt;Problem Formulation&lt;/h5&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
(1) \\
n_u \ \text{no.users} \\
n_m \ \text{no.movies} \\
r_{(i,j)} = 1 \ \text{if user j has rated movie i} \\
y^{(i,j)} = \ \text{rating given by user j to movie i} \\
(2)\\
\text{features} = (x_1, x_2, ... , x_n) \\
x_1 = romance \\
x_2 = action \\
\vdots \\
x_n = xxx \\
(3)\\
\text{weight} = (\theta_1, \theta_2, ... , \theta_n) \\
\text{value} = y = \text{5/4/3/2/1} \\
\theta^Tx = y \\
(4)\\
\text{to learn} \ \theta^{(j)} \\
(5)\\
\min_{\theta^{(j)}} = \frac{1}{2m^{(j)}} \sum_{i:r(i,j)=1} ( (\theta^{(j)})^Tx^{(i)} - y^{(i,j)} )^2\\
(6) \\
\min_{\theta^{(j)}} = \frac{1}{2m^{(j)}} \sum_{i:r(i,j)=1} ( (\theta^{(j)})^Tx^{(i)} - y^{(i,j)} )^2 +
\frac{\lambda}{2m^j} \sum_{k=1}^n (\theta_k^{(i)})^2 \\
(7) \\
\min_{\theta^{(j)}} = \frac{1}{2} \sum_{i:r(i,j)=1} ( (\theta^{(j)})^Tx^{(i)} - y^{(i,j)} )^2 +
\frac{\lambda}{2} \sum_{k=1}^n (\theta_k^{(i)})^2 \\
&lt;/script&gt;

&lt;h5 id=&quot;optimization-algorithm&quot;&gt;Optimization Algorithm&lt;/h5&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\min_{\theta^{(1)},...,\theta^{(n_u)}} = \frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} ( (\theta^{(j)})^Tx^{(i)} - y^{(i,j)} )^2 +
\frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n (\theta_k^{(i)})^2 \\
&lt;/script&gt;

&lt;h5 id=&quot;then-use-gradient-or-normal-equation&quot;&gt;Then Use Gradient or Normal Equation&lt;/h5&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;collaborative-filtering&quot;&gt;Collaborative Filtering&lt;/h4&gt;

&lt;p&gt;Given &lt;script type=&quot;math/tex&quot;&gt; \theta^{(1)}, ... , \theta^{(n_u)} &lt;/script&gt; to learn &lt;script type=&quot;math/tex&quot;&gt; x^{(i)} &lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\min_{x^{(i)}} = \frac{1}{2} \sum_{j:r(i,j)=1} ( (x^{(j)})^Tx^{(i)} - y^{(i,j)} )^2 +
\frac{\lambda}{2} \sum_{k=1}^n (x^{(i)})^2 \\

\min_{x^{(1)},...,x^{(n_m)}} = \frac{1}{2} \sum_{j=1}^{n_m} \sum_{j:r(i,j)=1} ( (\theta^{(j)})^Tx^{(i)} - y^{(i,j)} )^2 +
\frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2 \\
&lt;/script&gt;

&lt;p&gt;Given &lt;script type=&quot;math/tex&quot;&gt; x^{(1)}, ... , x^{(n_u)} &lt;/script&gt; to learn &lt;script type=&quot;math/tex&quot;&gt; \theta^{(i)} &lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\min_{\theta^{(1)},...,\theta^{(n_u)}} = \frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} ( (\theta^{(j)})^Tx^{(i)} - y^{(i,j)} )^2 +
\frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n (\theta_k^{(i)})^2 \\
&lt;/script&gt;

&lt;p&gt;利用上面两个公式，同时计算出&lt;script type=&quot;math/tex&quot;&gt;x, \theta&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J(x^1,...,x^{n_m}, \theta^1,...,\theta^{n_u}) = \frac{1}{2} \sum_{(i,j):r(i,j)=1} ( (\theta^{(j)})^Tx^{(i)} - y^{(i,j)} )^2  + \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n (\theta_k^{(i)})^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2  \\
\min_{(x^1,...,x^{n_m}, \theta^1,...,\theta^{n_u})} = J(x^1,...,x^{n_m}, \theta^1,...,\theta^{n_u})
&lt;/script&gt;

&lt;h4 id=&quot;low-rank-matrix-factorization-vectorization-of-collaborative-filtering&quot;&gt;Low Rank Matrix Factorization (Vectorization of Collaborative Filtering)&lt;/h4&gt;

&lt;p&gt;协同过滤的向量化&lt;/p&gt;

&lt;p&gt;Finding related movies: find movies with the smallest: &lt;script type=&quot;math/tex&quot;&gt;\| x^{(i)} - x^{(j)} \|&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;implement-detail-mean-normalization&quot;&gt;Implement Detail: Mean Normalization&lt;/h4&gt;
</content>
 </entry>
 
 <entry>
   <title>Lose Weight</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/07/first-week"/>
   <updated>2015-11-07T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/07/first-week</id>
   <content type="html">&lt;h4 id=&quot;section&quot;&gt;11/07 2015&lt;/h4&gt;

&lt;p&gt;平板支撑：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;1.21.94&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;俯卧撑: 5 * 15&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;11/08 2015&lt;/h4&gt;

&lt;p&gt;早餐&lt;/p&gt;

&lt;p&gt;中餐&lt;/p&gt;

&lt;p&gt;晚餐&lt;/p&gt;

&lt;p&gt;锻炼&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Viterbi Algorithm</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/06/viterbi"/>
   <updated>2015-11-06T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/06/viterbi</id>
   <content type="html">&lt;p&gt;Description&lt;/p&gt;

&lt;p&gt;Equation&lt;/p&gt;

&lt;p&gt;View&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Photo OCR</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/05/photo-ocr"/>
   <updated>2015-11-05T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/05/photo-ocr</id>
   <content type="html">&lt;h4 id=&quot;photo-ocr-pipeline&quot;&gt;Photo OCR pipeline&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Text dection
    &lt;ul&gt;
      &lt;li&gt;Find where is location of the text in the picture.&lt;/li&gt;
      &lt;li&gt;比例从小到大逐帧扫描整个图片。&lt;/li&gt;
      &lt;li&gt;用每个比例逐帧扫描一次。&lt;/li&gt;
      &lt;li&gt;每次用神经网络或者其他的算法判断当次扫描中是否有出现目标图像。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Character segmentation
    &lt;ul&gt;
      &lt;li&gt;Read the text in the regions. &lt;/li&gt;
      &lt;li&gt;在某个区域内的字母，合并为一个group&lt;/li&gt;
      &lt;li&gt;把Word分成一个一个小的character。&lt;/li&gt;
      &lt;li&gt;通过查看每个image patch里面是一个character还是多个&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Character classification(recognition)
    &lt;ul&gt;
      &lt;li&gt;Read single character in a word.&lt;/li&gt;
      &lt;li&gt;通过机器学习的方法辨识每一个字母 &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;scenario&quot;&gt;Scenario&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Help blend person to read the content is the real life.&lt;/li&gt;
  &lt;li&gt;Car navigation system.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;artifical-data-synthesis&quot;&gt;Artifical data synthesis&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Use small set of data to generate large data.
    &lt;ul&gt;
      &lt;li&gt;数据 + noise 合成新的数据&lt;/li&gt;
      &lt;li&gt;distort原始数据，成新的数据&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Collect/label it yourself
    &lt;ul&gt;
      &lt;li&gt;如果label的代价不是很大的话，其实自己label有时候效率是不差的。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;“Crowd source”
    &lt;ul&gt;
      &lt;li&gt;一些数据label的平台（网站），可以在上面label data。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;ceilling-analysis&quot;&gt;Ceilling Analysis&lt;/h4&gt;

&lt;p&gt;Find what part of pipline should pay more effort&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>K-Means</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/11/05/k-means"/>
   <updated>2015-11-05T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/11/05/k-means</id>
   <content type="html">&lt;p&gt;Input:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;K (number of clusters)&lt;/li&gt;
  &lt;li&gt;Training set {&lt;script type=&quot;math/tex&quot;&gt;x^{(1)},x^{(2)},...,x^{(m)} &lt;/script&gt;}&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;x^{(i)} \in R^n&lt;/script&gt; (drop &lt;script type=&quot;math/tex&quot;&gt;x_0 = 1&lt;/script&gt; convention)&lt;/p&gt;

&lt;p&gt;Step:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Randomly initialize K cluster centroid &lt;script type=&quot;math/tex&quot;&gt;\mu_1, \mu_2, ..., \mu_k \in R^n &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Repeat
    &lt;ul&gt;
      &lt;li&gt;for i=1 to m &lt;script type=&quot;math/tex&quot;&gt;c^{(i)} := &lt;/script&gt; index (from 1 to K) of cluster centroid closest to &lt;script type=&quot;math/tex&quot;&gt;x_{(i)}, \text{which means find: } \min_k \|x^{(i)}-\mu_k\|&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;for k=1 to K &lt;script type=&quot;math/tex&quot;&gt;\mu_k := &lt;/script&gt; average (mean) of points assigned to cluster k&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Optimization objective:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_k) = \frac{1}{m} \sum_{i=1}^m \| x^{(i)}-\mu_{c^{(i)}}\|^2 \\
\min_{c^{(1)},...,c^{(m)},\ \mu_1,...,\mu_k} J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_k)
&lt;/script&gt;

&lt;p&gt;Choosing the Number of Clusters:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Choosing more numbers of clusters could reduce local Optimization&lt;/li&gt;
  &lt;li&gt;Use “Elbow method” to find the K which is the numbers of clusters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Elbow method&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;K值越大，各个点到centroid的距离之和越小&lt;/li&gt;
  &lt;li&gt;当随着K值的增加，距离之和下降的不明显的话，就没有必要再增加K值了&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Support Vector Machines</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/10/30/svm"/>
   <updated>2015-10-30T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/10/30/svm</id>
   <content type="html">&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\min_{\theta} = C \sum_{i=1}^m \biggr[ y^{(i)} \operatorname{cost}_1 (\theta^Tx^{(i)}) + (1-y^{(i)})\operatorname{cost}_0 (\theta^Tx^{(i)}) \biggr] + \frac{1}{2} \sum_{j=1}^n \theta_j^2
&lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section&quot;&gt;要了解支撑向量机，首先要弄明白：向量相乘的几何意义。&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;向量u的模 &lt;script type=&quot;math/tex&quot;&gt;\times&lt;/script&gt; 向量v在向量u上的投影。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;u \times v = \| u \| \cdot \| v \| \cos(\theta)&lt;/script&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;向量相乘，可以表示&lt;code&gt;一个向量在另一个向量方向上投影的距离&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;支撑向量机的推理过程：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;如果一个向量空间中有两个向量：一个正向量u，一个负向量v，一个分割平面c。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
w \cdot u \geqslant c \\
w \cdot v \leqslant c
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;如果要在间隔的话，即：margin&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
w \cdot u - b \geqslant c \\
w \cdot v + b \leqslant c
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;如果把c平面看做0平面的话，即：平面上面的大于等于0，下面的小于等于0&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
w \cdot u - b \geqslant 0 \ \ \ \text{positive} \\
w \cdot v + b \leqslant 0 \ \ \ \text{negative}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;如果是间隔为1，并且normalization公式的话：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
w \cdot x_+ - 1 \geqslant 0 \ \ \ \text{positive} \\
w \cdot x_- + 1 \leqslant 0 \ \ \ \text{negative} \\
\\
w \cdot x_+ \geqslant 1 \ \ \ \text{positive} \\
w \cdot x_- \leqslant -1 \ \ \ \text{negative}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;引入一个y，到上面的式子中&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y =
\begin{cases}
+1 \ \ \ \text{positive sample}\\
-1 \ \ \ \text{negative sample}
\end{cases}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
w \cdot x_+ \geqslant 1 \ \ \ \text{positive} \\
w \cdot x_- \leqslant -1 \ \ \ \text{negative}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y_+ w \cdot x_+ \geqslant 1 \ \ \ \text{positive} \\
y_- w \cdot x_- \geqslant 1 \ \ \ \text{negative}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y \cdot w \cdot x \geqslant 1
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y w x -1 \geqslant 0
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;我们可以加上一个阀值：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y (w x + b)  -1 \geqslant 0
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;找出支撑点来&lt;/code&gt;，即在支撑线上的点&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y (w x + b)  -1 = 0
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;求支撑线之间的宽度：在+支撑线上的&lt;script type=&quot;math/tex&quot;&gt;x_+&lt;/script&gt;，与在-支撑线上的&lt;script type=&quot;math/tex&quot;&gt;x_-&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\text{WIDTH} =  (x_+ - x_-) \cdot \frac{w}{\| w \|}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
x_+ = \frac{1-b}{w} \\
x_- = -\frac{1+b}{w} \\
x_+ - x_- = \frac{1-b-(-1-b)}{w} = \frac{2}{w} \\
\text{WIDTH} =  (x_+ - x_-) \cdot \frac{w}{\| w \|} = \frac{2}{w} \cdot \frac{w}{\| w \|}  = \frac{2}{\| w \|} \\
w = \operatorname{arg} \max(\frac{2}{\| w \|}) \\
= \operatorname{arg} \max(\frac{1}{\| w \|}) \\
= \operatorname{arg} \min(\| w \|) \\
= \operatorname{arg} \min(\frac{1}{2}\| w \|^2)
&lt;/script&gt;

&lt;h4 id=&quot;section-2&quot;&gt;得到支撑向量机的公式表示：&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y =
\begin{cases}
+1 \ \ \ \text{positive sample}\\
-1 \ \ \ \text{negative sample}
\end{cases}
\ \ \ (1) \\

y (w x + b)  -1 \geqslant 0
\ \ \ (2) \\

w = \operatorname{arg} \min(\frac{1}{2}\| w \|^2)
\ \ \ (3)
&lt;/script&gt;

&lt;hr /&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\min(\frac{1}{2}\| w \|^2) \ \  \Bigl\{\text{subject to} \ \ \ y (w x + b) \geqslant 1 \Bigl\}
&lt;/script&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;这个其实是一个带约束的二次规划(quadratic-programming, QP)问题；&lt;/li&gt;
  &lt;li&gt;是一个凸问题，凸问题就是指的不会有局部最优解；&lt;/li&gt;
  &lt;li&gt;可以想象一个漏斗，不管我们开始的时候将一个小球放在漏斗的什么位置，这个小球最终一定可以掉出漏斗，也就是得到全局最优解。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;lagrange-equation&quot;&gt;使用“拉格朗日”函数，来求解支撑向量机（Lagrange equation）&lt;/h4&gt;

&lt;p&gt;关于 Lagrange duality 简单地来说，通过给每一个约束条件加上一个 Lagrange multiplier，我们可以将它们融和到目标函数里去：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\mathcal{L}(w,b,\alpha) = \frac{1}{2}\| w \|^2 - \sum \alpha_i \Bigl[y_i(wx_i + b) - 1 \Bigl] \\
\frac{\partial L}{\partial w} = w - \sum \alpha_i y_i x_i = 0\\
w = \sum_i \alpha_i y_i x_i \\
\frac{\partial L}{\partial b} = - \sum_i \alpha_i y_i = 0 \\
\sum_i \alpha_i y_i = 0
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\mathcal{L}(w,b,\alpha) = \frac{1}{2} w^Tw - \sum_i \alpha_i \Bigl[y_i(w^Tx_i + b) - 1 \Bigl] \\
\mathcal{L}(w,b,\alpha) = \frac{1}{2} w^Tw - \sum_i \alpha_i y_i x_i w^T - \sum_i \alpha_i y_i b + \sum_i \alpha_i\\
\mathcal{L}(w,b,\alpha) = \frac{1}{2} w^Tw - ww^T - 0 + \sum_i \alpha_i\\
\mathcal{L}(w,b,\alpha) = \sum_i \alpha_i - \frac{1}{2} w^Tw \\
\mathcal{L}(w,b,\alpha) = \sum_i \alpha_i - \sum_i \sum_j \alpha_i y_i x_i^T  \alpha_j y_j x_j \\
\mathcal{L}(w,b,\alpha) = \sum_i \alpha_i - \sum_i \sum_j \alpha_i \alpha_j y_i y_j x_i^T x_j
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;新问题加上其限制条件是（对偶问题）:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\max_\alpha \sum_i^n \alpha_i - \sum_i^n \sum_j^n \alpha_i \alpha_j y_i y_j x_i^T x_j \\
s.t., \alpha \geqslant 0, i=1,2,...n \\
\sum_i^n \alpha_i y_i = 0
&lt;/script&gt;

&lt;h4 id=&quot;kernel&quot;&gt;Kernel&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;用一个哲学例子来说：世界上本来没有两个完全一样的物体，对于所有的两个物体，我们可以通过增加维度来让他们最终有所区别，比如说两本书，从(颜色，内容)两个维度来说，可能是一样的，我们可以加上 作者 这个维度，是在不行我们还可以加入 页码，可以加入 拥有者，可以加入 购买地点，可以加入 笔记内容等等。&lt;code&gt;当维度增加到无限维的时候，一定可以让任意的两个物体可分了&lt;/code&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果用 &lt;script type=&quot;math/tex&quot;&gt;x_1,x_2&lt;/script&gt; 来表示二维平面的两个坐标的话，我们知道一条二次曲线（圆圈是二次曲线的一种特殊情况）的方程可以写作这样的形式：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a_1x_1 + a_2x_1^2 + a_3x_2+a_4x_2^2+a_5x_1x_2+a_6 = 0
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;如果我们构造另外一个五维的空间，其中五个坐标的值分别为 &lt;script type=&quot;math/tex&quot;&gt; z_1=x_1, z_2=x_1^2, z_3=x_2, z_4=x_2^2, z_5=x_1x_2 &lt;/script&gt; 那么显然，上面的方程在新的坐标系下可以写作：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a_1z_1 + a_2z_2 + a_3z_3+a_4z_4+a_5z_5+a_6 = 0 \\

\sum_{i=1}^5 a_iz_i + a_6 = 0
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\mathcal{L}(w,b,\alpha) = \sum_i \alpha_i - \sum_i \sum_j \alpha_i \alpha_j y_i y_j z_i^T z_j
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;关于新的坐标z，这正是一个 hyper plane 的方程！也就是说，如果我们做一个映射 ϕ:ℝ2→ℝ5 ，将 X 按照上面的规则映射为 Z ，那么在新的空间中原来的数据将变成线性可分的，从而使用之前我们推导的线性分类算法就可以进行处理了。这正是 Kernel 方法处理非线性问题的基本思想。&lt;/li&gt;
  &lt;li&gt;这种kernel的叫做“多项式核”。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

f(x) = a_1x_1 + a_2x_1^2 + a_3x_2+a_4x_2^2+a_5x_1x_2+a_6 = 0 \\
f(x) = a_1z_1 + a_2z_2 + a_3z_3+a_4z_4+a_5z_5+a_6 = 0 \\
z = \begin{bmatrix}
1 \\x_1 \\ x_1^2 \\ x_2 \\x_2^2 \\x_1x_2
\end{bmatrix}
\\
z^T = \begin{bmatrix}
1 &amp; x_1&#39; &amp; x_1&#39;^2 &amp; x_2&#39; &amp; x_2&#39;^2 &amp;x_1&#39;x_2&#39;
\end{bmatrix}
\\
z^Tz = 1 + x_1&#39;x_1 + x_1&#39;^2x_1^2 + x_2&#39;x_2 + x_2&#39;^2x_2^2 + x_1&#39;x_2&#39;x_1x_2 \ \ \ (1)
\\
x_i = \begin{bmatrix}
x_1 \\ x_1^2
\end{bmatrix}
\\
x_j = \begin{bmatrix}
x_1&#39; \\ x_1&#39;^2
\end{bmatrix}
\\
(1+x^Tx&#39;)^2 = (1+x_1x_1&#39;+x_2x_2&#39;)^2 = \\
1+ 2x_1&#39;x_1 + x_1&#39;^2x_1^2 + 2x_2&#39;x_2 + x_2&#39;^2x_2^2 + 2x_1&#39;x_2&#39;x_1x_2 \ \ \ (2)
 %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;由上面的例子可以看出，把低维度空间数据映射到高维空间数据，理论上是可行的。但是如果用这种方法的话，2个维度，映射到高维以后会变成5个维度；&lt;/li&gt;
  &lt;li&gt;3个维度映射到高维空间以后会变成19个维度，所以维度的增加会是指数级的，如果维度变大的话，计算量会指数级的变大。&lt;/li&gt;
  &lt;li&gt;我们发现两个向量相加的平方与两个向量映射到高维空间的复杂度是一样的。这样我们相当于在低维运算出高维的结果。计算量会大大减小。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
z^Tz&#39; = 1 + x_1&#39;x_1 + x_1&#39;^2x_1^2 + x_2&#39;x_2 + x_2&#39;^2x_2^2 + x_1&#39;x_2&#39;x_1x_2 \ \ \ (1) \\
(1+x^Tx&#39;)^2 = 1+ 2x_1&#39;x_1 + x_1&#39;^2x_1^2 + 2x_2&#39;x_2 + x_2&#39;^2x_2^2 + 2x_1&#39;x_2&#39;x_1x_2 \ \ \ (2)
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;第一个是现在高维空间展开，然后再做内积&lt;/li&gt;
  &lt;li&gt;第二个是直接在低维空间做内积，得到的值再平方，相当于在低维运算出高维的结果。&lt;/li&gt;
  &lt;li&gt;随着维度的增加，第二种方法的计算量会远小于第一种。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\max_\alpha \sum_i^n \alpha_i - \sum_i^n \sum_j^n \alpha_i \alpha_j y_i y_j k(x_i, x_j) \\
s.t., \alpha \geqslant 0, i=1,2,...n \\
\sum_i^n \alpha_i y_i = 0
&lt;/script&gt;

&lt;ol&gt;
  &lt;li&gt;Polynomial Kernel
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
 k(x_1,x_2) = (&lt;x_1,x_2&gt; + R)^d %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Gaussian Kernel
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt; k(x_1,x_2) = \text{exp} \Bigl(-\frac{\|x_1 - x_2 \|^2}{2\sigma^2} \Bigl)&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;如果 σ 选得很大的话，高次特征上的权重实际上衰减得非常快，所以实际上相当于一个低维的子空间；反过来，如果 σ 选得很小，则可以将任意的数据映射为线性可分——当然，这并不一定是好事，因为随之而来的可能是非常严重的过拟合问题。不过，总的来说，通过调控参数 σ ，高斯核实际上具有相当高的灵活性，也是使用最广泛的核函数之一。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Linear Kernel
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
 k(x_1,x_2) = &lt;x_1,x_2&gt;  %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;这实际上就是原始空间中的内积。这个核存在的主要目的是使得“映射后空间中的问题”和“映射前空间中的问题”两者在形式上统一起来了。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;除了 SVM 之外，任何将计算表示为数据点的内积的方法，都可以使用核方法进行非线性扩展。&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;soft-margin-svm-outliers&quot;&gt;Soft-margin SVM (Outliers)&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y_i (w^T x_i + b) \geqslant 1 \\

y_i (w^T x_i + b) \geqslant 1 - \xi_i
&lt;/script&gt;

&lt;p&gt;其中 ξi≥0 称为松弛变量 (slack variable) ，对应数据点 x 允许偏离的 functional margin 的量。当然，如果我们运行 ξi 任意大的话，那任意的超平面都是符合条件的了。所以，我们在原来的目标函数后面加上一项，使得这些 ξi 的总和也要最小：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\min(\frac{1}{2}\| w \|^2) + C\sum_{i=1}^n \xi_i
 &lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-3&quot;&gt;从不同的角度解释“向量相乘”&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

u =
\begin{bmatrix}
u_0 \\
u_1
\end{bmatrix}

\ \ \ \

v =
\begin{bmatrix}
v_0 \\
v_1
\end{bmatrix} \\

u^Tv =
\begin{bmatrix}
u_0 &amp; u_1
\end{bmatrix}

\begin{bmatrix}
v_0 \\
v_1
\end{bmatrix}

= u_0 v_0 + u_1 v_1 \\
 %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;img height=&quot;200px&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Dot_Product.svg/2000px-Dot_Product.svg.png&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\parallel u \parallel = \sqrt{(u_0^2 + u_1^2)} \\
p = \text{length of projection of v onto u} \\
u^Tv = p \times \parallel u \parallel \\
&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;http://cdn1.askiitians.com/Images/2014108-144310695-8606-dot-product-image.PNG&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
u \times v = \parallel u \parallel \parallel v \parallel \cos(\theta)
&lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference：&lt;/h4&gt;

&lt;p&gt;sth&lt;/p&gt;

&lt;p&gt;https://www.youtube.com/watch?v=_PwhiWxHK8o&lt;/p&gt;

&lt;p&gt;http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/basic-of-svm.html&lt;/p&gt;

&lt;p&gt;http://www.cnblogs.com/jerrylead/archive/2011/03/13/1982684.html&lt;/p&gt;

&lt;p&gt;http://blog.pluskid.org/?page_id=683&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Neural Networks</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/10/26/neural-networks"/>
   <updated>2015-10-26T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/10/26/neural-networks</id>
   <content type="html">&lt;h4 id=&quot;introduction&quot;&gt;Introduction&lt;/h4&gt;

&lt;p&gt;总的来说，人工神经网络，可以看做分为3层：输入层、隐含层、输出层&lt;/p&gt;

&lt;p&gt;下面以最简单的三层神经网络为例来描述人工神经网络：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Neural Model: Logistic Unit&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
g(z) = \frac{1}{1+e^{-(\theta^Tx)}}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;输入层&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
x =
\begin{bmatrix}
x_0 \\
x_1 \\
\vdots \\
x_n
\end{bmatrix} \ \ \

\theta =
\begin{bmatrix}
\theta_0 \\
\theta_1 \\
\vdots \\
\theta_n
\end{bmatrix}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;隐含层&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
z^{(2)} =
\begin{bmatrix}
z_0^{(2)} \\
z_1^{(2)} \\
\vdots \\
z_n^{(2)}
\end{bmatrix} \\
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a_1^{(2)} = g(\theta_{10}^{(1)}x_0 + \theta_{11}^{(1)}x_1 + \cdots + \theta_{1n}^{(1)}x_n) \\

a_2^{(2)} = g(\theta_{20}^{(1)}x_0 + \theta_{21}^{(1)}x_1 + \cdots + \theta_{2n}^{(1)}x_n) \\

\vdots \\

a_m^{(2)} = g(\theta_{m0}^{(1)}x_0 + \theta_{m1}^{(1)}x_1 + \cdots + \theta_{mn}^{(1)}x_n)
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;输出层&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
h(x)=g(\theta_0^{(2)} a_0^{(2)} + \theta_1^{(2)} a_1^{(2)} + \cdots + \theta_n^{(2)} a_n^{(2)})
&lt;/script&gt;

&lt;h4 id=&quot;cost-function&quot;&gt;Cost Function&lt;/h4&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference：&lt;/h4&gt;

&lt;p&gt;http://tieba.baidu.com/p/3013551686&lt;/p&gt;

&lt;p&gt;http://www.cnblogs.com/heaad/archive/2011/03/07/1976443.html&lt;/p&gt;

&lt;p&gt;https://github.com/ty4z2008/Qix/blob/master/dl.md&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Solving Overfitting</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/10/25/solve-overfitting"/>
   <updated>2015-10-25T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/10/25/solve-overfitting</id>
   <content type="html">&lt;h4 id=&quot;regularization&quot;&gt;1. Regularization&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J(\theta) = \frac{1}{2m} \Biggr[\sum_{i=1}^m (h_{\theta}x^{(i)}-y^{(i)})^2 - \lambda \sum_{j=1}^n \theta_j^2 \Biggr]
&lt;/script&gt;

&lt;h4 id=&quot;cross-validation&quot;&gt;2. Cross Validation&lt;/h4&gt;

&lt;p&gt;Cross-validation for detecting and preventing overfitting&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://qph.is.quoracdn.net/main-qimg-33774ab551d31370fbe2a4fa57286781?convert_to_webp=true&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;choose-data-size&quot;&gt;choose data size&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Training size and Cross-validation Size&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://1.bp.blogspot.com/-ii5sPXFN0K4/T9Wrs34LiHI/AAAAAAAAAwI/K6Eu-97LY1A/s1600/p2.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If Learning Algorithm is suffer from overfitting(high Variance), getting more data is likely to help.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://4.bp.blogspot.com/-uWXoQpZpdOs/T9WvcIcjpCI/AAAAAAAAAwc/Hr3pn8RPQz4/s1600/p3.png&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Normal Equation</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/10/23/normal-equation"/>
   <updated>2015-10-23T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/10/23/normal-equation</id>
   <content type="html">&lt;h3 id=&quot;theta--xtx-1xty&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;\theta = (X^TX)^{-1}X^Ty&lt;/script&gt;&lt;/h3&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;theta-in-r-&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \theta \in R &lt;/script&gt;&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J_{(\theta)} = a \theta^2 + b \theta + c \\
\frac{\partial}{\partial \theta} J_{(\theta)} = 0 \\
\text{solve for } \theta
&lt;/script&gt;

&lt;h4 id=&quot;theta-in-rn1-&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \theta \in R^{n+1} &lt;/script&gt;&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;

J_{(\theta_0, \theta_1, ... , \theta_m)} = \frac{1}{2m} \sum_{i=1}^m (h_{\theta} (x^{(i)}) - y^{(i)})^2 \\
\frac{\partial}{\partial \theta} J_{(\theta)} = \cdots = 0 \ \text{(for every j)} \\
\text{solve for } \theta_0, \theta_1, ... , \theta_n \\
\theta = (X^TX)^{-1}X^Ty
&lt;/script&gt;

&lt;hr /&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
x^{(i)} =
\begin{bmatrix}
x_0^{(i)} \\
x_1^{(i)} \\
x_2^{(i)} \\
\vdots  \\
x_n^{(i)}
\end{bmatrix}
\in R^{n+1}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
(x^{(i)})^T =
\begin{bmatrix}
x_0^{(i)}, x_1^{(i)}, \cdots, x_n^{(i)}
\end{bmatrix}
\in R^{n+1}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
X_{m \times n} =
\begin{bmatrix}
(x^{(i)})^T
\end{bmatrix}
=
\begin{bmatrix}
(x^{(1)})^T \\
(x^{(2)})^T \\
(x^{(3)})^T \\
\vdots  \\
(x^{(m)})^T
\end{bmatrix}
\in R^{m}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\theta_{n \times 1} =
\begin{bmatrix}
\theta_0 \\
\theta_1 \\
\theta_2 \\
\vdots  \\
\theta_n
\end{bmatrix}
\in R^{n+1}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y_{m \times 1} =
\begin{bmatrix}
y^{(1)} \\
y^{(2)} \\
y^{(3)} \\
\vdots  \\
y^{(m)}
\end{bmatrix}
\in R^{m}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
X_{m \times n} \theta_{n \times 1} = y_{m \times 1} \\
X \theta = y \\
X^T X \theta = X^T y \\
(X^T X)^{-1} (X^T X) \theta = (X^T X)^{-1} X^T y \\
\theta = (X^T X)^{-1} X^T y
&lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;normal-equation-vs-gradient-descent&quot;&gt;Normal Equation VS Gradient Descent&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Gradient Descent
    &lt;ul&gt;
      &lt;li&gt;need to choose &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;need many iterations.&lt;/li&gt;
      &lt;li&gt;works well even when &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; is large.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Normal Equation
    &lt;ul&gt;
      &lt;li&gt;no need to choose choose &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;do not need to iterate.&lt;/li&gt;
      &lt;li&gt;slow is &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; is very large.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Logistic Regression</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/10/23/logistic-regression"/>
   <updated>2015-10-23T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/10/23/logistic-regression</id>
   <content type="html">&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

h_{\theta} = \theta^Tx \\
y = 1 \ \text{if} \ \theta^Tx \ge 0 \\
y = 0 \ \text{if} \ \theta^Tx &lt;0
 %]]&gt;&lt;/script&gt;

&lt;p&gt;Take into Logistic Regression:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

g(h_{\theta}) = g(\theta^Tx) = 0.5 \\
y = 1 \ \text{if} \ \theta^Tx \ge 0 \\
y = 0 \ \text{if} \ \theta^Tx &lt;0
 %]]&gt;&lt;/script&gt;

&lt;p&gt;In Linear Regression, the hypothesis function is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; h_{\theta}(x) = \theta^Tx &lt;/script&gt;

&lt;p&gt;Sigmoid Function is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; g(z) = \frac{1}{1+ e^{-z}} &lt;/script&gt;

&lt;p&gt;Logistic Regression, the hypothesis function is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
h_{\theta}(x) = g(\theta^Tx) =
\frac{1}{1 + e^{-(\theta^Tx)}}
&lt;/script&gt;

&lt;p&gt;Decision Boundary&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
h_{\theta}(x) = g(\theta^Tx) = p(y=1 \ | \ x, \theta)
&lt;/script&gt;

&lt;p&gt;Predict:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

(1) \\
y=1 \ \ \text{if} \ h_{\theta} \ge 0.5 \\
\Rightarrow g(z) \ge 0.5 \\
\Rightarrow g(z) = g({\theta^Tx}) \\
\Rightarrow g(\theta^Tx) \ge 0.5 \\
\Rightarrow \theta^Tx \ge 0 \\
(2) \\
y=0 \ \ \text{if} \ h_{\theta} &lt; 0.5 \\
\Rightarrow g(z) &lt; 0.5 \\
\Rightarrow g(z) = g({\theta^Tx}) \\
\Rightarrow g(\theta^Tx) &lt; 0.5 \\
\Rightarrow \theta^Tx &lt; 0
 %]]&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section&quot;&gt;逻辑回归的推导过程：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;首先“逻辑回归”是“线性回归”的延续。其中&lt;script type=&quot;math/tex&quot;&gt;\theta_0&lt;/script&gt;是截距，&lt;script type=&quot;math/tex&quot;&gt;\theta_1&lt;/script&gt;是斜率。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
h_{\theta}(x) = \theta_0 + \theta_1x \ \ (\text{其中}\theta_0 \text{是截距, } \theta_1 \text{是斜率})
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;线性回归也是可以拟合（0，1）问题的，但是线性回归的值y，可能会&amp;gt;1,或者&amp;lt;0: { y&amp;lt;0 or y&lt;script type=&quot;math/tex&quot;&gt;\in&lt;/script&gt;{0,1} or y&amp;gt;1 }。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
h_{\theta}(x) \in (-\infty, +\infty) \\
y = (0, 1)
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;我们希望“线性回归”的区间在（0，1）之间。首先想到的是：使所有&amp;lt;0的值，都==0；所有&amp;gt;1的值，都==1。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\text{if} \ h_{\theta}(x) &lt; 0 \ \text{then} \ h_{\theta}(x) = 0 \\
\text{if} \ h_{\theta}(x) &gt; 1 \ \text{then} \ h_{\theta}(x) = 1
 %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;为了优化（平滑）上面的结果，我们想到了：&lt;script type=&quot;math/tex&quot;&gt;e^x&lt;/script&gt;曲线，它的所有值，都大于0，但是它的值会&amp;gt;1。带入公式得到：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
h_{\theta}(x) = e^x = e^{(\theta_0 + \theta_1x)} &gt; 0
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;我们再对上面的结果，做优化：&lt;script type=&quot;math/tex&quot;&gt;\frac{e^x}{e^x+1}&lt;/script&gt;，这样就得到了“逻辑回归”函数，也叫Sigmoid Function。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

h_{\theta}(x) = \frac{e^x}{e^x+1} = \frac{1}{1+e^{-x}} = \frac{1}{1+e^{-(\theta_0 + \theta_1x)}} &lt; 1
 %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;最后我们得到一个大于0，小于1的，平滑的函数：Sigmoid Function或者叫做：Logistic Function。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

0 &lt; \frac{1}{1+e^{-(\theta_0 + \theta_1x)}} &lt; 1 \ (\text{其中}\theta_0 \text{是截距, } \theta_1 \text{是斜率}) \\
0 &lt; h_{\theta}(x) &lt; 1
 %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;在这里&lt;script type=&quot;math/tex&quot;&gt;h_{\theta}(x) &lt;/script&gt; 有特殊的含义：它表示x对应的f(x)取值为1的概率。所以对于输入的x，结果为1和0的概率分别是：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
p(y=1 \ | \ x;\theta) = h_{\theta}(x) \\
p(y=0 \ | \ x;\theta) = 1 - h_{\theta}
&lt;/script&gt;

&lt;h4 id=&quot;cost-function&quot;&gt;逻辑回归的Cost Function：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;我们可以像“线性回归”一样，使用方差的和，来表示“期望函数”与“真实值之间的偏差”。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J_{\theta} = \frac{1}{2m} \sum_{i=1}^m (h_{\theta}(x)^{i} - y^{i})^2 \\
h_{\theta}(x) - y = \frac{e^x}{e^x + 1} - 1 = \frac{e^x}{e^x + 1} - \frac{e^x+1}{e^x+1} = \frac{-1}{e^x+1}  \ (\text{if} \ y = 1)\\
h_{\theta}(x) - y = \frac{e^x}{e^x + 1} - 0 = \frac{e^x}{e^x + 1} =  \frac{1}{e^x+1}  \ (\text{if} \ y = 0)\\
(h_{\theta}(x) - y)^2 = (\frac{1}{e^x+1})^2 = (e^x+1)^{-2} \ \text{where} \ y = (0,1) \\
J_{\theta} = \frac{1}{2m} \sum_{i=1}^m (e^x+1)^{-2}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;对上面的函数是一个“非凸函数”，有很多局部最优解，所以不能使用“梯度下降”。&lt;/li&gt;
  &lt;li&gt;需要用其它的思路来minimize cost function：“极大似然”。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
Cost(h_{\theta}(x), y) =
\begin{cases}
-\log(h_{\theta}(x)) \ \text{if} \ y = 1 \\
-\log(1- h_{\theta}(x)) \ \text{if} \ y = 0
\end{cases} \\
= (y^{(i)} \log(h_{\theta}(x^{(i)})) + (1-y^{(i)})\log(1-h_{\theta}(x^{(i)})))
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;把上面的公式，写到同一个公式中。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用“极大似然”推导cost function的过程&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
p(y|x;\theta) = (h_{\theta}(x))^y(1-h_{\theta}(x))^{1-y} \\
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;取似然函数为：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
L_{\theta} = \prod_{i=1}^m p(y^{(i)}|x^{(i)};\theta)
= \prod_{i=1}^m (h_{\theta}(x^{(i)}))^{y^{(i)}} (1-h_{\theta}(x^{(i)}))^{1-y^{(i)}}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;为了简化计算量，为似然函数取log，取对数可以得到对数似然度：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
l(\theta) = \log(L(\theta)) =
\sum_{i=1}^m (y^{(i)} \log(h_{\theta}(x^{(i)})) + (1-y^{(i)})\log(1-h_{\theta}(x^{(i)})))
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;现在我们要求的就是可以是&lt;script type=&quot;math/tex&quot;&gt;l(\theta)&lt;/script&gt;的值，为最大的&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;的值。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\text{We wanna find } \theta \text{ let } l(\theta) \text{ to be maximized: } \\
\theta = \operatorname{arg} \max(l(\theta))
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;这里我们要求最大值，可以用梯度上升法来求，也可以先对&lt;script type=&quot;math/tex&quot;&gt;l(\theta)&lt;/script&gt;取负数，然后用梯度下降法来求最小值。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J(\theta) = -\frac{1}{m} l(\theta)
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;所以这里还用梯度下降法来最小值：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\theta = \operatorname{arg} \min(l(\theta))
&lt;/script&gt;

&lt;h4 id=&quot;jthetatheta&quot;&gt;用“梯度下降”求使&lt;script type=&quot;math/tex&quot;&gt;J(\theta)&lt;/script&gt;为最小值的&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J_{(\theta)} \ (j=0...n)
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Partial Derivative (1)&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\frac{\partial}{\partial x} (\log_ax) = \frac{1}{x \ln a}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Partial Derivative (2)&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\frac{\partial}{\partial x} e^x = e^x
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Partial Derivative (3)&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
h_{\theta}(x^{(i)}) = g(\theta^Tx^{(i)})  \\

\frac{\partial}{\partial x_i} g(\theta^Tx^{(i)}) =
\frac{\partial}{\partial x_i} (\frac{1}{1+e^{-(\theta^Tx^{(i)})}}) \\
= (\frac{1}{1+e^{-(\theta^Tx^{(i)})}})^2 e^{-(\theta^Tx^{(i)})} \frac{\partial}{\partial x_i} (\theta^Tx^{(i)}) \\

= \frac{1}{1+e^{-(\theta^Tx^{(i)})}} \frac{e^{-(\theta^Tx^{(i)})}}{1+e^{-(\theta^Tx^{(i)})}} \frac{\partial}{\partial x_i} (\theta^Tx^{(i)}) \\

= \frac{1}{1+e^{-(\theta^Tx^{(i)})}} \frac{e^{-(\theta^Tx^{(i)})}}{1+e^{-(\theta^Tx^{(i)})}} x^{(i)}\\

= g(\theta^Tx^{(i)})(1-g(\theta^Tx^{(i)}))x^{(i)} \\

= h_{\theta}(x^{(i)})(1-h_{\theta}(x^{(i)}))x^{(i)}
&lt;/script&gt;

&lt;hr /&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\frac{\partial}{\partial \theta_j} J_{(\theta)} =
\frac{\partial}{\partial \theta_j} (-\frac{1}{m} \sum_{i=1}^m (y^{(i)} \log(h_{\theta}(x^{(i)})) + (1-y^{(i)})\log(1-h_{\theta}(x^{(i)})))) \\

= -\frac{1}{m} \sum_{i=1}^m (y^{(i)} \frac{1}{h_{\theta}(x^{(i)})} \frac{\partial}{\partial \theta_j}(h_{\theta}(x^{(i)})) - (1-y^{(i)}) \frac{1}{1-h_{\theta}(x^{(i)})} \frac{\partial}{\partial \theta_j}(h_{\theta}(x^{(i)}))) \\

= -\frac{1}{m} \sum_{i=1}^m (y^{(i)} \frac{1}{h_{\theta}(x^{(i)})} - (1-y^{(i)}) \frac{1}{1-h_{\theta}(x^{(i)})} ） \frac{\partial}{\partial \theta_j}(h_{\theta}(x^{(i)})） \\

= -\frac{1}{m} \sum_{i=1}^m (y^{(i)} \frac{1}{h_{\theta}(x^{(i)})} - (1-y^{(i)}) \frac{1}{1-h_{\theta}(x^{(i)})} ）h_{\theta}(x^{(i)})(1-h_{\theta}(x^{(i)}))x_j^{(i)} \\

= -\frac{1}{m} \sum_{i=1}^m (y^{(i)} (1-h_{\theta}(x^{(i)})) - (1-y^{(i)}) h_{\theta}(x^{(i)})）x_j^{(i)} \\

= -\frac{1}{m} \sum_{i=1}^m (y^{(i)} - h_{\theta}(x^{(i)})) x_j^{(i)} \\

= \frac{1}{m} \sum_{i=1}^m (h_{\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} \\
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J_{(\theta)} \ (j=0...n) \\
\theta_j := \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m (h_{\theta}(x_j^{(i)}) - y^{(i)}) x_j^{(i)}  \ (j=0...n) \\
\theta_j := \theta_j - \alpha \sum_{i=1}^m (h_{\theta}(x_j^{(i)}) - y^{(i)}) x_j^{(i)}  \ (j=0...n)
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;如果“梯度上升”的话，与“梯度下降”的原理一样，公式可以改写为：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\theta_j := \theta_j + \alpha \sum_{i=1}^m (y^{(i)} - h_{\theta}(x_j^{(i)})) x_j^{(i)}  \ (j=0...n)
&lt;/script&gt;

&lt;hr /&gt;

&lt;pre&gt;&lt;code&gt;
x &amp;lt;- runif(100, 0, 10)
y &amp;lt;- runif(100, 0, 10)

plot(main=&quot;Tumour Or Not&quot;, xlab=&quot;tumour size&quot;, ylab=&quot;tumour or not&quot;, pch=19, col=&quot;red&quot;, col.axis=&quot;brown&quot;, fg=&quot;purple&quot;, bg=&quot;white&quot;, col.sub=&quot;orange&quot;, sub=&quot;Logistic Regression&quot;, x,y,col.main=&quot;blue&quot;,col.lab=&quot;brown&quot;, xlim=c(0,10), ylim=c(0,10))

abline(a=10, b=-1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;
y &amp;lt;- c(0,0,0,0,1,1,1,1)
x &amp;lt;- c(-4,-3,-2,-1,1,2,3,4)
plot(main=&quot;Tumour Or Not&quot;, xlab=&quot;tumour size&quot;, ylab=&quot;tumour or not&quot;, pch=19, col=&quot;red&quot;, col.axis=&quot;brown&quot;, fg=&quot;purple&quot;, bg=&quot;white&quot;, col.sub=&quot;orange&quot;, sub=&quot;Logistic Regression&quot;, x,y,col.main=&quot;blue&quot;,col.lab=&quot;brown&quot;, xlim=c(-4,4), ylim=c(0,1.1))

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference：&lt;/h4&gt;

&lt;p&gt;http://blog.csdn.net/dongtingzhizi/article/details/15962797&lt;/p&gt;

&lt;p&gt;http://tech.meituan.com/intro_to_logistic_regression.html&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Linear Regression</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/10/21/linear-regression"/>
   <updated>2015-10-21T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/10/21/linear-regression</id>
   <content type="html">&lt;h4 id=&quot;model-representation&quot;&gt;Model Representation&lt;/h4&gt;

&lt;pre clas=&quot;r language&quot;&gt;&lt;code&gt;
# Use R language to create plot

x &amp;lt;- c(1:6)
y &amp;lt;- c(1:6)

plot(main=&quot;Plot Recent House Sale&quot;, xlab=&quot;square feet (sq.ft.)&quot;, ylab=&quot;price ($)&quot;, pch=19, col=&quot;red&quot;, col.axis=&quot;brown&quot;, fg=&quot;purple&quot;, bg=&quot;white&quot;, col.sub=&quot;orange&quot;, sub=&quot;Relation between size and price&quot;, x,y,col.main=&quot;blue&quot;,col.lab=&quot;brown&quot;, xlim=c(0,7), ylim=c(0,7))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/linear-regression-1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We have a dataset:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
d_1 = \{1, 1\} \\
d_2 = \{2, 2\} \\
d_3 = \{3, 3\} \\
d_4 = \{4, 4\} \\
d_5 = \{5, 5\} \\
d_6 = \{6, 6\}
&lt;/script&gt;

&lt;p&gt;We can find a line can fitting all these data, which is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
f(x) = w_0 + w_1x
&lt;/script&gt;

&lt;hr /&gt;

&lt;pre clas=&quot;r language&quot;&gt;&lt;code&gt;
model &amp;lt;- lm(y~x)

plot(main=&quot;Plot Recent House Sale&quot;, xlab=&quot;square feet (sq.ft.)&quot;, ylab=&quot;price ($)&quot;, pch=19, col=&quot;red&quot;, col.axis=&quot;brown&quot;, fg=&quot;purple&quot;, bg=&quot;yellow&quot;, col.sub=&quot;orange&quot;, sub=&quot;Relation between size and price&quot;, x,y,col.main=&quot;blue&quot;,col.lab=&quot;brown&quot;, xlim=c(0,7), ylim=c(0,7))

abline(model, col=&quot;blue&quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/linear-regression-2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this plot, the scope is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
f(x) = 0 + 1 \cdot x
&lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;cost-function&quot;&gt;Cost Function&lt;/h4&gt;

&lt;pre clas=&quot;r language&quot;&gt;&lt;code&gt;
plot(main=&quot;Plot Recent House Sale&quot;, xlab=&quot;square feet (sq.ft.)&quot;, ylab=&quot;price ($)&quot;, pch=19, col=&quot;red&quot;, col.axis=&quot;brown&quot;, fg=&quot;purple&quot;, bg=&quot;yellow&quot;, col.sub=&quot;orange&quot;, sub=&quot;Relation between size and price&quot;, x,y,col.main=&quot;blue&quot;,col.lab=&quot;brown&quot;, xlim=c(0,7), ylim=c(0,7))

abline(a=1,b=3, col=&quot;blue&quot;)
abline(a=1,b=2, col=&quot;green&quot;)
abline(a=1,b=1, col=&quot;red&quot;)
abline(a=0,b=1, col=&quot;black&quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/linear-regression-3.png&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;

total \ deviation \ is: \ \sum_{x=1}^6 (f_{\theta}(x)-y)^2 \\
to \ general \ is: \ \sum_{x=i}^m (f_{\theta}(x)-y)^2 \\
we \ can \ rewrite \ to: \frac{1}{m} \sum_{x=i}^m (f_{\theta}(x)-y)^2 \\
also \ we \ can \ rewrite \ to: \frac{1}{2m} \sum_{x=i}^m (f_{\theta}(x)-y)^2 \\
we \ define: \ J_{\theta} = \frac{1}{2m} \sum_{x=i}^m (f_{\theta}(x)-y)^2 \\
we \ wanna \ minimize \ J_{\theta} : \theta = \operatorname{arg} \min{(J_{\theta})}
&lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h4&gt;

&lt;pre clas=&quot;r language&quot;&gt;&lt;code&gt;
x &amp;lt;- seq(-6,6,0.5)
f &amp;lt;- function(x)x^2
y &amp;lt;- f(x)
plot(main=&quot;Gradient Descent&quot;, x,y)
lines(loess.smooth(x,y),col=&#39;red&#39;,lwd=2)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/linear-regression-4.png&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;partial-derivative&quot;&gt;Partial Derivative&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J_{(\theta_0, \ \theta_1)} = (f_{\theta}(x)-y)^2 = (f_{\theta}(x))^2 - 2f_{\theta}(x)y- y^2 =
(w_0 + w_1x)^2 - 2(w_0+w_1x)y - y^2 =
w_0^2 + 2w_0w_1x + w_1^2x^2 - 2w_0y - 2w_1xy - y^2
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J_{(w_0, \ w_1)} = w_0^2 + 2w_0w_1x + w_1^2x^2 - 2w_0y - 2w_1xy - y^2
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\frac{\partial J_{(w_0, \ w_1)}}{\partial w_0} = 2w_0 + 2w_1x -2y = 2(w_0 + w_1x - y) = 2(f_{\theta}(x) - y) \\
\frac{\partial J_{(w_0, \ w_1)}}{\partial w_1} = 2w_0x + 2w_1x^2 - 2xy = 2x(w_0 + w_1x - y) = 2x(f_{\theta}(x) - y)
&lt;/script&gt;

&lt;hr /&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\theta := \theta - \alpha \frac{\partial J_{\theta}}{\partial \theta} \\
\theta_0 := \theta_0 - \alpha \frac{\partial J_{(\theta_0, \ \theta_1)}}{\partial \theta_0} \\
\theta_1 := \theta_1 - \alpha \frac{\partial J_{(\theta_0, \ \theta_1)}}{\partial \theta_1} \\

\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum_{i=1}^m(f_{\theta}(x) - y) \\
\theta_1 := \theta_1 - \alpha \frac{1}{m} \sum_{i=1}^m(f_{\theta}(x) - y)x
&lt;/script&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;feature-scaling&quot;&gt;Feature Scaling&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Mean normalization:
    &lt;ul&gt;
      &lt;li&gt;replace &lt;script type=&quot;math/tex&quot;&gt; x_i &lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt; x_i - u_i &lt;/script&gt;, Example:&lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x_i = \frac{x_i - u_i}{s_i}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;Average house size is: 1000, and maxima house size: 2000, then&lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x_1 = \frac{size-1000}{2000} &lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;Average bedroom is: 2, and maxima bedroom is: 5, then&lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt; x_2 = \frac{\#bedrooms-2}{5} &lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Example of the Machine Learning Steps</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/10/20/example-steps"/>
   <updated>2015-10-20T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/10/20/example-steps</id>
   <content type="html">
&lt;p&gt;Example: The project steps of “Detect Stree” with sensor. It is a project in: Mobile Sensor Data-to-knowledge&lt;/p&gt;

&lt;p&gt;Reference website: https://md2k.org/&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section&quot;&gt;1. 收集数据&lt;/h4&gt;

&lt;p&gt;以收集用户“情绪紧张”的数据为例：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;主动收集（实验室收集）效果90%
    &lt;ul&gt;
      &lt;li&gt;让参与者模拟当众“演讲”，来收集当时的参数&lt;/li&gt;
      &lt;li&gt;让参与者“把手放入冰水中”，来收集用户参数&lt;/li&gt;
      &lt;li&gt;让参与者考试：“做一份难度很大的测试”，来收集参数&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;被动收集（参与者主动汇报）效果75%
    &lt;ul&gt;
      &lt;li&gt;不是让用户“情绪紧张的时候汇报”，而是&lt;/li&gt;
      &lt;li&gt;随机在不同的时间，让用户填一份收集信息的表格，并检查当时的数据&lt;/li&gt;
      &lt;li&gt;被动收集数据的时候，可能用户的紧张情绪已经过了，但是用户仍然会认为还处在紧张情绪中，但是身体的各个指标已经恢复正常了，所以&lt;code&gt;由于每个人对紧张情绪理解的不一样，会造成数据和结果的偏差&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;2. 清洗数据&lt;/h4&gt;

&lt;p&gt;收集数据的时候，会不可避免的出现一些数据的异常，比如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;由于sensor的性能影响，有时候传入“收集系统”的数据时间间隔会不一样&lt;/li&gt;
  &lt;li&gt;由于sensor没有佩戴好，所以导致数据的异常&lt;/li&gt;
  &lt;li&gt;sensor本身可能会出现故障&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;由于上面的原因，需要对收集到的数据做清洗&lt;/p&gt;

&lt;h4 id=&quot;feature&quot;&gt;3. 确定feature&lt;/h4&gt;

&lt;p&gt;一次数据收集，可能会收集到很多的数据，供多个实验，这就需要找出不同实现需要的数据了。同一组数据收集，对应的实验：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;压力测试&lt;/li&gt;
  &lt;li&gt;饮酒测试&lt;/li&gt;
  &lt;li&gt;抽烟测试&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-2&quot;&gt;4. 归一化&lt;/h4&gt;

&lt;p&gt;不同的人，收集的到底数据样本是不一样的，比如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;模型人的心跳速度本来就会快些&lt;/li&gt;
  &lt;li&gt;有些人的体温本来就比正常人高或者低些&lt;/li&gt;
  &lt;li&gt;每个人对相同的压力，或者刺激，数据&lt;code&gt;变化的幅度&lt;/code&gt;也不一样。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们需要训练出来的数据，是“普遍”意义上的数据，所以需要“normalize”&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;min-max标准化（Min-Max Normalization）也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。&lt;/li&gt;
  &lt;li&gt;Z-score标准化方法. 这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。经过处理的数据符合标准正态分布，即均值为0，标准差为1。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;section-3&quot;&gt;5. 训练模型&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;可是使用传入的二分算法训练模型，如：
    &lt;ul&gt;
      &lt;li&gt;Support Vector Machine&lt;/li&gt;
      &lt;li&gt;Logistic Regression&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;可以使用二分算法，来就出各种结果的可能性，如：
    &lt;ul&gt;
      &lt;li&gt;Support Vector Machine
        &lt;ul&gt;
          &lt;li&gt;可以通过计算，测试节点&lt;code&gt;离&lt;/code&gt;分界线的&lt;code&gt;距离&lt;/code&gt;，来计算“百分比”&lt;/li&gt;
          &lt;li&gt;Logistic Regression，本来就可以计算“百分比”。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;可以使用一些算法，来分析模型，分析每个feature的权重。如：
    &lt;ul&gt;
      &lt;li&gt;Decision Tree
        &lt;ul&gt;
          &lt;li&gt;它本来就是训练每个branch的重要性的。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;section-4&quot;&gt;6. 交叉验证&lt;/h4&gt;

&lt;p&gt;通过cross validation多次运算，计算结果。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Information Flow Processing</title>
   <link href="http://zhou-dong.github.io/2015/10/13/information-flow-processing"/>
   <updated>2015-10-13T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/10/13/information-flow-processing</id>
   <content type="html">&lt;h4 id=&quot;section-1&quot;&gt;Section 1&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Information Flow Processing(IFP)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Information of Data no need to be stored into Database systems
    &lt;ul&gt;
      &lt;li&gt;Not deal with persistent data&lt;/li&gt;
      &lt;li&gt;Deal with transient data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data from different source 
    &lt;ul&gt;
      &lt;li&gt;Device sensors&lt;/li&gt;
      &lt;li&gt;Mobile phones&lt;/li&gt;
      &lt;li&gt;Web servers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Contributions to this model come from different communities
    &lt;ul&gt;
      &lt;li&gt;distributed information systems&lt;/li&gt;
      &lt;li&gt;nusiness process automation&lt;/li&gt;
      &lt;li&gt;control systems&lt;/li&gt;
      &lt;li&gt;network monitoring&lt;/li&gt;
      &lt;li&gt;sensor networks&lt;/li&gt;
      &lt;li&gt;middleware in general&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;May be come from the publish-subsribe domain&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;Section 2&lt;/h4&gt;

&lt;p&gt;describes the IFP domain in more detail, provides an initial description of the different technologies that have been developed to support it, and explains the need for combining the best of different worlds to fully support IFP applications. &lt;/p&gt;

&lt;h5 id=&quot;active-database-system&quot;&gt;Active database system&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Something origial DB can not do&lt;/li&gt;
  &lt;li&gt;There are several tools classified as active database systems, with different software architectures, functionality, and oriented toward different application domains&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-3&quot;&gt;Section 3&lt;/h4&gt;

&lt;p&gt;describes a framework to model and analyze the different aspects that are relevant for an IFP engine from its functional architecture, to its data and processing models, to the language it provides to express how information has to be processed, to its run-time architecture. &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Functional Model
    &lt;ol&gt;
      &lt;li&gt;Each time a new item (including those periodically produced by the Clock) enters the engine through the Receiver&lt;/li&gt;
      &lt;li&gt;Evaluates all the rules currently present in the Rules store to find those whose condition part is true.&lt;/li&gt;
      &lt;li&gt;At the end of this phase we have a set of rules that have to be executed.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Processing Model
    &lt;ul&gt;
      &lt;li&gt;Together with the last information item entering the Decider, the set of deployed rules, and the information stored in the History and in the Knowledge Base, three additional concepts concur at uniquely determining the output of a single detection- production cycle: the selection, consumption, and load shedding policies adopted by the system.&lt;/li&gt;
      &lt;li&gt;some systems offer a programmable policy, by including special language constructs that enable users to decide, often rule by rule, if they have to fire once or more than once at each detection-production cycle, and in the former case, which elements have to be actually selected among the different possible combinations. &lt;/li&gt;
      &lt;li&gt;Load shedding. Load shedding is a technique adopted by some IFP systems to deal with bursty inputs. It can be described as an automatic drop of information items when the input rate becomes too high for the processing capabilities of the engine.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deployment Model&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;A networked IFP engine focuses on minimizing network usage by dispersing processors over a wide area network, with the goal of &lt;code&gt;processing information as close as possible to the sources&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;In summary, in their seek for better scalability, clustered and networked engines focus on different aspects: the former on increasing the available processing power by sharing the workload among a set of well connected machines, the latter on minimizing bandwidth usage by processing information as close as possible to the sources.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Interaction Model 
    &lt;ul&gt;
      &lt;li&gt;In a pull observation model, the IFP engine is the initiator of the interaction to bring information from sources to the engine; otherwise we have a push observation model.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data Model
    &lt;ul&gt;
      &lt;li&gt;Former manipulate generic data items&lt;/li&gt;
      &lt;li&gt;While the latter manipulates event notifications&lt;/li&gt;
      &lt;li&gt;In many IFP scenarios, in fact, information received from sources has an associated degree of uncertainty. As an example, if sources were only able to provide rounded data [Wasserkrug et al. 2008], the system could associate such data with a level of uncertainty instead of accepting it as a precise information.&lt;/li&gt;
      &lt;li&gt;Engines allow different types of information items in the same flow.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Time Model&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;With the term time model we refer to the relationship between the information items flowing into the IFP engine and the passing of time. More precisely, we refer to the ability of the IFP system of associating some kind of happened-before relationship to information items.&lt;/li&gt;
      &lt;li&gt;There is the case of systems that associate items with an interval, i.e., two timestamps taken from a global time, usually representing: the time when the related event started, the time when it ended. In this case, depending on the semantics associated with intervals, a total or a partial ordering among items can be defined.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rule Model&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Rules are much more complex entities than data. Looking at existing systems we can find many different approaches to represent rules, which depend on the adopted rule language. However, we can roughly classify them in two macro classes: transforming rules and detecting rules.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Language Model
    &lt;ul&gt;
      &lt;li&gt;It is worth mentioning that existing systems sometime allow users to express rules using more than one paradigm. For example, many commercial systems offer both a declarative language for rule creation, and a graphical tool for connecting defined rules in an imperative way. Moreover, some existing declarative languages embed simple operators for pattern detection, blurring the distinction between transform- ing and detecting languages.&lt;/li&gt;
      &lt;li&gt;SQL&lt;/li&gt;
      &lt;li&gt;Available Operators&lt;/li&gt;
      &lt;li&gt;Logistic Operators &lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;COMMAND ( A &amp;amp;&amp;amp; B, A&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;B)&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-4&quot;&gt;Section 4&lt;/h4&gt;

&lt;p&gt;We use this framework in Section 4 to describe and compare the state of the art in the field.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In the following we use the concepts introduced in Section 3 to present and classify existing IFP systems. We provide a brief description of each system and summarize its characteristics by compiling four tables.&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Table I focuses on the functional and processing models of each system: it shows if a system includes the Clock (i.e., it supports periodic processing) and the Knowl- edge Base, and if the maximum size of the sequences (Seq) that the Decider sends to the Producer is bounded or unbounded, given the set of deployed rules. Then, it analyzes if information items produced by fired rules may re-enter the system (recursion), and if the rule set can be changed by fired actions at run-time. Fi- nally, it presents the processing model of each system, by showing its selection, consumption, and load shedding policies.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Table II focuses on the deployment and interaction models, by showing the type of deployment supported by each system, and the interaction styles allowed in the observation, notification, and forwarding models.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Table III focuses on the data, time, and rule models, presenting the nature of the items processed by each systems (generic data or event notifications), the format of data, the support for data uncertainty, and the nature of flows (homogeneous or heterogeneous). It also introduces how the notion of time is captured and rep- resented by each system, the type of rules adopted, and the possibility to define probabilistic rules.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Finally, Table IV focuses on the language adopted by each system, by listing its type and the set of operators available.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Active databases&lt;/li&gt;
  &lt;li&gt;Data Stream Management Systems
    &lt;ul&gt;
      &lt;li&gt;Usually, these systems are designed for application domains in which the timeliness requirement is less critical, like for example Internet updates monitoring. On the contrary, all remaining systems are heavily tailored for the processing of high rate streams.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Commercial Systems
    &lt;ul&gt;
      &lt;li&gt;The platform is designed to scale by exploiting multiple cores on a single ma- chine or multiple machines in a clustered environment. &lt;/li&gt;
      &lt;li&gt;Aleri Streaming Platform.&lt;/li&gt;
      &lt;li&gt;Coral8 CEP Engine.&lt;/li&gt;
      &lt;li&gt;StreamBase. &lt;/li&gt;
      &lt;li&gt;Oracle CEP. &lt;/li&gt;
      &lt;li&gt;Esper.&lt;/li&gt;
      &lt;li&gt;Tibco Business Events.&lt;/li&gt;
      &lt;li&gt;IBM System S. &lt;/li&gt;
      &lt;li&gt;Other commercial systems. &lt;/li&gt;
      &lt;li&gt;IBM WebSphere Business Events.&lt;/li&gt;
      &lt;li&gt;Event Zero.&lt;/li&gt;
      &lt;li&gt;Progress Apama Event Processing Platform.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-5&quot;&gt;Section 5&lt;/h4&gt;

&lt;p&gt;Discussing the results of such classification in Section 5. &lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-6&quot;&gt;Section 6&lt;/h4&gt;

&lt;p&gt;Finally, Section 6 reviews related work, while Section 7 provides some conclusive remarks and a list of open issues.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In this section we briefly discuss the results of on-going or past research which aims at providing a more complete understanding of the IFP domain. In particular we cover four different aspects: &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;we present work that studies general mechanisms for IFP; &lt;/li&gt;
  &lt;li&gt;we review specific models used to describe various classes of systems, or to address single issues; &lt;/li&gt;
  &lt;li&gt;we provide an overview of systems presenting similarities with IFP systems; &lt;/li&gt;
  &lt;li&gt;we discuss existing attempts to create a standard for the IFP domain.&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Many researchers focused on developing general mechanisms for IFP by studying (i) rule processing strategies, (ii) operator placement and load balancing algorithms, (iii) communication protocols for distributed rule processing, (iv) techniques to provide adequate levels of QoS, and (v) mechanisms for high availability and fault tolerance.&lt;/li&gt;
  &lt;li&gt;In distributed scenarios it is of primary importance to define efficient communica- tion strategies between the different actors (sources, processors, and sinks).&lt;/li&gt;
  &lt;li&gt;Different contributions, primarily from people working on stream processing, fo- cused on the problem of bursty arrival of data &lt;/li&gt;
  &lt;li&gt;Recently, a few works coming from the event-based community&lt;/li&gt;
  &lt;li&gt;Finally, a few works have focused on high-availability and fault tolerance for dis- tributed stream processing. &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;other-models&quot;&gt;Other Models&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;As we have seen, IFP is a large domain, including many systems. Although the literature misses a unifying model, which is able to capture and classify all existing works, various contributions are worth mentioning. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;System Models. 
    &lt;ul&gt;
      &lt;li&gt;As described in Section 2, two main models for IFP have emerged, one coming from the database community and one coming from the event- processing community.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Models for Single Aspects of IFP.
    &lt;ul&gt;
      &lt;li&gt;A relevant part of our classification focuses on the data representations and rule definition languages adopted by IFP systems, and on the underlying time model assumed for processing. &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Related Systems
    &lt;ul&gt;
      &lt;li&gt;Besides the systems described in Section 4, other tools exist, which share many similarities with IFP systems.&lt;/li&gt;
      &lt;li&gt;Runtime Verification Tools.&lt;/li&gt;
      &lt;li&gt;Runtime Monitoring Tools.&lt;/li&gt;
      &lt;li&gt;Scalable Distributed Information Management Systems. &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;online-machine-learning&quot;&gt;Online Machine Learning&lt;/h4&gt;
</content>
 </entry>
 
 <entry>
   <title>Install Hadoop for Computer Lab</title>
   <link href="http://zhou-dong.github.io/2015/10/07/install-hadoop"/>
   <updated>2015-10-07T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/10/07/install-hadoop</id>
   <content type="html">&lt;p&gt;Universal USB Installer&lt;/p&gt;

&lt;p&gt;http://www.pendrivelinux.com/universal-usb-installer-easy-as-1-2-3/#button&lt;/p&gt;

&lt;p&gt;Set up hadoop Reference&lt;/p&gt;

&lt;p&gt;http://tashan10.com/yong-dockerda-jian-hadoopwei-fen-bu-shi-ji-qun/&lt;/p&gt;

&lt;p&gt;Operating System:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ubuntu 14.04.1 LTS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;User:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Username: hadoop&lt;/li&gt;
  &lt;li&gt;Password: hadoop&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ip Address: 10.33.1.74&lt;/p&gt;

&lt;h4 id=&quot;configurate-ubuntu&quot;&gt;Configurate Ubuntu&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Install SSH
    &lt;ul&gt;
      &lt;li&gt;sudo apt-get install openssh-server&lt;/li&gt;
      &lt;li&gt;sudo apt-get install openssh-client&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Update
    &lt;ul&gt;
      &lt;li&gt;sudo apt-get update&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Update vim
    &lt;ul&gt;
      &lt;li&gt;sudo apt-get install vim&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Create folder of workspace
    &lt;ul&gt;
      &lt;li&gt;mkdir workspace&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Install Java
    &lt;ol&gt;
      &lt;li&gt;Download JDK
        &lt;ul&gt;
          &lt;li&gt;http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;copy to ubuntu
        &lt;ul&gt;
          &lt;li&gt;scp ~/Downloads/jdk-8u60-linux-x64.gz hadoop@10.33.1.74:/home/hadoop/workspace/download/.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;upzip jdk
        &lt;ul&gt;
          &lt;li&gt;tar -xzvf jdk-8u60-linux-x64.gz&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;config jdk environment
        &lt;ul&gt;
          &lt;li&gt;vim ~/.profile&lt;/li&gt;
          &lt;li&gt;export JAVA_HOME=/home/hadoop/workspace/jdk1.8.0_60&lt;/li&gt;
          &lt;li&gt;export PATH=$JAVA_HOME/bin:$PATH&lt;/li&gt;
          &lt;li&gt;source ~/.profile&lt;/li&gt;
          &lt;li&gt;java -version&lt;/li&gt;
          &lt;li&gt;javac -version&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;install-docker&quot;&gt;Install Docker&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;sudo apt-get install apt-transport-https&lt;/li&gt;
  &lt;li&gt;sudo apt-key adv &lt;code&gt;--keyserver&lt;/code&gt; hkp://keyserver.ubuntu.com:80 &lt;code&gt;--recv-keys&lt;/code&gt; 36A1D7869245C8950F966E92D8576A8BA88D21E9&lt;/li&gt;
  &lt;li&gt;sudo bash -c “echo deb https://get.docker.io/ubuntu docker main &amp;gt; /etc/apt/sources.list.d/docker.list”&lt;/li&gt;
  &lt;li&gt;sudo apt-get update&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;sudo apt-get install lxc-docker&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;sudo service docker start&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;add-user-into-docker&quot;&gt;Add user into docker&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Create a docker group
    &lt;ul&gt;
      &lt;li&gt;sudo groupadd docker&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adding user &lt;code&gt;hadoop&lt;/code&gt; to group docker
    &lt;ul&gt;
      &lt;li&gt;sudo gpasswd -a hadoop docker&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Restart Docker
    &lt;ul&gt;
      &lt;li&gt;sudo service docker restart&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Test Docker
    &lt;ul&gt;
      &lt;li&gt;docker version&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;docker-common-command&quot;&gt;Docker common command&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;docker images：列出所有镜像(images)&lt;/li&gt;
  &lt;li&gt;docker ps：列出正在运行的(容器)containers&lt;/li&gt;
  &lt;li&gt;docker ps -a: 列出所有的容器，包括不运行的容器。&lt;/li&gt;
  &lt;li&gt;docker pull ubuntu：下载镜像&lt;/li&gt;
  &lt;li&gt;docker run -i -t ubuntu /bin/bash：运行ubuntu镜像&lt;/li&gt;
  &lt;li&gt;docker restart master: 重启已经停止的container，但start不能够再指定容器启动时运行的指令，因为docker只能有一个前台进程。&lt;/li&gt;
  &lt;li&gt;docker commit 3a09b2588478 ubuntu:mynewimage：提交你的变更，并且把容器保存成Tag为mynewimage的新的ubuntu镜像.(注意，这里提交只是提交到本地仓库，类似git)&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;download-ubuntu-mirror-by-docker&quot;&gt;Download ubuntu mirror by docker&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;docker pull ubuntu:14.04&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;start-ubuntu-in-docker&quot;&gt;start ubuntu in docker&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;docker run -ti ubuntu&lt;/li&gt;
  &lt;li&gt;docker run -ti ubuntu:14.04&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;test-docker-then-exit&quot;&gt;Test docker then exit&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;docker run ubuntu /bin/echo ‘Hello world’&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;install-ssh-in-docker&quot;&gt;Install SSH In docker&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;sudo apt-get install openssh-server&lt;/li&gt;
  &lt;li&gt;sudo apt-get install openssh-client&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;install-java-in-docker&quot;&gt;Install Java In docker&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;vim ~/.bashrc&lt;/li&gt;
  &lt;li&gt;export JAVA_HOME=/workspace/jdk1.8.0_60&lt;/li&gt;
  &lt;li&gt;export PATH=$JAVA_HOME/bin:$PATH&lt;/li&gt;
  &lt;li&gt;source ~/.bashrc&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;commit-change-of-docker&quot;&gt;Commit change of docker&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;docker commit -m “java install” 122a2cecdd14 ubuntu:java&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;install-hadoop&quot;&gt;Install Hadoop&lt;/h4&gt;

&lt;h5 id=&quot;install-wget&quot;&gt;Install wget&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;apt-get install wget&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;download-hadoop&quot;&gt;Download Hadoop&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;mkdir -p soft/apache/hadoop&lt;/li&gt;
  &lt;li&gt;cd /root/soft/apache/hadoop&lt;/li&gt;
  &lt;li&gt;wget http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;config-hadoop-in-bashrc&quot;&gt;Config Hadoop in ./bashrc&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;export HADOOP_HOME=/root/soft/apache/hadoop/hadoop-2.6.0&lt;/li&gt;
  &lt;li&gt;export HADOOP_CONFIG_HOME=$HADOOP_HOME/etc/hadoop&lt;/li&gt;
  &lt;li&gt;export PATH=$PATH:$HADOOP_HOME/bin&lt;/li&gt;
  &lt;li&gt;export PATH=$PATH:$HADOOP_HOME/sbin&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;config-hadoop&quot;&gt;Config Hadoop&lt;/h5&gt;

&lt;ol&gt;
  &lt;li&gt;Create three folder
    &lt;ul&gt;
      &lt;li&gt;mkdir tmp&lt;/li&gt;
      &lt;li&gt;mkdir namenode&lt;/li&gt;
      &lt;li&gt;mkdir datanode&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Config
    &lt;ul&gt;
      &lt;li&gt;cd $HADOOP_CONFIG_HOME/&lt;/li&gt;
      &lt;li&gt;cp mapred-site.xml.template mapred-site.xml&lt;/li&gt;
      &lt;li&gt;.core-site.xml&lt;/li&gt;
      &lt;li&gt;.hdfs-site.xml&lt;/li&gt;
      &lt;li&gt;.mapred-site.xml&lt;/li&gt;
      &lt;li&gt;hadoop-env.sh (export JAVA_HOME=/workspace/jdk1.8.0_60)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Format namenode
    &lt;ul&gt;
      &lt;li&gt;hadoop namenode -format&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Install ssh
    &lt;ul&gt;
      &lt;li&gt;apt-get install ssh&lt;/li&gt;
      &lt;li&gt;/var/run/sshd&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Add ssh to barshrc
    &lt;ul&gt;
      &lt;li&gt;vim ~/.bashrc&lt;/li&gt;
      &lt;li&gt;/usr/sbin/sshd&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Create key
    &lt;ul&gt;
      &lt;li&gt;ssh-keygen -t rsa -P ‘’ -f ~/.ssh/id_dsa&lt;/li&gt;
      &lt;li&gt;cd .ssh&lt;/li&gt;
      &lt;li&gt;cat id_dsa.pub » authorized_keys&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;config-master-and-slave&quot;&gt;Config Master and Slave&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Start up all the master and slave
    &lt;ul&gt;
      &lt;li&gt;docker run -ti -h master ubuntu&lt;/li&gt;
      &lt;li&gt;docker run -ti -h slave1 ubuntu&lt;/li&gt;
      &lt;li&gt;docker run -ti -h slave2 ubuntu&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;check the ip of the machine
    &lt;ul&gt;
      &lt;li&gt;ifconfig&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;config host
    &lt;ul&gt;
      &lt;li&gt;vim /etc/hosts&lt;/li&gt;
      &lt;li&gt;172.17.0.15 master&lt;/li&gt;
      &lt;li&gt;172.17.0.16 slave1&lt;/li&gt;
      &lt;li&gt;172.17.0.17 slave2&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Config slave
    &lt;ol&gt;
      &lt;li&gt;go to master machine&lt;/li&gt;
      &lt;li&gt;cd $HADOOP_CONFIG_HOME/&lt;/li&gt;
      &lt;li&gt;vim slaves
        &lt;ul&gt;
          &lt;li&gt;slave1&lt;/li&gt;
          &lt;li&gt;slave2&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Start Hadoop
    &lt;ul&gt;
      &lt;li&gt;start-dfs.sh&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Check run status in master
    &lt;ul&gt;
      &lt;li&gt;hdfs dfsadmin -report&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;stop hadoop
    &lt;ul&gt;
      &lt;li&gt;stop-dfs.sh&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Start stop docker
    &lt;ul&gt;
      &lt;li&gt;docker start bob_the_container&lt;/li&gt;
      &lt;li&gt;docker start aa3f365f0f4e&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Start demaon docker
    &lt;ul&gt;
      &lt;li&gt;docker run -ti -d ubuntu&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;section&quot;&gt;运行镜像，并让生成的容器一直在后台运行：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;第一个-d表示让容器在后台运行&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;末尾的-D表示启动ssh的daemon模式，不然容器启动后立刻就变为停止状态了&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;docker run -d NAME/VERSION /etc/init.d/ssh start -D&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ssh&quot;&gt;现在，便可以ssh登陆容器了。&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;查询容器IP
    &lt;ul&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;docker inspect CONTAINER_ID&lt;/td&gt;
              &lt;td&gt;grep IP&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;登入
    &lt;ul&gt;
      &lt;li&gt;ssh root@IP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h5 id=&quot;start-docker-as-deman&quot;&gt;start docker as deman&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;docker run -d &lt;code&gt;--name master&lt;/code&gt; &lt;code&gt;-h master&lt;/code&gt; ubuntu /etc/init.d/ssh start -D&lt;/li&gt;
  &lt;li&gt;docker run -d &lt;code&gt;--name slave1&lt;/code&gt; &lt;code&gt;-h slave1&lt;/code&gt; ubuntu /etc/init.d/ssh start -D&lt;/li&gt;
  &lt;li&gt;docker run -d &lt;code&gt;--name slave2&lt;/code&gt; &lt;code&gt;-h slave2&lt;/code&gt; ubuntu /etc/init.d/ssh start -D&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;find-ip-of-docker&quot;&gt;Find IP of docker&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;docker inspect master&lt;/td&gt;
          &lt;td&gt;grep IP&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;docker inspect slave1&lt;/td&gt;
          &lt;td&gt;grep IP&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;docker inspect slave2&lt;/td&gt;
          &lt;td&gt;grep IP&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;ssh root@172.17.0.29&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;add-user-into-server&quot;&gt;add user into server&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;sudo useradd userone&lt;/li&gt;
  &lt;li&gt;sudo passwd userone&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;create-foler-of-userone&quot;&gt;create foler of userone&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;sudo mkdir /home/userone&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;sudo useradd -d /home/usertwo -m usertwo&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;add-user-to-docker-group&quot;&gt;Add user to docker group&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;sudo gpasswd -a userone docker&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;password-of-user&quot;&gt;password of user&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;userone 157432&lt;/li&gt;
  &lt;li&gt;usertwo 17728&lt;/li&gt;
  &lt;li&gt;userthree 15062&lt;/li&gt;
  &lt;li&gt;userfour 17743&lt;/li&gt;
  &lt;li&gt;userfive 96574&lt;/li&gt;
  &lt;li&gt;usersix 45732&lt;/li&gt;
  &lt;li&gt;userseven 66843&lt;/li&gt;
  &lt;li&gt;usereight 57832&lt;/li&gt;
  &lt;li&gt;usernine 44573&lt;/li&gt;
  &lt;li&gt;userten 35762&lt;/li&gt;
  &lt;li&gt;usereleven 24876&lt;/li&gt;
  &lt;li&gt;usertwelve 567432&lt;/li&gt;
  &lt;li&gt;userthirteen 13249&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h5 id=&quot;virtual-machine-ip-is&quot;&gt;Virtual Machine IP is:&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;master: 172.17.0.33&lt;/li&gt;
  &lt;li&gt;slave1: 172.17.0.34&lt;/li&gt;
  &lt;li&gt;slave2: 172.17.0.35&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;/home/hadoop/workspace/authorized_keyspub&lt;/p&gt;

&lt;p&gt;使用Eclipse编译运行MapReduce程序 Hadoop2.6.0/Ubuntu&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;http://www.powerxing.com/hadoop-build-project-using-eclipse/&lt;/li&gt;
  &lt;li&gt;https://github.com/winghc/hadoop2x-eclipse-plugin&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Add file from disk to HDFS, then run map-reduce on Hadoop&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;hadoop fs -mkdir /user&lt;/li&gt;
  &lt;li&gt;hadoop fs -mkdir /user/hadoop&lt;/li&gt;
  &lt;li&gt;hadoop fs -ls /user/hadoop&lt;/li&gt;
  &lt;li&gt;hadoop fs -put shakes.txt /user/hadoop/shakes.txt&lt;/li&gt;
  &lt;li&gt;hadoop jar wordcount.jar org.dongzhou.hadoop.WordCount /user/hadoop/shakes.txt /user/hadoop/shakeResult&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;hadoop fs -mkdir /user/mingyang&lt;/li&gt;
  &lt;li&gt;hadoop fs -put shakes.txt /user/mingyang/&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hadoop jar wordcount.jar org.mingyang.hadoop.WordCount /user/mingyang/shakes.txt /user/dongxu/shakeResult&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;hadoop fs -mkdir /user/dongxu  &lt;/li&gt;
  &lt;li&gt;hadoop fs -put shakes.txt /user/dongxu/&lt;/li&gt;
  &lt;li&gt;hadoop jar wordcount.jar com.dongxu.hadoop.WordCount /user/dongxu/shakes.txt /user/dongxu/shakeResult&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;complie java file use command line&lt;/p&gt;

&lt;p&gt;http://www.cnblogs.com/myresearch/p/mapreduce-compile-jar-run.html&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$HADOOP_HOME/share/hadoop/common/hadoop-common-2.6.0.jar&lt;/li&gt;
  &lt;li&gt;$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar&lt;/li&gt;
  &lt;li&gt;$HADOOP_HOME/share/hadoop/common/lib/commons-cli-1.2.jar&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;vim /etc/profile&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;export CLASSPATH=”$HADOOP_HOME/home/hadoop/opt/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:$HADOOP_HOME/home/hadoop/opt/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:$HADOOP_HOME/home/hadoop/opt/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:$CLASSPATH”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;complile&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;javac WordCount.java&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;makr jar file&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;jar -cvf WordCount.jar ./WordCount*.class&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Data Stream Analyze</title>
   <link href="http://zhou-dong.github.io/2015/10/05/data-stream"/>
   <updated>2015-10-05T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/10/05/data-stream</id>
   <content type="html">&lt;h4 id=&quot;section&quot;&gt;流式计算的特殊性:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;数据实时到达;&lt;/li&gt;
  &lt;li&gt;数据到达次序独立,不受应用系统所控制;&lt;/li&gt;
  &lt;li&gt;数据规模宏大且不能预知其最大值;&lt;/li&gt;
  &lt;li&gt;数据一经处理,除非特意保存,否则不能被再次取出处理,或者再次提取数据代价昂贵(one pass).&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-1&quot;&gt;我们觉得流计算的技术难点不是算法：&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;而是怎样在低成本、高可用的环境下快速的处理和存储流数据。&lt;/li&gt;
  &lt;li&gt;在不同的应用场景之下，使用一些经过优化以后的数据挖掘算法，或者普通的算法。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;首先所有的算法，只要效率够高，都可以使用在流计算中。&lt;/li&gt;
  &lt;li&gt;而真正的问题是分布式该工程的实现上。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;算法的关键在于设计一个远小于数据集规模的结构,从而可以在内存中处理数据.相对于数据流的规模而言,这种名为概要数据结构(synopsis data structure)的规模至多应该是次线性的.即如果流的长度为 N,则概要数据结构大小不超过 O(polylog(N)),并且处理流上每一组数据的时间不超过 O(polylog(N)).&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;可以用到一些方法或者是指导思想:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Histogram
    &lt;ul&gt;
      &lt;li&gt;直方图技术就是将一个大数据集划分为很多个连续的桶(bucket),也就是小数据集,每个桶都由一个数字来代表其特征&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Sampling
    &lt;ul&gt;
      &lt;li&gt;抽样方法也是生成概要数据结构的常用手段.它从数据集中抽取小部分数据代表整个数据集,并根据该样本集合获得查询结果.抽样方法可以分成均匀抽样(uniform sampling)和偏倚抽样(biased sampling)两种.&lt;/li&gt;
      &lt;li&gt;(Wavelet)小波分析方法是一种通用的数字信号处理技术.类似于傅立叶变换,小波分析根据输入的模拟量,变换成一系列的小波参数,并且少数几个小波参数就拥有大部分能量&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hash Method
    &lt;ul&gt;
      &lt;li&gt;Bloom Filter&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-3&quot;&gt;科研界的成果：&lt;/h4&gt;

&lt;p&gt;Data stream managerment system(DSMS)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;STREAM [Stanford University] http://infolab.stanford.edu/stream/&lt;/li&gt;
  &lt;li&gt;Telegraph [berkeley] http://telegraph.cs.berkeley.edu/&lt;/li&gt;
  &lt;li&gt;Aurora [Brown University] http://cs.brown.edu/research/aurora/&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-4&quot;&gt;工业界的成果：&lt;/h4&gt;

&lt;p&gt;PlatForm for Data Strem:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Apache Storm https://storm.apache.org/
    &lt;ul&gt;
      &lt;li&gt;在Storm中，先要设计一个用于实时计算的图状结构，我们称之为拓扑（topology）。这个拓扑将会被提交给集群，由集群中的主控节点（master node）分发代码，将任务分配给工作节点（worker node）执行。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Apache Spark https://spark.apache.org/streaming/
    &lt;ul&gt;
      &lt;li&gt;Spark Streaming是核心Spark API的一个扩展，它并不会像Storm那样一次一个地处理数据流，而是在处理前按时间间隔预先将其切分为一段一段的批处理作业。Spark针对持续性数据流的抽象称为DStream（DiscretizedStream），一个DStream是一个微批处理（micro-batching）的RDD（弹性分布式数据集）；而RDD则是一种分布式数据集，能够以两种方式并行运作，分别是任意函数和滑动窗口数据的转换。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Apache Samza http://samza.apache.org/
    &lt;ul&gt;
      &lt;li&gt;Samza处理数据流时，会分别按次处理每条收到的消息。Samza的流单位既不是元组，也不是Dstream，而是一条条消息。在Samza中，数据流被切分开来，每个部分都由一组只读消息的有序数列构成，而这些消息每条都有一个特定的ID（offset）。该系统还支持批处理，即逐次处理同一个数据流分区的多条消息。Samza的执行与数据流模块都是可插拔式的，尽管Samza的特色是依赖Hadoop的Yarn（另一种资源调度器）和Apache Kafka。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-5&quot;&gt;流式应用的相关组件&lt;/h4&gt;

&lt;p&gt;Distributed Queue:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Apache Kafka http://kafka.apache.org/&lt;/li&gt;
  &lt;li&gt;Beanstalkd http://kr.github.io/beanstalkd/&lt;/li&gt;
  &lt;li&gt;Apache Flume https://flume.apache.org/&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Reference&lt;/p&gt;

&lt;p&gt;Finding frequent items in data streams
http://www.sciencedirect.com/science/article/pii/S0304397503004006&lt;/p&gt;

&lt;p&gt;Counting Distinct Elements in a Data Stream
http://link.springer.com/chapter/10.1007/3-540-45726-7_1&lt;/p&gt;

&lt;p&gt;http://www.jos.org.cn/ch/reader/create_pdf.aspx?file_no=20040809&amp;amp;journal_id=jos&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Notes of Android</title>
   <link href="http://zhou-dong.github.io/2015/08/26/android-study"/>
   <updated>2015-08-26T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/08/26/android-study</id>
   <content type="html">
&lt;p&gt;Activity: Like JavaScript&lt;/p&gt;

&lt;p&gt;Layout: Like HTML&lt;/p&gt;

&lt;p&gt;DDMS: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Log the monitor debug info into Eclipse&lt;/li&gt;
  &lt;li&gt;Send message into monitor&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;

public static void main(String args[]){
    System.out.println(&quot;Hello world!&quot;) ;
}

&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Notes of Maching Learning</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/08/14/notes-of-machine-learning"/>
   <updated>2015-08-14T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/08/14/notes-of-machine-learning</id>
   <content type="html">&lt;ol&gt;
  &lt;li&gt;Linear Regression
    &lt;ul&gt;
      &lt;li&gt;Gradient Descent&lt;/li&gt;
      &lt;li&gt;Normal Equation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Logstic Regression&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在计算logistic Regression的cost function的时候，需要使用极大似然&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Regularzation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;参数越小，cursive就越平滑
software: octave&lt;/p&gt;

&lt;p&gt;为了梯度下降的效率更高，可以按比例的归一化数据
logstic regression是分类算法，而不是回归算法。
mohammed.alsafi313@gmail.com&lt;/p&gt;

&lt;p&gt;Aug 25, 2015&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;神经网络
    &lt;ul&gt;
      &lt;li&gt;分层次逐渐求解&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;神经网络的应用&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;神经网路：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;逐层的求解&lt;/li&gt;
  &lt;li&gt;计算出cost function，是训练最优值，
    &lt;ul&gt;
      &lt;li&gt;可以使用逻辑回归、&lt;/li&gt;
      &lt;li&gt;梯度下降&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;使用back propagation，来计算梯度的值&lt;/li&gt;
  &lt;li&gt;最常用的神经网络是三层神经网络：
    &lt;ol&gt;
      &lt;li&gt;输入层&lt;/li&gt;
      &lt;li&gt;隐含层&lt;/li&gt;
      &lt;li&gt;输出层&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;如果有多个“隐含层”，那各个隐含层的变量数目相同。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Support Vector machine&lt;/li&gt;
  &lt;li&gt;Nerual Networks&lt;/li&gt;
  &lt;li&gt;K-Means&lt;/li&gt;
  &lt;li&gt;DIMENSIONALITY REDUCTION
    &lt;ul&gt;
      &lt;li&gt;Principal Component Analysis(PCA)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;recommendation system
    &lt;ul&gt;
      &lt;li&gt;content base recommendation system&lt;/li&gt;
      &lt;li&gt;collaborative filtering&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Online Learning&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Map reduce&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Photo OCR&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pipline in machine learning&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;finish the course&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;255 - 256&lt;/p&gt;

&lt;p&gt;13.14&lt;/p&gt;

&lt;p&gt;A and B&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPI (cycle per instruction)&lt;/li&gt;
  &lt;li&gt;MIPS (millions of instructions per second)&lt;/li&gt;
  &lt;li&gt;Throughput&lt;/li&gt;
  &lt;li&gt;artifical data synthesis&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>CS6649</title>
   <link href="http://zhou-dong.github.io/2015/08/12/cs6649"/>
   <updated>2015-08-12T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/08/12/cs6649</id>
   <content type="html">&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Cloud assisted delivering of health services over Health IoT&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sofeware defined virtual caching machanism over NDN&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Creation of Social network of IoTs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Traffic aware rescource allocation and scheduring over GEO distribution cloud.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Dashboard
- analysis&lt;/p&gt;

&lt;p&gt;Application 场景&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;interface
    &lt;ul&gt;
      &lt;li&gt;在android&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分析场景&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;删除一些属性，加一些属性&lt;/p&gt;

&lt;p&gt;增加功能&lt;/p&gt;

&lt;p&gt;这些东西的性能&lt;/p&gt;

&lt;p&gt;查一下，哪些watch比较好&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Use node.js to rewrite totem project</title>
   <link href="http://zhou-dong.github.io/2015/08/11/use-node-to-write-totem"/>
   <updated>2015-08-11T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/08/11/use-node-to-write-totem</id>
   <content type="html">&lt;p&gt;I think may be it is the time to use the Node.js to rewrite the core of totem project.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;I should name my project.&lt;/li&gt;
  &lt;li&gt;Create a prototype of the totem App&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;pre:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Study the node.js again&lt;/li&gt;
  &lt;li&gt;To know what is the express of nodejs&lt;/li&gt;
  &lt;li&gt;To know what is grunt.&lt;/li&gt;
  &lt;li&gt;to know how to export and require node module.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Meeting online One</title>
   <link href="http://zhou-dong.github.io/2015/07/11/kumar-meeting"/>
   <updated>2015-07-11T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/07/11/kumar-meeting</id>
   <content type="html">
&lt;ol&gt;
  &lt;li&gt;Dong’s Question: Do I need have the right to use the AWS of PHINet application?
    &lt;ul&gt;
      &lt;li&gt;Richard suggested Dong should has him own AWS test account.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Richard Question: What is the business model of app?&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Rechard suggest: First sencor is free, the other sencors are charged.&lt;/li&gt;
      &lt;li&gt;Kumar suggest: Like Facebook:  don’t pay for application but  pay for the analyze.&lt;/li&gt;
      &lt;li&gt;Dong suggest: Everythings is free, and First thing is make our project useful and let people like our app.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Doctor Kumar will introduce more people to our project, first is his elder cousin, who is working in AT&amp;amp;T and have more experience on bussiness.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;integate censor data first&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;precalcute first in the &lt;/p&gt;

&lt;p&gt;compress first
restruct work&lt;/p&gt;

&lt;p&gt;最长使用的数据&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>First Meeting</title>
   <link href="http://zhou-dong.github.io/2015/07/11/first-meeting"/>
   <updated>2015-07-11T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/07/11/first-meeting</id>
   <content type="html">&lt;h1 id=&quot;first-meeing-of-phinet&quot;&gt;First meeing of PHINet&lt;/h1&gt;

&lt;p&gt;Date 07/11/2015&lt;/p&gt;

&lt;p&gt;People: 
- Kumar
- Richard
- Dong&lt;/p&gt;

&lt;h2 id=&quot;content&quot;&gt;Content:&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Dong’s Question: Do I need have the right to use the AWS of PHINet application?
    &lt;ul&gt;
      &lt;li&gt;Richard suggested: Dong should has him own AWS test account.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Richard Question: What is the business model of app?&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Rechard suggest: First censor is free, the other censors are charged.&lt;/li&gt;
      &lt;li&gt;Kumar suggest: Like Facebook:  don’t pay for application, but pay for the analyze.&lt;/li&gt;
      &lt;li&gt;Dong suggest: Everythings is free, and First thing is make our project useful and let people like our app.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Doctor Kumar will introduce more people to our project, first one is his elder cousin, who is working in AT&amp;amp;T and have more experience on bussiness.&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;More: Richard has sent me an email to suggest me start with let user to view their data on the website, I will do that first.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Test LateX</title>
   <link href="http://zhou-dong.github.io/2015/07/05/test"/>
   <updated>2015-07-05T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/07/05/test</id>
   <content type="html">
&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q1: Solve \: the \:following\:linear\:programming\:problem:\\ \textbf{Min}\:\: f(x_1,x_2):\:\:x_1+x_2\\ \textbf{Subject to:}\: 3x_1-x_2\leq3\\ x_1+2x_2\leq5\\ x_1+x_2\leq4\\ x_1\ge0; x_2\: unrestricted\: in\:sign. \:\:\:\:\:\:\:\:\:\:\:\:\textbf{(8)}&lt;/script&gt;

&lt;p&gt;Transportation&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;formula&lt;/li&gt;
  &lt;li&gt;matrix&lt;/li&gt;
  &lt;li&gt;visualization&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;Intergrate with apple watch&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Support XMPP&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Find other imformation for client(like something of watch) &lt;/li&gt;
  &lt;li&gt;Add UDp or TCP/IP&lt;/li&gt;
  &lt;li&gt;NDN&lt;/li&gt;
  &lt;li&gt;Naming scheme(extend naming scheme)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;moto 360&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;suman.kumaar@gmail.com&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>CS6648 TBAA Notes Optimization Modeling</title>
   <link href="http://zhou-dong.github.io/2015/06/24/cs-6648"/>
   <updated>2015-06-24T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/06/24/cs-6648</id>
   <content type="html">
&lt;ol&gt;
  &lt;li&gt;LaTeX
    &lt;ul&gt;
      &lt;li&gt;Download&lt;a href=&quot;http://miktex.org/&quot;&gt;MiKTeX&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;or use Sublime to write LaTex&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Download&lt;a href=&quot;https://tug.org/mactex/&quot;&gt;MacTex&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Travelling_salesman_problem&quot;&gt;Travelling salesman problem&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Linear Programming&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;install Latex In Mac with Sublime text 2&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Down Sublime text 2&lt;/li&gt;
  &lt;li&gt;install &lt;a href=&quot;https://packagecontrol.io/installation#st2&quot;&gt;Package control for sublmit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Command+Shift+P to install LaTexTools&lt;/li&gt;
  &lt;li&gt;download skim for look pdf for sublime&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;

x_1 + x_2 \le 3 \\

x_1 + x_2 + \theta_1 = 3 \\

2x_1 + x_2 + \theta_1 + A =  6 \\

2x_1 \ and \ x_2 slack variable \\

A \ artifical variable

&lt;/script&gt;

&lt;p&gt;NP-hard&lt;/p&gt;

&lt;p&gt;Row operation&lt;/p&gt;

&lt;p&gt;Rank of Matrix&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;

2^{n=3} = 8 \\

n_0, n_1, n_2 \\
0 \ 0 \ 0 \\
0 \ 0 \ 1 \\
0 \ 1 \ 0 \\
0 \ 1 \ 1 \\
1 \ 0 \ 0 \\
1 \ 0 \ 1 \\
1 \ 1 \ 0 \\
1 \ 1 \ 1 \\


&lt;/script&gt;
</content>
 </entry>
 
 <entry>
   <title>Javascript Notes</title>
   <link href="http://zhou-dong.github.io/javascript%20jquery/2015/05/29/js"/>
   <updated>2015-05-29T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/javascript%20jquery/2015/05/29/js</id>
   <content type="html">
&lt;p&gt;javascript:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ECMAscript&lt;/li&gt;
  &lt;li&gt;DOM&lt;/li&gt;
  &lt;li&gt;BOM&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;defer=’defer’: 立即下载，但是页面渲染完以后再执行
asyn=’asyn’: 立即下载，但是不阻断页面的渲染，也不能保证javascript的执行顺序&lt;/p&gt;

&lt;p&gt;JQuery&lt;/p&gt;

&lt;p&gt;Javascript原生的方法就是可以把function当做参数来传递，jquery继承了这个方式&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
$(document).ready(function(){
    $(&#39;div&#39;).click(function(){
        $(this).hover(
            function(){
                //do some thing
            };
            function(){
                //do some thing
            } ;
        );
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JQuery selector&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;原生的DOM对象直接用引号&lt;/li&gt;
  &lt;li&gt;. # 选择class和id&lt;/li&gt;
  &lt;li&gt;可以使用CSS的选择器&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;
var $p = $(&quot;p&quot;);
var $div = $(&#39;div&#39;);
var $ol = $(&#39;ol&#39;) ;
var $cls = $(&quot;.class-name&quot;) ;
var $id = $(&quot;#id-name&quot;);
var $name = $(&#39;input[name=name-attr]&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JQuery UI&lt;/p&gt;

&lt;p&gt;JQuery UI添加了各种动画效果的实现和更多的内置样式。&lt;/p&gt;

&lt;p&gt;JavaScript变量可以用来保存两种类型的值：基本类型和引用类型。&lt;/p&gt;

&lt;p&gt;基本类型：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Undefined&lt;/li&gt;
  &lt;li&gt;Null&lt;/li&gt;
  &lt;li&gt;Boolean&lt;/li&gt;
  &lt;li&gt;Number&lt;/li&gt;
  &lt;li&gt;String&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;基本类型在内存中占据固定大小的空间，因此会被保存在栈内存中&lt;/li&gt;
  &lt;li&gt;从一个变量向另一个变量复制基本类型的值，会创建这个值的一个副本&lt;/li&gt;
  &lt;li&gt;引用类型的值是对象，会保存在堆中&lt;/li&gt;
  &lt;li&gt;包含引用类型值的变量实际上包含的并不是对象本身，而是指向该对象的一个指针&lt;/li&gt;
  &lt;li&gt;从一个变量向另一个变量复制引用类型的值，复制的其实是指针，因此两个变量最终指向同一个对象&lt;/li&gt;
  &lt;li&gt;确定一个值是哪种基本类型可以使用typeof，而确定一个值是哪种引用类型可以使用instanceof&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JavaScript 可以使用变量来访问属性&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
    var propertyName = &quot;name&quot; ;
    console.log(person[propertyName]) ;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Function在javascript中也是一个对象，所以Function在Javascript中有了更多神奇的使用方法&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;function作为一个对象，可以作为属性，在其它对象之间传递&lt;/li&gt;
  &lt;li&gt;可以return function&lt;/li&gt;
  &lt;li&gt;javascript的function没有重载，因为后一个会替换前一个对象的引用&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在JavaScript中，Array有更多的内置方法，可以更加方便的操作array&lt;/p&gt;

&lt;p&gt;Global对象跟Java中的global对象是不一样的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Java中global对象是全局的父对象&lt;/li&gt;
  &lt;li&gt;而JavaScript中，global对象只是有别于其它对象的一个对象，所以不属于其它对象的属性，都属于global对象&lt;/li&gt;
  &lt;li&gt;在浏览器中，常常使用window对象来实现global对象&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在JavaScript中，也有针对基本类型的包装类型，包装类型在处理完操作以后，就会被释放&lt;/p&gt;

&lt;p&gt;eval() 是个特别强大的函数，会把里面的字符串当做javascript语法来处理，所以使用eval()时需要特别小心，防止被代码注入!&lt;/p&gt;

&lt;p&gt;越来越感觉到，JavaScript、Ruby这些语言比Java要更符合“万物皆对象！”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在Java中，有string、function、class这些东西都不放在heap中，而在“永久带”中&lt;/li&gt;
  &lt;li&gt;但是JavaScript中，向function、prototype，都是对象。（连构造函数本身也对对象）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JavaScript没有块级作用域的概念。如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
for (var i=0; i&amp;lt;10; i++){
    console.log(i);
}
console.log(i) //9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是可以使用另一种方法来模拟块级作用域&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
(function(){
    for (var i=0; i&amp;lt;10; i++){
        console.log(i)
    }
})() ;
console.log(i) //error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码的意思是：创建一个匿名函数，并且立即调用它。&lt;/p&gt;

&lt;p&gt;JavaScript的闭包真的是个比较有趣的概念！&lt;/p&gt;

&lt;p&gt;用了那么就的JSON，今天在明白了JSON的由来。&lt;/p&gt;

&lt;p&gt;JSON: (JavaScript object notation)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JSON的格式，就是javascript定义对象的格式&lt;/li&gt;
  &lt;li&gt;只是JSON对象的属性也在引号里面&lt;/li&gt;
  &lt;li&gt;所以在一开始的时候，才用eval()来解析json对象（会有安全问题，不建议使用）&lt;/li&gt;
  &lt;li&gt;使用JSON.stringify(object,”数组”/函数,”缩进”)来javascript对象转成成JSON对象&lt;/li&gt;
  &lt;li&gt;使用JSON.parse(object,函数) 来把JSON对象转换成javascript对象&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Statistics</title>
   <link href="http://zhou-dong.github.io/2015/05/28/statistics"/>
   <updated>2015-05-28T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/05/28/statistics</id>
   <content type="html">
&lt;h2 id=&quot;section&quot;&gt;统计学习方法笔记&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;统计学习方法概论&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;感知机&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;k邻近法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;朴素贝叶斯法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;决策树&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;逻辑斯蒂回归与最大熵模型&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;支持向量机&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;提升方法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;EM算法及其推广&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;隐含马尔科夫模型&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;条件随机场&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>HTML CSS Bootstrap</title>
   <link href="http://zhou-dong.github.io/2015/05/26/html-css"/>
   <updated>2015-05-26T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/05/26/html-css</id>
   <content type="html">
&lt;h4 id=&quot;bootstrap&quot;&gt;Bootstrap&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Bootstrap把页面分为12列，称为grid&lt;/li&gt;
  &lt;li&gt;class=”container” 是正文部分，包含了边距等&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;html&quot;&gt;HTML&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;导航栏应该有ul + li&lt;/li&gt;
  &lt;li&gt;好像差不多也没啥可说的&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;css&quot;&gt;CSS&lt;/h4&gt;

&lt;p&gt;display&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;block: 重新起一行&lt;/li&gt;
  &lt;li&gt;inline: 在原有行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;position &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;relative: 与&lt;strong&gt;本应该在的位置&lt;/strong&gt;的相对位置&lt;/li&gt;
  &lt;li&gt;absolute：在页面的中的绝对位置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;background-attachment: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;fixed: 背景不随下来框移动&lt;/li&gt;
  &lt;li&gt;scroll: 默认值。背景图像会随着页面其余部分的滚动而移动。&lt;/li&gt;
  &lt;li&gt;inherit: 规定应该从父元素继承 background-attachment 属性的设置。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;margin:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;margin-left: auto 最大限度的向右&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;margin-right: auto 最大限度的向左&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;同时margin-left:auto, margin-right:auto&lt;/li&gt;
  &lt;li&gt;或者margin: auto&lt;/li&gt;
  &lt;li&gt;向左和向右中和了，所以居中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;border-redius: 100% 圆圈&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Javascript Notes</title>
   <link href="http://zhou-dong.github.io/javascript/2015/05/25/js-note"/>
   <updated>2015-05-25T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/javascript/2015/05/25/js-note</id>
   <content type="html">
&lt;h4 id=&quot;section&quot;&gt;原型：&lt;/h4&gt;

&lt;p&gt;参考地址： http://www.ruanyifeng.com/blog/2011/06/designing_ideas_of_inheritance_mechanism_in_javascript.html&lt;/p&gt;

&lt;p&gt;javascript 使用&lt;strong&gt;构造函数&lt;/strong&gt;来构造一个对象，如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
function Person(name, age){  
    this.name = name;
    this.age = age;
};
var person1 = new Person(&quot;Linda&quot;, 28) ;
var person2 = new Person(&quot;Snow&quot;, 24) ;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样的缺点是，那就是无法共享属性和方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
function Female(name, age){
    this.name = name ;
    this.age = age ;
    this.gender = &#39;female&#39; ;
};
var person1 = new Female(&quot;Linda&quot;, 28) ;
var person2 = new Female(&quot;Snow&quot;, 24) ;
person1.gender = &#39;male&#39; ;
console.log(person1.gender) // male
console.log(person2.gender) //female
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每一个实例对象，都有自己的属性和方法的副本。这不仅无法做到数据共享，也是极大的资源浪费。&lt;/p&gt;

&lt;p&gt;考虑到这一点，Brendan Eich决定为构造函数设置一个prototype属性。&lt;/p&gt;

&lt;p&gt;这个属性包含一个对象（以下简称”prototype对象”），所有实例对象需要共享的属性和方法，都放在这个对象里面；那些不需要共享的属性和方法，就放在构造函数里面。&lt;/p&gt;

&lt;p&gt;实例对象一旦创建，将自动引用prototype对象的属性和方法。也就是说，实例对象的属性和方法，分成两种，一种是本地的，另一种是引用的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
function Female(name, age){
    this.name = name ;
    this.age = age ;
};
Female.prototype = {gender: &#39;female&#39;} ;
var person1 = new Female(&quot;Linda&quot;, 28) ;
var person2 = new Female(&quot;Snow&quot;, 24) ;
console.log(person1.gender) // female
console.log(person2.gender) //female
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;section-1&quot;&gt;总结&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;
由于所有的实例对象共享同一个prototype对象，那么从外界看起来，prototype对象就好像是实例对象的原型，而实例对象则好像&quot;继承&quot;了prototype对象一样。
&lt;/code&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Review Machine Learning in Action</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/05/24/reviews"/>
   <updated>2015-05-24T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/05/24/reviews</id>
   <content type="html">
&lt;h4 id=&quot;machine-learning-regression&quot;&gt;Machine Learning: Regression&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;使用回归模型，可以使用所有的数据来为模型服务！&lt;/li&gt;
  &lt;li&gt;如果只是找到最相近的几个数据点，然后来求他们的分类或者预测属性的话，那整个数据集中，只有几个点参与到的预测和分类中，其它的数据都几乎没有用到。&lt;/li&gt;
  &lt;li&gt;使用回归模型，不但可以用x，预测y；也可以用y，预测x&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Simple linear regression&lt;/li&gt;
  &lt;li&gt;Multiple Regression&lt;/li&gt;
  &lt;li&gt;Assessing performance
    &lt;ul&gt;
      &lt;li&gt;Remember that all models are wrong; the practical question is how wrong do they have to be to not be useful.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ridge Regression&lt;/li&gt;
  &lt;li&gt;Feature Selection &amp;amp; Lasso&lt;/li&gt;
  &lt;li&gt;Nearest Neighbors &amp;amp; Kernel Regression&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;advantage-knndisadvantage&quot;&gt;回归模型的advantage 和KNN的disadvantage&lt;/h4&gt;

&lt;p&gt;KNN的劣势：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算复杂度高，每次都要遍历整个数据集。&lt;/li&gt;
  &lt;li&gt;只有最接近的K个数据参与到最后的分类或者预测中。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;x&quot;&gt;在回归模型中，加入随着x轴的变化，周期变化的参数：&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y_i = w_0 + w_1t_i + w_2 \sin (2 \pi t_i / 12 - \Phi ) + \epsilon_i
&lt;/script&gt;

&lt;p&gt;Equivalently&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y_i = w_0 + w_1t_i + w_2 \sin (2 \pi t_i / 12) + w_3 \cos (2 \pi t_i / 12) + \epsilon_i
&lt;/script&gt;

&lt;p&gt;Generic basis expansion&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
y_i = w_0h_0(x_i) + w_1h_1(x_i) + w_2 h_2(x_i)  + \cdots + w_D h_D(x_i)  + \epsilon_i \\

= \sum_{j=0}^D w_j h_j(x_i) + \epsilon_i
&lt;/script&gt;

&lt;h4 id=&quot;section&quot;&gt;向量和矩阵 计算梯度&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Since the derivative of a sum is the sum of the derivatives we can compute the derivative for a single data point and then sum over data points. We can write the squared difference between the observed output and predicted output for a single point as follows:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
(w[0]*[CONSTANT] + w[1]*[feature_1] + ... + w[i] *[feature_i] + ... + w[k]*[feature_k] - output)^2
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Where we have k features and a constant. So the derivative with respect to weight w[i] by the chain rule is:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
2*(w[0]*[CONSTANT] + w[1]*[feature_1] + ... + w[i] *[feature_i] + ... + w[k]*[feature_k] - output)* [feature_i]
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The term inside the paranethesis is just the error (difference between prediction and output). So we can re-write this as:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
2*error*[feature_i]
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself. In the case of the constant then this is just twice the sum of the errors!
Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature[i] is just two times the dot product between the values of feature[i] and the current errors.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;assessing-loss-on-the-training-set&quot;&gt;Assessing loss on the training set&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;RMSE: root mean square error:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\sqrt{ \frac{1}{N} \sum_{i=1}^N (y_i-f(x_i))^2 }
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Generalization error vs model complexity
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;判断结果是不是符合正态分布&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;define overfitting
        &lt;ol&gt;
          &lt;li&gt;training error less than other parameter&lt;/li&gt;
          &lt;li&gt;test error larger than other parameter&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;split train and test data
        &lt;ol&gt;
          &lt;li&gt;留下足够的测试数据&lt;/li&gt;
          &lt;li&gt;然后使用剩下的所有数据做training&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\frac{1}{N \text{test}} \sum_{i=1}^N L(y_i-f(x_i))
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;3 sources of error
    &lt;ul&gt;
      &lt;li&gt;Noise&lt;/li&gt;
      &lt;li&gt;Bias&lt;/li&gt;
      &lt;li&gt;Variance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bias-variance tradeoff
    &lt;ul&gt;
      &lt;li&gt;High-complexity has low bias&lt;/li&gt;
      &lt;li&gt;High-complexity has high variance &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bias of function estimator
    &lt;ul&gt;
      &lt;li&gt;使用交叉验证&lt;/li&gt;
      &lt;li&gt;在每个数据集上训练数据&lt;/li&gt;
      &lt;li&gt;把每个数据集得到的结果求平均值&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Mean squre error = bias * bias + variance * variance&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;choose-model-complexity&quot;&gt;Choose model complexity&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;split data set to:
    &lt;ul&gt;
      &lt;li&gt;Training Set&lt;/li&gt;
      &lt;li&gt;Validation Set&lt;/li&gt;
      &lt;li&gt;Test Set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;use the training set to train different polynomial degrees of function&lt;/li&gt;
  &lt;li&gt;use validation set to find the best model complexity (degree of polynomial)&lt;/li&gt;
  &lt;li&gt;use test set to test the result&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;ridge-regression&quot;&gt;Ridge Regression&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Coefficients 越大，模型越fit data set.&lt;/li&gt;
  &lt;li&gt;If coefficients 太大的话，会overfitting&lt;/li&gt;
  &lt;li&gt;We expect model，fit data set， but not overfit&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;ridge-regression-comes-to-rescue&quot;&gt;Ridge regression comes to rescue&lt;/h5&gt;

&lt;p&gt;Generally, whenever we see weights change so much in response to change in data, we believe the variance of our estimate to be large. Ridge regression aims to address this issue by penalizing “large” weights. &lt;/p&gt;

&lt;h5 id=&quot;which-means&quot;&gt;Which means:&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;如果一个模型overfitting的话，一般情况下coefficients会特别大&lt;/li&gt;
  &lt;li&gt;which means we wanna model fit data set, but coefficients do not to be too large.&lt;/li&gt;
  &lt;li&gt;We wanna balance between model fit and the magnitude of coefficients&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;total-cost--measure-of-fit--measure-of-magnitude-of-coefficients&quot;&gt;Total cost = measure of fit + measure of magnitude of coefficients&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Regularization &lt;script type=&quot;math/tex&quot;&gt; \text{minimize: } RSS(w) + \lambda \| w \|^2 &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \lambda &lt;/script&gt; tunning parameter = balance of fit and magnitude&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\text{arg}_{(w, \lambda)} \min \Bigr[\sum_{i=1}^N (y_i-f_{w}(x_i))^2 + \lambda \sum_{j=i}^D w_j^2 \Bigr] 
&lt;/script&gt;

&lt;h5 id=&quot;cross-validation&quot;&gt;Cross Validation&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Leave one cross validation&lt;/li&gt;
  &lt;li&gt;K-fold cross validation&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;features-selection&quot;&gt;Features selection&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;All subsets
    &lt;ol&gt;
      &lt;li&gt;Find feature which reduce RSS most.&lt;/li&gt;
      &lt;li&gt;Fine the combination of two fearues which reduce RSS most. (Do not need to contain the step one feature).&lt;/li&gt;
      &lt;li&gt;Find the combination of three features which most reduce RSS. (do not need to contain step one or step two features).&lt;/li&gt;
      &lt;li&gt;repeat until convergence.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;How many choice?
    &lt;ul&gt;
      &lt;li&gt;total: &lt;script type=&quot;math/tex&quot;&gt;2^D&lt;/script&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Greedy Algorithm
    &lt;ol&gt;
      &lt;li&gt;Start at them trainning errors as all subsets(no features).&lt;/li&gt;
      &lt;li&gt;Choose the one feature which reduce the RSS most.&lt;/li&gt;
      &lt;li&gt;在第一个feature的基础上，find the next feaure which reduce RSS most.&lt;/li&gt;
      &lt;li&gt;repeat until convergence.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example of All Subsets VS. Greedy Algorithm:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;First step:
    &lt;ul&gt;
      &lt;li&gt;All subsets: sq.ft. living&lt;/li&gt;
      &lt;li&gt;Greedy algorithm: sq.ft. living&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Second step:
    &lt;ul&gt;
      &lt;li&gt;All subsets: 
        &lt;ul&gt;
          &lt;li&gt;No. bedrooms&lt;/li&gt;
          &lt;li&gt;No. bathrooms&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Greedy Algorithm: 
        &lt;ul&gt;
          &lt;li&gt;sq.ft. living&lt;/li&gt;
          &lt;li&gt;year renovated&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Third step:
    &lt;ul&gt;
      &lt;li&gt;…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Lasso algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use regularization for feature selection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为什么不能在ridge regression的基础上做降维：不能直接删除weight小的feature。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果几个features表示类似的属性，如：bathroom、showers，那么这两个feature的weight在ridge中，都会被降低。&lt;/li&gt;
  &lt;li&gt;如果同时删除几个类似的属性。那么可能会删除相关有用的信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;difference-between-ridge-regression-and-lasso-regression&quot;&gt;Difference between Ridge Regression and Lasso Regression&lt;/h5&gt;

&lt;p&gt;Formula:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ridge regression: &lt;script type=&quot;math/tex&quot;&gt;\text{arg}_w \min RSS + \lambda \| w \|_2^2&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Lasso Regression: &lt;script type=&quot;math/tex&quot;&gt;\text{arg}_w \min RSS + \lambda \| w \|_1&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Specific:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ridge regression: 
    &lt;ul&gt;
      &lt;li&gt;weight occupy bigger part in whole cost than Lasso regression&lt;/li&gt;
      &lt;li&gt;so every weight will shrink quickly&lt;/li&gt;
      &lt;li&gt;harder to find which weight is 0 when others are not.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lasso regression:
    &lt;ul&gt;
      &lt;li&gt;weight not occupy larger part in whole cost then Lasso regression&lt;/li&gt;
      &lt;li&gt;some weight will shrink quickly but some not&lt;/li&gt;
      &lt;li&gt;easier to sepeare 0 weight and none 0 weight &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;coordinate-descent&quot;&gt;Coordinate descent&lt;/h4&gt;

&lt;p&gt;Coordinate descent的思想在Lasso regression中非常重要。Often hard to find all minimum of all coordinates, but for each coordinate.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;坐标下降法（英语：coordinate descent）是一种非梯度优化算法。算法在每次迭代中，在当前点处沿一个坐标方向进行一维搜索以求得一个函数的局部极小值。在整个过程中循环使用不同的坐标方向。&lt;/li&gt;
  &lt;li&gt;对于不可拆分的函数而言，算法可能无法在较小的迭代步数中求得最优解。为了加速收敛，可以采用一个适当的坐标系，例如通过主成分分析获得一个坐标间尽可能不相互关联的新坐标系&lt;/li&gt;
  &lt;li&gt;coordinate descent不是梯度下降，它每次计算函数在一个坐标方向上的局部极小值。而不是逐步递进！&lt;/li&gt;
  &lt;li&gt;每次迭代，要在一个weight上做迭代，如果在这个weight上算出的梯度为0，那么说明：
    &lt;ul&gt;
      &lt;li&gt;说明这个weight不重要&lt;/li&gt;
      &lt;li&gt;已经达到了函数的极小值&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\hat{w}_j = \rho_j \\

\hat{w}_j = \begin{cases}
\rho_j + \lambda/2 &amp; \text{if } \rho_j &lt; -\lambda/2 \\
0 &amp; \text{if } \rho_j \in [-\lambda/2, \lambda/2] \\
\rho_j - \lambda/2 &amp; \text{if } \rho_j &gt; \lambda / 2
\end{cases}
 %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;normalizing-features&quot;&gt;Normalizing features&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
h_j(x_k) = \frac{h_j(x_k)}{\sqrt{\sum_{i=1}^N h_j (x_i)^2 }}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Scale training columns (not rows!)&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Apply same training scale factors in test data!&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;nearest-neighbors-and-kernal-regression&quot;&gt;Nearest Neighbors and Kernal Regression&lt;/h4&gt;

&lt;p&gt;Nearest neighbor regression&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;normalize features first&lt;/li&gt;
  &lt;li&gt;compute distance with query and all data set&lt;/li&gt;
  &lt;li&gt;find the closest data to this query.&lt;/li&gt;
  &lt;li&gt;predict result base on the closet data.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;k-Nearest neighbors&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;find the k-nearest neighbors&lt;/li&gt;
  &lt;li&gt;average the neighbors price&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;weighted k-nearest neighbors&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;different neighbors have the different distances, so should have different weights&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kernel regression&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Implement of weighted k-nearest neighbors&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;gaussian distribution to compute the weight of the neighbors&lt;/li&gt;
  &lt;li&gt;closest k neighbors&lt;/li&gt;
  &lt;li&gt;average their value&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Local weighted linear regression&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;use linear regression with the k neighbors&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;linear-classifiers&quot;&gt;Linear classifiers&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Score the weight of the each word (训练每个词的权重) 比如：
    &lt;ul&gt;
      &lt;li&gt;good: 1.0&lt;/li&gt;
      &lt;li&gt;beautiful: 1.3&lt;/li&gt;
      &lt;li&gt;awesome: 1.5&lt;/li&gt;
      &lt;li&gt;bad: -1.0&lt;/li&gt;
      &lt;li&gt;suck: -2.0&lt;/li&gt;
      &lt;li&gt;car: 0.0&lt;/li&gt;
      &lt;li&gt;house: 0.0&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;把句子中的每个词的权重相加算出得分：
    &lt;ul&gt;
      &lt;li&gt;大于0，positive&lt;/li&gt;
      &lt;li&gt;小于0，negative&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-1&quot;&gt;基于商品的协同过滤&lt;/h4&gt;

&lt;p&gt;看来华盛顿大学的机器学习课程，才发现协同过滤真的很简单！这门课太棒了！&lt;/p&gt;

&lt;p&gt;最简单的product-to-product推荐系统&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先他是一个&lt;code&gt;对角矩阵&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;行和列一样的商品&lt;/li&gt;
  &lt;li&gt;这样的话，就能知道，两两商品同时出现的次数&lt;/li&gt;
  &lt;li&gt;这也就可以做协同过滤了&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\begin{array}{|c|c|c|c|c|c|c|} \hline X &amp; 从一到无穷大 &amp; 深入浅出设计模式 &amp; Effective Java &amp; 三体 &amp; 时间简史 \\
\hline
从一到无穷大     &amp; 20 &amp; 1  &amp; 2  &amp; 100 &amp; 15 \\
\hline
深入浅出设计模式 &amp; 1  &amp; 30 &amp; 16 &amp; 110 &amp; 3  \\
\hline
Effective Java   &amp; 2  &amp; 16 &amp; 40 &amp; 150 &amp;  4  \\
\hline
三体             &amp; 100 &amp; 110 &amp; 150 &amp; 10000 &amp; 250 \\
\hline
时间简史         &amp; 15 &amp; 3  &amp; 4  &amp; 250 &amp; 70 \\
\hline
\end{array}
 %]]&gt;&lt;/script&gt;

&lt;h5 id=&quot;normalizing-co-occurrence-matrices&quot;&gt;Normalizing co-occurrence matrices&lt;/h5&gt;

&lt;p&gt;Jaccard similarity，因为有些商品购买的特别多，无论买那个商品都会推荐它&lt;/p&gt;

&lt;p&gt;who purchased &lt;code&gt;i and j&lt;/code&gt; divided by who purchased &lt;code&gt;i or j&lt;/code&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\frac{\text{# purchased } i \text{ and }  j }{\text{# purchased } i \text{ or }  j}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\begin{array}{|c|c|c|c|c|c|c|} \hline X &amp; 从一到无穷大 &amp; 深入浅出设计模式 &amp; Effective Java &amp; 三体 &amp; 时间简史 \\
\hline
从一到无穷大     &amp; 1     &amp; 0.05  &amp; 0.10  &amp; 0.05 &amp; 0.75 \\
\hline
深入浅出设计模式 &amp; 0.05  &amp; 1     &amp; 0.53  &amp; 0.27 &amp; 0.10  \\
\hline
Effective Java   &amp; 0.10  &amp; 0.53  &amp; 1     &amp; 0.27 &amp;0.10  \\
\hline
三体             &amp; 0.05  &amp; 0.27  &amp; 0.27  &amp; 1 &amp; 0.25 \\
\hline
时间简史         &amp; 0.75  &amp; 0.10  &amp; 0.10  &amp; 0.25 &amp; 1 \\
\hline
\end{array}
 %]]&gt;&lt;/script&gt;

&lt;p&gt;如果用户同时购买了两件商品，或者更多的商品，可以想搜素引擎打分一样，给商品打分&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;分别找出为这两个商品推荐的商品&lt;/li&gt;
  &lt;li&gt;分别把这些权重相加，找出得分最高的商品&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\begin{array}{|c|c|c|c|c|c|c|} \hline X &amp; 从一到无穷大 &amp; 深入浅出设计模式 &amp; Effective Java &amp; 三体 &amp; 时间简史 \\
\hline
从一到无穷大     &amp; 1     &amp; 0.05  &amp; 0.10  &amp; 0.05 &amp; 0.75 \\
\hline
Effective Java   &amp; 0.10  &amp; 0.53  &amp; 1     &amp; 0.27 &amp;0.10  \\
\hline
Result           &amp; 1.10  &amp; 0.58  &amp; 1.10  &amp; 0.32 &amp; 0.85 \\
\hline
\end{array}
 %]]&gt;&lt;/script&gt;

&lt;p&gt;所以推荐的顺序是：时间简史、深入浅出审计模式、三体&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-2&quot;&gt;基于内容的协同过滤&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;user     有多个features&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;movie  也有多个feature&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;user = (f1,f2,f3,…,fn)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;movie = (k1,k2,k3,…,kn)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;user * movie = score(positve, negative)&lt;/li&gt;
  &lt;li&gt;用这种方法可以求出各个feature和weight&lt;/li&gt;
  &lt;li&gt;然后再用使用基于内容的协同过滤&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;matrix-factorization&quot;&gt;matrix factorization&lt;/h5&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-3&quot;&gt;评价系统的推荐系统&lt;/h4&gt;

&lt;p&gt;Recall&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\frac{\text{# liked &amp; shown}}{\text{ # liked}}
 %]]&gt;&lt;/script&gt;

&lt;p&gt;Precision&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\frac{\text{# liked &amp; shown}}{\text{# shown}}
 %]]&gt;&lt;/script&gt;

&lt;p&gt;Optimal recommenders&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
Recall = 1 \\
Precision = 1
&lt;/script&gt;

&lt;p&gt;Precision-recall curves&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We can use Area Under the Curve(AUC) method to evluate with curve is better.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img width=&quot;40%&quot; src=&quot;http://ivrl.epfl.ch/files/content/sites/ivrg/files/supplementary_material/RK_ICIP2010/images/MSSSvsOthers.jpg&quot; alt=&quot;Precision-recall curves&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;word-count-document-representation&quot;&gt;Word count document representation&lt;/h4&gt;

&lt;h5 id=&quot;bag-of-words-model&quot;&gt;Bag of words model&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Ignore order of words&lt;/li&gt;
  &lt;li&gt;Count # of instances of each word in vocabulary&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原来比较两个文章的相似度，比我想的还要简单&lt;/p&gt;

&lt;h4 id=&quot;supervised-learning-method&quot;&gt;Supervised Learning method&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;KNN (k nearest neighbor)
    &lt;ol&gt;
      &lt;li&gt;Calculate the distance will all the data.&lt;/li&gt;
      &lt;li&gt;Find the nearest k data&lt;/li&gt;
      &lt;li&gt;From this k nearest data find the most frequent category&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Decision Tree
    &lt;ol&gt;
      &lt;li&gt;Find the most efficient propercity to divided the datas&lt;/li&gt;
      &lt;li&gt;Check if all the sub tree has been divied&lt;/li&gt;
      &lt;li&gt;If not recurive steps 1 and 2&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Naive Bayes
    &lt;ul&gt;
      &lt;li&gt;根据朴素贝叶斯概率模型来计算一个目标可能出现在哪个分类中&lt;/li&gt;
      &lt;li&gt;如果出现在分来A的概率大于出现在分类B的概率，则结果为A反之为B&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Regression
    &lt;ul&gt;
      &lt;li&gt;找出或者画出一条可以拟合数据走向的线&lt;/li&gt;
      &lt;li&gt;最小二乘&lt;/li&gt;
      &lt;li&gt;logistic regression&lt;/li&gt;
      &lt;li&gt;CART Classification-and-Regression-Trees&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SVM (support vector machine)
    &lt;ul&gt;
      &lt;li&gt;找出支撑点&lt;/li&gt;
      &lt;li&gt;利用kernel把地位的数据映射到高维求解&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adaboost
    &lt;ul&gt;
      &lt;li&gt;可以多次重复同一函数，也可用不同函数&lt;/li&gt;
      &lt;li&gt;每次计算以后，增加错误数据的权重，减小正确数据的权重&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;unsupervised-learning-method&quot;&gt;Unsupervised Learning method&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;K means
    &lt;ul&gt;
      &lt;li&gt;首先定义K个中心店，然后计算所有点到这些点的距离&lt;/li&gt;
      &lt;li&gt;把里这些点最近的点合成一簇，&lt;/li&gt;
      &lt;li&gt;找出簇内的中心店，继续迭代&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Apriori
    &lt;ul&gt;
      &lt;li&gt;原理是认为如果一项不频繁，那些包含它的集合也不是频繁项&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;FP-Growth
    &lt;ul&gt;
      &lt;li&gt;先构建FP tree&lt;/li&gt;
      &lt;li&gt;扫描FP tree，获得频繁项&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;other-optimize&quot;&gt;Other optimize&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;PCA
    &lt;ul&gt;
      &lt;li&gt;找出最能表现数据的维度作为坐标轴&lt;/li&gt;
      &lt;li&gt;通过这种方式来降维&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SVD
    &lt;ul&gt;
      &lt;li&gt;把一个大的系数矩阵，切分为几个矩阵来运算&lt;/li&gt;
      &lt;li&gt;通过上面的方法来达到降维的目的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Introduction to NLP</title>
   <link href="http://zhou-dong.github.io/2015/05/10/intro"/>
   <updated>2015-05-10T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/05/10/intro</id>
   <content type="html">
&lt;p&gt;分析一段句子的步骤&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Tagging（词性标注）
    &lt;ul&gt;
      &lt;li&gt;单词词性的标注。
        &lt;ul&gt;
          &lt;li&gt;Verb&lt;/li&gt;
          &lt;li&gt;Noun&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;命名体识别，几个单词组成一个词，如：
        &lt;ul&gt;
          &lt;li&gt;人名：John Hopkins&lt;/li&gt;
          &lt;li&gt;地点：Wall Street&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Phase（句子划分）
    &lt;ul&gt;
      &lt;li&gt;Definition:
        &lt;ul&gt;
          &lt;li&gt;根据英语语法的规则来切分句子&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;method：
        &lt;ul&gt;
          &lt;li&gt;Parse Tree&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;例子:
        &lt;ul&gt;
          &lt;li&gt;主谓宾&lt;/li&gt;
          &lt;li&gt;定状补&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Context Free Grammer
        &lt;ul&gt;
          &lt;li&gt;与具体的单词意思无关&lt;/li&gt;
          &lt;li&gt;根据单词的词性，以及在上下文中的位置&lt;/li&gt;
          &lt;li&gt;来切分句子&lt;/li&gt;
          &lt;li&gt;在不同的切分中，找到概率最高的&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Probabilistic Context-Free Grammars(PCFG)
        &lt;ul&gt;
          &lt;li&gt;CKY (one of dynamic programming)&lt;/li&gt;
          &lt;li&gt;Use dynamic programming to find the max probalities&lt;/li&gt;
          &lt;li&gt;Chomsky Normal Form&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Weaknesses of PCFGs
        &lt;ul&gt;
          &lt;li&gt;Lack of sensitivity of lexical information&lt;/li&gt;
          &lt;li&gt;Lack of sensitivity of structural frequencies&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Lexical of PCFGs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Machine Translation&lt;/p&gt;

&lt;p&gt;First genereaion&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IBM Model&lt;/li&gt;
  &lt;li&gt;EM Algorithm for IBM Model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Second generation&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;phase based translation&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>CS-5549 Final Review</title>
   <link href="http://zhou-dong.github.io/2015/04/28/final-review"/>
   <updated>2015-04-28T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/04/28/final-review</id>
   <content type="html">
&lt;p&gt;Greddy Algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Description:
    &lt;ul&gt;
      &lt;li&gt;是一种在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望导致结果是最好或最优的算法。比如在旅行推销员问题中，如果旅行员每次都选择最近的城市，那这就是一种贪心算法。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;用在哪些地方：
    &lt;ul&gt;
      &lt;li&gt;贪心法可以解决一些最优化问题，如：求图中的最小生成树、求哈夫曼编码……对于其他问题。&lt;/li&gt;
      &lt;li&gt;贪心法一般不能得到我们所要求的答案。一旦一个问题可以通过贪心法来解决，那么贪心法一般是解决这个问题的最好办法。&lt;/li&gt;
      &lt;li&gt;由于贪心法的高效性以及其所求得的答案比较接近最优结果，贪心法也可以用作辅助算法或者直接解决一些要求结果不特别精确的问题。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;我们学过的贪心算法：
    &lt;ul&gt;
      &lt;li&gt;Prime&lt;/li&gt;
      &lt;li&gt;Kruskal&lt;/li&gt;
      &lt;li&gt;Dijkstra&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Search Tree or Map&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Breadth First Search
    &lt;ul&gt;
      &lt;li&gt;先建立priori queue&lt;/li&gt;
      &lt;li&gt;先进先出，然后遍历所有的的结点。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Depth First Search
    &lt;ul&gt;
      &lt;li&gt;朝一个方向深度遍历。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Minimum Spanning Tree&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;最小生成树的边，应该是顶点总数减一：(total_vertex-1)。&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Prime
    &lt;ul&gt;
      &lt;li&gt;Description: 由一条最短的边，逐渐扩展成一棵树&lt;/li&gt;
      &lt;li&gt;Steps:
        &lt;ol&gt;
          &lt;li&gt;随便找一个顶点，然后找出与这个顶点相连的最的边。把这条变加入到树中。&lt;/li&gt;
          &lt;li&gt;找出与这棵树相连的最短的边，加入树中。&lt;/li&gt;
          &lt;li&gt;重复步骤2，直到所有的定点都加入到树中。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kruskal
    &lt;ul&gt;
      &lt;li&gt;Description: 找出最短的边，以每个边为基础，生成多个tree，然后这些tree合并成一个tree。&lt;/li&gt;
      &lt;li&gt;Steps:
        &lt;ol&gt;
          &lt;li&gt;首先按边进行排序，并放在queue中。&lt;/li&gt;
          &lt;li&gt;新建一个key-value set，来标记这些点是否已经在set中。&lt;/li&gt;
          &lt;li&gt;依次中queue中取出边，如果两个顶点都不在set中，这个边加入到set中。&lt;/li&gt;
          &lt;li&gt;重复第二步，直到所有的点都加入到set中。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Single Source Shortest Path&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bellman Ford
    &lt;ul&gt;
      &lt;li&gt;Specical: can work on negative edge weight graph&lt;/li&gt;
      &lt;li&gt;Description: 多次松弛。&lt;/li&gt;
      &lt;li&gt;Steps:
        &lt;ol&gt;
          &lt;li&gt;设置开始结点离所有点的距离都为无穷大。&lt;/li&gt;
          &lt;li&gt;遍历所开始结点相邻的所有点，并且更新距离。&lt;/li&gt;
          &lt;li&gt;依次遍历，剩下的结点，如果通过剩下的结点，可以使到开始结点的距离变短，更新结点，并更新父结点。&lt;/li&gt;
          &lt;li&gt;重复上面的步骤n(结点的个数)次。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dijkstra:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=5GT5hYzjNoo&quot;&gt;教学视频&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Description: 找到最短的路径，然后逐渐的松弛每条边，然后找出单点到其它点的最短路径。&lt;/li&gt;
      &lt;li&gt;Stepson：
        &lt;ol&gt;
          &lt;li&gt;找出与起始点相连的所有点，然后找出其中距离最短的点&lt;/li&gt;
          &lt;li&gt;通过最短的点来做松弛。并标记松弛点的来源。&lt;/li&gt;
          &lt;li&gt;在剩下的点中，找出最短的点，并通过这个点做松弛。&lt;/li&gt;
          &lt;li&gt;重复第3步，直到使用完所有的点做松弛。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;More：
        &lt;ul&gt;
          &lt;li&gt;可以用堆做优化，来找出距离最短的电&lt;/li&gt;
          &lt;li&gt;可以继续优化成斐波那契堆，可以更高的提高效率。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Multiple Source Shortest Path&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Floyd Warshall
    &lt;ul&gt;
      &lt;li&gt;时间复杂度是n的立方&lt;/li&gt;
      &lt;li&gt;Steps: 所有点依次通过每个点，到其它点的距离做松弛。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Johnson’s Algorithm
    &lt;ol&gt;
      &lt;li&gt;在图的外边添加另一个顶点q，并初始化q到其它点的距离为0&lt;/li&gt;
      &lt;li&gt;使用Bellman Ford算法，求q到其它点的距离。&lt;/li&gt;
      &lt;li&gt;reweight各个点之间的距离。&lt;/li&gt;
      &lt;li&gt;使用Dijkstra算法，分别求出每个点到其它点的最短距离。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;NP-complete&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;简单来说，P = NP问题问道：如果是／不是问题的正面答案可以很快验证，其答案是否也可以很快计算？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;不严格的讲，NP完全问题是NP类中“最难”的问题，也就是说它们是最可能不属于P类的。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Some problems are intractable: as they grow large, we are unable to solve them in reasonable time.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What constitutes &lt;code&gt;reasonable time&lt;/code&gt;? Standard working definition: &lt;code&gt;polynomial time&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Polynomial time: &lt;script type=&quot;math/tex&quot;&gt; O(n^2), O(n^3), O(1), O(n \log n) &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Not in polynomial time: &lt;script type=&quot;math/tex&quot;&gt; O(2^n), O(n^n), O(n!) &lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Polynomial-Time Algorithms&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We define P to be the class of problems solvable in polynomial time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NP-Complete Problems&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The NP-Complete problems are an interesting class of problems whose status is unknown.&lt;/li&gt;
  &lt;li&gt;NP (nondeterministic polynomial time) is the set of problems that can be solved in polynomial time by a nondeterministic computer.&lt;/li&gt;
  &lt;li&gt;NP-hard Problem：对于这一类问题，用一句话概括他们的特征就是“at least as hard as the hardest problems in NP Problem”， 就是NP-hard问题至少和NP问题一样难。&lt;/li&gt;
  &lt;li&gt;NP-complete Problem: 对于这一类问题，他们满足两个性质:
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;一个就是在polynomial时间内可以验证一个candidate answer是不是真正的解。&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;另一个性质就是我们可以把任何一个NP问题在polynomial的时间内把他的input转化，使之成为一个NP-complete问题。&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;NP = problems verifiable in polynomial time&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;P: problems that can be solved in polynomial time&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;NP: problems for which a solution can be verified in polynomial time&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unknown whether P = NP (most suspect not)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Example: Hamiltonian-cycle problem is in NP:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cannot solve in polynomial time&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Easy to verify solution in polynomial time (How?)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;All the P problem is NP problem.&lt;/li&gt;
  &lt;li&gt;Not all the NP problem are p problem.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NP-Complete problems are the “hardest” problems in NP.&lt;/p&gt;

&lt;p&gt;NP-Complete可以简单地理解为：那些在NP中，同时最不可能在P中的问题。&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Text Retrieval and Search Engines</title>
   <link href="http://zhou-dong.github.io/data-mining/2015/04/17/search-engines"/>
   <updated>2015-04-17T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/data-mining/2015/04/17/search-engines</id>
   <content type="html">
&lt;h3 id=&quot;vector-space-model&quot;&gt;Vector Space Model&lt;/h3&gt;

&lt;p&gt;Basic Idea is: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use &lt;code&gt;Dot Product&lt;/code&gt; to calculate the similarity between Query and Documents&lt;/li&gt;
  &lt;li&gt;两个向量求内积，通过这两个向量的内积来判断相似度。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Difficult part is to calculate the weight of the terms&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TF
    &lt;ul&gt;
      &lt;li&gt;词频&lt;/li&gt;
      &lt;li&gt;Term在文档中出现的频率&lt;/li&gt;
      &lt;li&gt;Term在文章中出现的频率越高，说明Term与这个文章的主题越接近&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;IDF
    &lt;ul&gt;
      &lt;li&gt;逆文档频率&lt;/li&gt;
      &lt;li&gt;文档总数/包含这个term的文档数&lt;/li&gt;
      &lt;li&gt;包含这个Term的文档越多，说明这个Term在整体文档库中越不重要。&lt;/li&gt;
      &lt;li&gt;可以对这个值取log，来避免这个值太大&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Doc Length Normation
    &lt;ul&gt;
      &lt;li&gt;Pivoted length normalization&lt;/li&gt;
      &lt;li&gt;以doc的平均长度作为pivot，如果长度大于pivot减分；如果长度小于pivot加分。&lt;/li&gt;
      &lt;li&gt;K = (1-b) + b(dl/avdl)&lt;/li&gt;
      &lt;li&gt;把K作为分母，这样就可以保证大于pivot减分，小于pivot加分。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BM25
    &lt;ul&gt;
      &lt;li&gt;通过4个维度来计算weight值
        &lt;ol&gt;
          &lt;li&gt;IDF&lt;/li&gt;
          &lt;li&gt;TF&lt;/li&gt;
          &lt;li&gt;Doc Length&lt;/li&gt;
          &lt;li&gt;Query TF&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;个人理解：
        &lt;ul&gt;
          &lt;li&gt;在各个维度都可以添加调节因子来计算weight的值&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BM25F 
    &lt;ul&gt;
      &lt;li&gt;Name From: BM25 and Fields&lt;/li&gt;
      &lt;li&gt;(Term在各个域中出现的频率*这个域的调节因子)/这个域的文档长度&lt;/li&gt;
      &lt;li&gt;Term出现在doc的不同域中，会对doc的weight做出不同大小的贡献&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;probabilistic-retrieval-model&quot;&gt;Probabilistic Retrieval Model&lt;/h3&gt;

&lt;p&gt;Basic Idea is: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;计算每个Term出现在各个doc中的概率，可通过贝叶斯规则进行计算&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;P(A,B) = P(A) * P(B&lt;/td&gt;
          &lt;td&gt;A) = P(B) * P(A&lt;/td&gt;
          &lt;td&gt;B).&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Example:&lt;/li&gt;
  &lt;li&gt;d1 a, a, a, b, c, e, f, f&lt;/li&gt;
  &lt;li&gt;d2 a, b, b, d, f, f, f, f&lt;/li&gt;
  &lt;li&gt;d3 b, b, c, c, d, d, d, f&lt;/li&gt;
  &lt;li&gt;total_a = 4&lt;/li&gt;
  &lt;li&gt;total_b = 5&lt;/li&gt;
  &lt;li&gt;total_c = 3&lt;/li&gt;
  &lt;li&gt;total_d = 4&lt;/li&gt;
  &lt;li&gt;total_e = 1&lt;/li&gt;
  &lt;li&gt;total_f = 7&lt;/li&gt;
  &lt;li&gt;Data:&lt;/li&gt;
  &lt;li&gt;p(d1,a)=3/4 p(d1,b)=1/5 p(d1,c)=1/3 p(d1,d)=0/4 p(d1,e)=1/1 p(d1,f)=2/7 &lt;/li&gt;
  &lt;li&gt;p(d2,a)=1/4 p(d2,b)=2/5 p(d2,c)=0/3 p(d2,d)=1/4 p(d2,e)=0/1 p(d2,f)=4/7 &lt;/li&gt;
  &lt;li&gt;p(d3,a)=0/4 p(d3,b)=2/5 p(d3,c)=2/3 p(d3,d)=3/4 p(d3,e)=0/1 p(d3,f)=1/7&lt;/li&gt;
  &lt;li&gt;p(d1) = 5/6&lt;/li&gt;
  &lt;li&gt;p(d2) = 4/6&lt;/li&gt;
  &lt;li&gt;p(d3) = 4/6 &lt;/li&gt;
  &lt;li&gt;p(a) = 4/24 &lt;/li&gt;
  &lt;li&gt;p(b) = 5/24 &lt;/li&gt;
  &lt;li&gt;p(c) = 3/24 &lt;/li&gt;
  &lt;li&gt;p(d) = 4/24 &lt;/li&gt;
  &lt;li&gt;p(e) = 1/24 &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;p(f) = 7/24&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Smoothing Methods&lt;/li&gt;
  &lt;li&gt;Rocchio Method&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;collaborative-filtering&quot;&gt;Collaborative Filtering&lt;/h3&gt;

&lt;p&gt;Basic Info： 根据相似的物或者相似的人，来推荐商品。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Items Based Filtering：基于item的协同过滤
    &lt;ul&gt;
      &lt;li&gt;通过商品的各个属性来求商品之间的相似度。&lt;/li&gt;
      &lt;li&gt;可以通过余弦相似来求给个商品之间的相似度。&lt;/li&gt;
      &lt;li&gt;通过这种方法可以返回与某个商品相似的商品。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Users Based Filtering：基于user的协同过滤
    &lt;ul&gt;
      &lt;li&gt;购买过这个商品的人还买过什么，是典型的协同过滤。&lt;/li&gt;
      &lt;li&gt;通过公共感兴趣的商品，来求人人之间的相似度。&lt;/li&gt;
      &lt;li&gt;然后根据相似的人来推荐产品。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;协同过滤的劣势是：如果一个人以前没有任何行为&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;就没有办法找到与他相似的人。&lt;/li&gt;
  &lt;li&gt;就没法适用协同过滤推荐商品。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们PEOPLE-TP-PEOPLE项目其实使用的就是协同过滤的思想。&lt;/p&gt;

&lt;h3 id=&quot;feedback&quot;&gt;Feedback&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;在用户中，做调查，哪些是有效的结果，哪些是无效的结果。
    &lt;ul&gt;
      &lt;li&gt;可以通过这些来查找同义词&lt;/li&gt;
      &lt;li&gt;也可以慢慢增加Term在doc中的权重&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pseudo Feedback
    &lt;ul&gt;
      &lt;li&gt;假设搜索返回的前N个是相关度高的，用这些相关度高的文章来训练query的同义词。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Implicit Feedback
    &lt;ul&gt;
      &lt;li&gt;通过分析的对搜索结果的行为，如浏览、点击等来查找query的同义词。&lt;/li&gt;
      &lt;li&gt;也可以增加Term在doc中的权重。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;通过query中同时出现的词，来查找query的同义词。
    &lt;ul&gt;
      &lt;li&gt;FP-Growth&lt;/li&gt;
      &lt;li&gt;Aprior&lt;/li&gt;
      &lt;li&gt;Vertical index&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Rocchio Feedback
    &lt;ul&gt;
      &lt;li&gt;使query逐渐与目标doc相似&lt;/li&gt;
      &lt;li&gt;增加query的同义词&lt;/li&gt;
      &lt;li&gt;增强正影响，减少负影响&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;section&quot;&gt;二次搜索：&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;加入同义词重新搜索同一个索引库。&lt;/li&gt;
  &lt;li&gt;建立新的索引库专门为二次搜索提供服务。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;page-rank&quot;&gt;Page Rank&lt;/h3&gt;

&lt;p&gt;马尔科夫链：每行的值相加为1&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;求转移概率矩阵，假设a = 0.5&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1 -&amp;gt; 2, 3 -&amp;gt; 2, 2 -&amp;gt; 1, 2-&amp;gt; 3&lt;/p&gt;

&lt;p&gt;概率矩阵x：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;0.0 1.0 0.0&lt;/li&gt;
  &lt;li&gt;0.5 0.0 0.5&lt;/li&gt;
  &lt;li&gt;0.0 1.0 0.0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;随机跳转矩阵y：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1/3 1/3 1/3&lt;/li&gt;
  &lt;li&gt;1/3 1/3 1/3&lt;/li&gt;
  &lt;li&gt;1/3 1/3 1/3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;转移概率矩阵P：&lt;/p&gt;

&lt;p&gt;(1-a)x + ab = 0.5x + o.by =&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1/6 2/3 1/6&lt;/li&gt;
  &lt;li&gt;5/12 1/6 5/12&lt;/li&gt;
  &lt;li&gt;1/6 2/3 1/6&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;假设初始向量x_0 = (1 0 0)&lt;/p&gt;

&lt;p&gt;迭代运算，直到最后的值趋于稳定为止&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;x_0*p = (1/6 2/3 1/6) = x_1&lt;/li&gt;
  &lt;li&gt;x_1*p = (1/3 1/3 1/3) = x_2&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;x_2*p = (1/4 1/2 1/4) = x_3&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;x_n*p = (5/18 4/9 5/18) = x_{n+1}&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hit&quot;&gt;HIT&lt;/h2&gt;

&lt;p&gt;对每个网页打分：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;hub值&lt;/li&gt;
  &lt;li&gt;authority值&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Frequent Pattern Mining for Text Data</title>
   <link href="http://zhou-dong.github.io/2015/04/12/pattern-mining-text"/>
   <updated>2015-04-12T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/04/12/pattern-mining-text</id>
   <content type="html">
&lt;ol&gt;
  &lt;li&gt;Simultaneously inferring phrases and topics
    &lt;ul&gt;
      &lt;li&gt;Bigram Topic Model&lt;/li&gt;
      &lt;li&gt;Topical N-Grams&lt;/li&gt;
      &lt;li&gt;Phrase-Discovering LDA&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Post Topic Modeling Phrase Construction&lt;/li&gt;
  &lt;li&gt;First Phrase Mining then Topic Modeling&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Phrase Mining and Topic Modeling&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Generate bag-of-words to generate sequence of tokens&lt;/li&gt;
  &lt;li&gt;Post bag-of-words model inference, visualize topics with n-grams&lt;/li&gt;
  &lt;li&gt;Prior bag-of-words model inference, ming phrases and impose to the bag-of-words model&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;First Phrase Mining then Topic Modeling 先找出频繁项，然后再从里面找出文章的主题&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Perform frequent contiguous pattern mining to extract candidate phrases and their counts&lt;/li&gt;
  &lt;li&gt;bag-of-phrases&lt;/li&gt;
  &lt;li&gt;LDA&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Challenges for Data Analysis in Data Streams&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fast changing&lt;/li&gt;
  &lt;li&gt;In and out streaming&lt;/li&gt;
  &lt;li&gt;有的方式，想apriori或者FPgrowth，需要2次或者2次以上的读取数据，这些算法就不能用在data streams&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Spatiotemporal and Trajectory Pattern&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在空间的维度上找出pattern，比如在坐标上相近的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Software bug mining&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use pattern mining to find bugs in software&lt;/li&gt;
  &lt;li&gt;Static bug detection&lt;/li&gt;
  &lt;li&gt;dynamic bug detection&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;debugging&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;pattern mining&lt;/li&gt;
  &lt;li&gt;some patterns are likely bugs&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Pattern Mining Methods</title>
   <link href="http://zhou-dong.github.io/apriori/eclat/fpgrowth/2015/04/12/pattern-mining-methods"/>
   <updated>2015-04-12T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/apriori/eclat/fpgrowth/2015/04/12/pattern-mining-methods</id>
   <content type="html">
&lt;h3 id=&quot;apriori&quot;&gt;Apriori&lt;/h3&gt;

&lt;p&gt;Basic Knowledge:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Other name: Down Closure Property of Frequent Patterns&lt;/li&gt;
  &lt;li&gt;Discription: Any subset of frequent itemset must be frequent&lt;/li&gt;
  &lt;li&gt;Then: If any subset of itemset S is infrequent, then there is no change for S to be frequent&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;先在所有的数据集中找出每个item出现的频率&lt;/li&gt;
  &lt;li&gt;删除频率低的&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;我们就得到了出现频率大于某个阀值的items&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;通过第一次得到的数据，再去数据集中去查询同时出现2个商品，并记录他们的频率&lt;/li&gt;
  &lt;li&gt;删除其中出现频率低的&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这样我们就得到了出现频率大于某个阀值的一对items&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;通过第二次得到的数据，再去数据集中查询同时出现的3个商品，并记录他们的频率&lt;/li&gt;
  &lt;li&gt;删除其中频率低的&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这样我们就得到了一组频率大于某个阀值的3个同时出现的items&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;通过上面的算法，继续计算更多商品同时出现的频率。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Improvements:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Reduce passes of transaction database scans
    &lt;ul&gt;
      &lt;li&gt;Partitioning: Scan database only twice&lt;/li&gt;
      &lt;li&gt;Partition database and find local frequent patterns&lt;/li&gt;
      &lt;li&gt;Consilidate global frequent patterns&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Shrink the number of candidates&lt;/li&gt;
  &lt;li&gt;Exploring special data structure&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;eclat&quot;&gt;Eclat&lt;/h3&gt;

&lt;p&gt;Basic info&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Theory: Exploring vertical Data Format&lt;/li&gt;
  &lt;li&gt;Whole NameEquivalence Class Transformation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Method:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;给每个item建立索引，然后做并集&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Improvement：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果他们的并集很大的话，可以用他们的并集取反来来存贮结果，这样存贮和计算效率会更高。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;fpgrowth&quot;&gt;FPgrowth&lt;/h3&gt;

&lt;p&gt;Basic info&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;FP-tree&lt;/li&gt;
  &lt;li&gt;Mine each conditional pattern-base recursively&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;需要扫描两次数据集&lt;/li&gt;
  &lt;li&gt;第一次统计所有items的出现频率，删除频率较低的，然后对所有items按出现频率排序&lt;/li&gt;
  &lt;li&gt;第二次扫描，把所有的数据生成一棵树&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;相同商品，在不同的分支之间，应该关联起来。这样在第二部分的统计的时候会方便。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;分析生成的FP-tree，然后从下向上统计出与每个商品同时出现的商品。&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Pattern Evaluation</title>
   <link href="http://zhou-dong.github.io/2015/04/12/pattern-evaluation"/>
   <updated>2015-04-12T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/04/12/pattern-evaluation</id>
   <content type="html">
&lt;p&gt;在同一个系统的中：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;不同的level应该有不同的阀值&lt;/li&gt;
  &lt;li&gt;不同的商品也应该有不同的阀值&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Multi-Dimensional Associations&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;single-dimensional 如果A买苹果，也买了香蕉&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Inter-dimensional 如果A是18-25岁，并且是学生，所以买coke&lt;/li&gt;
  &lt;li&gt;Hybrid-dimensional 如果A是18-25岁，并且买popcorn，可能会买coke&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Mining Quantitative Associations&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Numberical atrributes: age and salary&lt;/li&gt;
  &lt;li&gt;Deviation analysis: gender: male and female&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rare Patterns vs. Negative Patterns&lt;/p&gt;

&lt;p&gt;Rare Patterns&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Very low support but interesting&lt;/li&gt;
  &lt;li&gt;How to mine them? different group-based thresholds&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nagative Patterns&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nagetively corealted &lt;/li&gt;
  &lt;li&gt;How to define&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Constraint Based Mining&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Different kinds of constraints lead to different pruning strategies&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;constraints can be categorized as&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pattern sapce pruning (pruning某些data)
    &lt;ul&gt;
      &lt;li&gt;Anti-monotonic&lt;/li&gt;
      &lt;li&gt;Monotonic&lt;/li&gt;
      &lt;li&gt;Succinct&lt;/li&gt;
      &lt;li&gt;Convertible&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;data space pruning (pruning 一个data的一部分)
    &lt;ul&gt;
      &lt;li&gt;Data succinct&lt;/li&gt;
      &lt;li&gt;Data anti-monotonic&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sequence Patterns&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Sequence Databases&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Gapped sequential patterns (GSP)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Non-gapped sequential patterns&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Generalized Sequential Patterns&lt;/li&gt;
  &lt;li&gt;Vertical format-based&lt;/li&gt;
  &lt;li&gt;Pattern-growth methods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pattern-Based Classification&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;apple pie&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;apple ipad&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;pattern first, then classification&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;CBA (Classification Based on Associations)&lt;/li&gt;
  &lt;li&gt;CMAR&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Discriminative Patterns&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;选取数据集中最具代表性的properties&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Courses In Data Mining</title>
   <link href="http://zhou-dong.github.io/data-mining/2015/04/11/courses-data-mining"/>
   <updated>2015-04-11T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/data-mining/2015/04/11/courses-data-mining</id>
   <content type="html">
&lt;ul&gt;
  &lt;li&gt;Pattern Discovery in Data Mining
    &lt;ol&gt;
      &lt;li&gt;A Brief Introduction to Data Mining
        &lt;ul&gt;
          &lt;li&gt;We are drowning in Data but straving for knowledge!&lt;/li&gt;
          &lt;li&gt;Necessity is the mother of invention&lt;/li&gt;
          &lt;li&gt;Knowledge mining from Data&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Pattern Discovery: Basic Concepts&lt;/li&gt;
      &lt;li&gt;Efficient Pattern Mining Methods
        &lt;ul&gt;
          &lt;li&gt;Down closure Property of Frequent Pattern (Apriori) &lt;/li&gt;
          &lt;li&gt;Any subset of frequent itemset must be frequent&lt;/li&gt;
          &lt;li&gt;If any subset of an itemset S infrequent, then there is no change for S to be frequent&lt;/li&gt;
          &lt;li&gt;I think it is kind of Dynamic Programming&lt;/li&gt;
          &lt;li&gt;Scalable mining methods: 3 major approaches&lt;/li&gt;
          &lt;li&gt;Apriori&lt;/li&gt;
          &lt;li&gt;Eclat&lt;/li&gt;
          &lt;li&gt;FPgrowth&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Pattern Evaluation
        &lt;ul&gt;
          &lt;li&gt;Objective: By math to calculate&lt;/li&gt;
          &lt;li&gt;Subjective: One man’s trash could be another man’s treasure&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Mining Diverse Frequdent Patterns&lt;/li&gt;
      &lt;li&gt;Constraint-Based Pattern Mining&lt;/li&gt;
      &lt;li&gt;Sequential Pattern Mining&lt;/li&gt;
      &lt;li&gt;Graph Pattern Mining&lt;/li&gt;
      &lt;li&gt;Pattern-Based Classification&lt;/li&gt;
      &lt;li&gt;Pattern Analysis: Application Exploration&lt;/li&gt;
      &lt;li&gt;Futher Topics on Pattern Analysis&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;More data mining steps:
    &lt;ul&gt;
      &lt;li&gt;Data Mining Process step 1
        &lt;ul&gt;
          &lt;li&gt;Data cleaning&lt;/li&gt;
          &lt;li&gt;Data integration&lt;/li&gt;
          &lt;li&gt;Data normalization&lt;/li&gt;
          &lt;li&gt;Feature selection&lt;/li&gt;
          &lt;li&gt;Dimension reduction&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data Mining Process step 2
        &lt;ul&gt;
          &lt;li&gt;Multi-dimensional data summary&lt;/li&gt;
          &lt;li&gt;Pattern discovery&lt;/li&gt;
          &lt;li&gt;Association and correaltion&lt;/li&gt;
          &lt;li&gt;Classification&lt;/li&gt;
          &lt;li&gt;Clustering (How to group data from new categories)&lt;/li&gt;
          &lt;li&gt;Outlier analysis (Discovery of anomalies and rare events)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data mining Process step 3
        &lt;ul&gt;
          &lt;li&gt;Pattern evalution&lt;/li&gt;
          &lt;li&gt;Pattern selection&lt;/li&gt;
          &lt;li&gt;Pattern interpretation&lt;/li&gt;
          &lt;li&gt;Pattern visualization &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data mining include:
    &lt;ul&gt;
      &lt;li&gt;Machine Learning&lt;/li&gt;
      &lt;li&gt;Statistics&lt;/li&gt;
      &lt;li&gt;Pattern Recognition&lt;/li&gt;
      &lt;li&gt;Applications&lt;/li&gt;
      &lt;li&gt;Visualization&lt;/li&gt;
      &lt;li&gt;Algorithm&lt;/li&gt;
      &lt;li&gt;Database Technology&lt;/li&gt;
      &lt;li&gt;Distributed/Cloud computing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Text Retrieval and Search Engines&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster Analysis in Data Mining&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Text Mining and Analytics&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Visualization&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Mining Capstone&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Protein</title>
   <link href="http://zhou-dong.github.io/protein/2015/03/28/protein-type"/>
   <updated>2015-03-28T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/protein/2015/03/28/protein-type</id>
   <content type="html">
&lt;p&gt;Protein Structure:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;一级结构：氨基酸的序列 &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;二级结构：由氨基酸序列构成的物理结构&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;三级结构：三维的folding结构&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;Protein Type:&lt;/p&gt;

&lt;p&gt;肉类蛋白，豆类蛋白，乳清蛋白，奶中的蛋白，和蔬菜蛋白之间的区别：&lt;/p&gt;

&lt;p&gt;动物蛋白和蔬菜蛋白之间的区别：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先人类的身体的可以制造出大部分自己所需要的蛋白质来。&lt;/li&gt;
  &lt;li&gt;但是有9种氨基酸人类制造不出来，必须从我们的食物中获取&lt;/li&gt;
  &lt;li&gt;大多数的动物蛋白质都包含人类所必须的9中氨基酸。&lt;/li&gt;
  &lt;li&gt;植物蛋白也可能包含我们所需要的蛋白质，但是含量可能不是很理想。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;肉蛋白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一提到肉蛋白，大多数人可能会想到：牛肉。&lt;/li&gt;
  &lt;li&gt;牛肉蛋白里面包含人类所需的所有氨基酸&lt;/li&gt;
  &lt;li&gt;但是纯度其实不高，20%的牛肉重量是蛋白质&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;而且营养元素的含量也不高&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;3盎司的牛肉中大约包含：
    &lt;ul&gt;
      &lt;li&gt;23 克蛋白质&lt;/li&gt;
      &lt;li&gt;15 克脂肪&lt;/li&gt;
      &lt;li&gt;蛋白质净使用率73&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;家禽蛋白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;人们一般觉得跟牛肉相比鸡肉包含较少的营养元素，事实上&lt;/li&gt;
  &lt;li&gt;3盎司的鸡肉瘦肉（不含皮肤）包含：
    &lt;ul&gt;
      &lt;li&gt;27 克蛋白质&lt;/li&gt;
      &lt;li&gt;2-3克脂肪&lt;/li&gt;
      &lt;li&gt;蛋白质净使用率80&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;鱼肉脂肪：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;鱼肉里面包含大量的蛋白质，关键的是里面没有碳水化合物，而且只有少量脂肪&lt;/li&gt;
  &lt;li&gt;它的脂肪里面包含大量对人类有益的Omega-3 fatty acids（omega-3饱和脂肪酸）&lt;/li&gt;
  &lt;li&gt;3盎司鱼肉中：
    &lt;ul&gt;
      &lt;li&gt;蛋白质净使用率81&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;猪肉蛋白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果不是来自第三世界国家，吃垃圾长大的猪，猪肉的质量还是可以保证对人类无害的&lt;/li&gt;
  &lt;li&gt;现在证明：
    &lt;ul&gt;
      &lt;li&gt;猪肉和牛肉、鸡肉一样健康&lt;/li&gt;
      &lt;li&gt;猪肉相对牛肉其实更容易消化&lt;/li&gt;
      &lt;li&gt;猪肉含有相对较高的脂肪&lt;/li&gt;
      &lt;li&gt;全美的猪肉质量是有保证的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;奶蛋白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;很多人对奶蛋白过敏&lt;/li&gt;
  &lt;li&gt;蛋白质净使用率81&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;乳清蛋白:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当前最好的蛋白质来源&lt;/li&gt;
  &lt;li&gt;蛋白质的使用率90-100&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;鸡蛋：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In fact, the whole biological value scale is based on egg protein ranking a benchmark 100&lt;/li&gt;
  &lt;li&gt;鸡蛋蛋白是最容易引起过敏的。&lt;/li&gt;
  &lt;li&gt;吃整鸡蛋比光是蛋白含有更多的营养。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;豆类蛋白质：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;豆类其实不是一个有效的蛋白质的来源。&lt;/li&gt;
  &lt;li&gt;豆类中包含很多过敏的元素，而且都会有抑制矿物质元素的吸收。&lt;/li&gt;
  &lt;li&gt;蛋白质的包含量：70-70&lt;/li&gt;
  &lt;li&gt;蛋白质的净利用率只有61&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;谷物&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;虽有谷物和豆类包含了人类所需的蛋白质。但是氨基酸的包含比例是不平衡的。&lt;/li&gt;
  &lt;li&gt;所以食用纯素的时候，可能需要根据蛋白质的含量不同，食用不同比例的食物&lt;/li&gt;
  &lt;li&gt;所以如果纯食素的话，对运动员、减肥的人、病人是不好的。&lt;/li&gt;
  &lt;li&gt;如果需要健身的话，需要高纯度的蛋白质的，而且需要合理的氨基酸比例&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;resource from: http://www.nutribodyprotein.com/protein-types.php&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Intro of Bioinformatics</title>
   <link href="http://zhou-dong.github.io/bioinformatics/2015/03/27/intro"/>
   <updated>2015-03-27T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/bioinformatics/2015/03/27/intro</id>
   <content type="html">
&lt;p&gt;bioinformatics about：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;gene：基因&lt;/li&gt;
  &lt;li&gt;genome：基因组&lt;/li&gt;
  &lt;li&gt;protein：蛋白质&lt;/li&gt;
  &lt;li&gt;cell：细胞&lt;/li&gt;
  &lt;li&gt;amino acid：氨基酸&lt;/li&gt;
  &lt;li&gt;nucleotide：核酸&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;bioinformatics aim：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;预测&lt;/li&gt;
  &lt;li&gt;建模&lt;/li&gt;
  &lt;li&gt;设计&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;database：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;primary database: DNA and “amino acid” sequence&lt;/li&gt;
  &lt;li&gt;secondary database: fingerprint, profile, block&lt;/li&gt;
  &lt;li&gt;teriary database: domains, folding&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;sequence alignment:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Identify very short exact matches&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Dynamic Programming&lt;/li&gt;
  &lt;li&gt;HMM&lt;/li&gt;
  &lt;li&gt;FASTA&lt;/li&gt;
  &lt;li&gt;BLAST&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Website: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;www.expasy.org&lt;/li&gt;
  &lt;li&gt;ncbi&lt;/li&gt;
  &lt;li&gt;biopython&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>FASTA AND BLAST</title>
   <link href="http://zhou-dong.github.io/fasta/blast/bioinformatics/2015/03/26/fasta-blast"/>
   <updated>2015-03-26T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/fasta/blast/bioinformatics/2015/03/26/fasta-blast</id>
   <content type="html">
&lt;p&gt;Pairwise alignment&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Global
    &lt;ul&gt;
      &lt;li&gt;Best score from among alignments of full-length sequences&lt;/li&gt;
      &lt;li&gt;Needelman-Wunch algorithm&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Local
    &lt;ul&gt;
      &lt;li&gt;Best score form among alignments of partial sequences&lt;/li&gt;
      &lt;li&gt;Smith-Waterman algorithm&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;FASTA: First fast sequence search algorithm for comparing query sequency against a database&lt;/p&gt;

&lt;p&gt;BLAST: Basic Locial Alignment Search Technique, improvement of FASTA: search speed, ease of use, statistics rigor.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;FASTA and BLAST&lt;/p&gt;

&lt;p&gt;Dynamic programming&lt;/p&gt;

&lt;p&gt;Basic idea: short lengths of exact matches:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First: identify very short exact matches&lt;/li&gt;
  &lt;li&gt;Next: the best short hits from the first step are extended to longer regions of similarity&lt;/li&gt;
  &lt;li&gt;Finally: the best hits are optimized&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;FASTA Algorithm:&lt;/p&gt;

&lt;p&gt;Derived from logic of dot plot&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;computer best diagonals from all frames of alignment&lt;/li&gt;
  &lt;li&gt;the method look for exact matches between words in query and test sequence
    &lt;ul&gt;
      &lt;li&gt;DNA sequence are usually 6 nucleotides long&lt;/li&gt;
      &lt;li&gt;protein words are 2 amino acids long&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Five steps of FASTA:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;idenfity common k-words between I and J （把query和Test同时放在一个matrix中）&lt;/li&gt;
  &lt;li&gt;score diagonals with k-word matches, identify 10 best diagonals （在matrix中，标记处横坐标和纵坐标相同的点，然后连城线段）&lt;/li&gt;
  &lt;li&gt;recore initial regions with a substitution of matrix (把一些较短的线段的分值调低)&lt;/li&gt;
  &lt;li&gt;join inital regions with gaps, penalise for gaps&lt;/li&gt;
  &lt;li&gt;perform dynamic programming to find final alignments&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;BLAST Algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BLAST can not handle gaps well&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Three steps of BLAST:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;word search method
    &lt;ul&gt;
      &lt;li&gt;find the list of high scoring words of length w&lt;/li&gt;
      &lt;li&gt;compare the word list to database and identify exact matches&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;identification of exact word method
    &lt;ul&gt;
      &lt;li&gt;break the query into words&lt;/li&gt;
      &lt;li&gt;break the database sequences into words&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;maximum segment pair alignment method
    &lt;ul&gt;
      &lt;li&gt;extend hits one base at a time&lt;/li&gt;
      &lt;li&gt;scroing of alignment&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The result of word matching and attemps to extend the alignment are segments called HSPs:
- high scoring segmeng pair&lt;/p&gt;

&lt;p&gt;BLAST ofter product sereral short HSPs&lt;/p&gt;

&lt;p&gt;WEBSITE: www.expasy.org&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Bioinformatics</title>
   <link href="http://zhou-dong.github.io/bioinformatics/2015/03/26/bioinformatics"/>
   <updated>2015-03-26T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/bioinformatics/2015/03/26/bioinformatics</id>
   <content type="html">
&lt;p&gt;Analysis of: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;gene&lt;/li&gt;
  &lt;li&gt;genome&lt;/li&gt;
  &lt;li&gt;protein&lt;/li&gt;
  &lt;li&gt;cell&lt;/li&gt;
  &lt;li&gt;ecological system&lt;/li&gt;
  &lt;li&gt;medical information&lt;/li&gt;
  &lt;li&gt;robots&lt;/li&gt;
  &lt;li&gt;artifical intelligence&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Use the knowledge for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;prediction&lt;/li&gt;
  &lt;li&gt;modelling&lt;/li&gt;
  &lt;li&gt;design&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;amino acid: 氨基酸&lt;/p&gt;

&lt;p&gt;data type：&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;primary data&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;sequence&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;–&amp;gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;primary database&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;AATGCGTAAGTC&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DNA&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DMPVERILEALAVE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;amino acid&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;secondary data&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;secondary protein structure&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;–&amp;gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;secondary db&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;“motif”&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;regular expressions&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;block&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;profiles&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;fingerprints&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;teriary data&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;teriary protein structure&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;–&amp;gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;teriary db&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;atomic co-ordinates&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;domains, folding units&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;databases:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Nucleotide: 核酸
    &lt;ul&gt;
      &lt;li&gt;primary db&lt;/li&gt;
      &lt;li&gt;secondary db&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;tritiary db&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;EMBL [The European Molecular Boilogy Laboratory] Germany&lt;/li&gt;
      &lt;li&gt;GenBank &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;DDBJ [DNA data bank of Janpan]&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;All together is under INSDC [International Nucleotide Sequence Databases] &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;protein
    &lt;ul&gt;
      &lt;li&gt;sequence
        &lt;ul&gt;
          &lt;li&gt;Uniprot&lt;/li&gt;
          &lt;li&gt;PIR&lt;/li&gt;
          &lt;li&gt;SwissProt&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;interaction
        &lt;ul&gt;
          &lt;li&gt;Biogrid&lt;/li&gt;
          &lt;li&gt;STRING&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;structure
        &lt;ul&gt;
          &lt;li&gt;PDB&lt;/li&gt;
          &lt;li&gt;CATH&lt;/li&gt;
          &lt;li&gt;SCOPE&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;INSDC [International Nucleotide Sequence Databases]
    &lt;ul&gt;
      &lt;li&gt;EMBL (EUROPE)
        &lt;ul&gt;
          &lt;li&gt;EMBL&lt;/li&gt;
          &lt;li&gt;EBI&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;DDBJ (JAPAN)
        &lt;ul&gt;
          &lt;li&gt;NIG&lt;/li&gt;
          &lt;li&gt;CIB&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;GenBank (USA)
        &lt;ul&gt;
          &lt;li&gt;NLM&lt;/li&gt;
          &lt;li&gt;NCBI&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;sequence alignment&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;2&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;3&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;4&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;5&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;6&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;A&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;G&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&amp;gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sequence one&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;A&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&amp;gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sequcece two&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GAP&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MISMATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;we wanna use that way to get maximum match&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;2&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;3&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;4&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;5&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;6&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;A&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;G&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&amp;gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sequence one&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;A&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&amp;gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sequcece two&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MISMATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MISMATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MISMATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GAP&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;Score for sequcen alignment&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Match &lt;strong&gt;positive&lt;/strong&gt; score&lt;/li&gt;
  &lt;li&gt;Mismatch &lt;strong&gt;negtive&lt;/strong&gt; score&lt;/li&gt;
  &lt;li&gt;Gap &lt;strong&gt;negtive&lt;/strong&gt; score&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Align sequence must be more than one sequence&lt;/p&gt;

&lt;p&gt;Align sequence is basic of the bioinformatics&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Radial Basis Function Network</title>
   <link href="http://zhou-dong.github.io/rbf/2015/03/20/rbf"/>
   <updated>2015-03-20T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/rbf/2015/03/20/rbf</id>
   <content type="html">&lt;p&gt;Radial Basis Function Network&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;radial: only depends on distance between x and ‘center’ x_n&lt;/li&gt;
  &lt;li&gt;basis function: to be ‘combined’&lt;/li&gt;
  &lt;li&gt;跟半径有关的预测方式&lt;/li&gt;
  &lt;li&gt;其实中心店就是support vectors&lt;/li&gt;
  &lt;li&gt;找到那些中心点，和中心店的系数&lt;/li&gt;
  &lt;li&gt;可是利用kernel&lt;/li&gt;
  &lt;li&gt;Near neighbor&lt;/li&gt;
  &lt;li&gt;k-means algorithm: partition optimization&lt;/li&gt;
  &lt;li&gt;RBF using k-means&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;K-Means&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;无监督的学习&lt;/li&gt;
  &lt;li&gt;分类算法&lt;/li&gt;
  &lt;li&gt;先找定好要分成几个点，然后逐步优化接近&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;先用k-means找出代表，然后再继续使用rbf&lt;/p&gt;

&lt;p&gt;可以把高纬度的数据放到低纬度的空间来做运算&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;压缩方法转换&lt;/li&gt;
  &lt;li&gt;投影的方法转换&lt;/li&gt;
  &lt;li&gt;也可以通过其他的方法来降维&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最基本的最佳化的方法是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;梯度下降 gradient descent&lt;/li&gt;
  &lt;li&gt;牛顿法下降&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Equivalent Solution&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SVM的对偶问题&lt;/li&gt;
  &lt;li&gt;kernel logistic regression&lt;/li&gt;
  &lt;li&gt;PCA&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Multiple Steps&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;probabilistic SVM &lt;/li&gt;
  &lt;li&gt;linear blending&lt;/li&gt;
  &lt;li&gt;stacking&lt;/li&gt;
  &lt;li&gt;RBF network&lt;/li&gt;
  &lt;li&gt;deep learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Alternating optimization&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;k-means&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Divide and conquer&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;decision tree&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;overfitting elimination via regularization&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;large-margin
    &lt;ul&gt;
      &lt;li&gt;svm&lt;/li&gt;
      &lt;li&gt;adaboost&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;L2 regularization
    &lt;ul&gt;
      &lt;li&gt;SVR&lt;/li&gt;
      &lt;li&gt;kernel models&lt;/li&gt;
      &lt;li&gt;nnet&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;voting/averaging
    &lt;ul&gt;
      &lt;li&gt;uniform blending&lt;/li&gt;
      &lt;li&gt;bagging&lt;/li&gt;
      &lt;li&gt;random forest&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;denosing
    &lt;ul&gt;
      &lt;li&gt;autoencoder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;weight-elimination
    &lt;ul&gt;
      &lt;li&gt;NNET&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;pruning
    &lt;ul&gt;
      &lt;li&gt;decision tree&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;early stopping
    &lt;ul&gt;
      &lt;li&gt;RBF&lt;/li&gt;
      &lt;li&gt;auto encoder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;constraining&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Neural Netword & Deep Learning</title>
   <link href="http://zhou-dong.github.io/machine/learning/neural/deep/2015/03/20/neural-network"/>
   <updated>2015-03-20T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine/learning/neural/deep/2015/03/20/neural-network</id>
   <content type="html">&lt;p&gt;Neural Netword&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一层一层的做运算，一层的输出作为另一层的输入，层层递进。&lt;/li&gt;
  &lt;li&gt;每一层可以用以前学的方法来执行。&lt;/li&gt;
  &lt;li&gt;经过多层的运算，我们希望我们得到的结果是好的。&lt;/li&gt;
  &lt;li&gt;可以用gradient descent来实现，来一步一步的做最佳化&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;其实gradient descent就是做偏微分。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;因为经过了多次的转化 ，所以可能得不到最优解。&lt;/li&gt;
  &lt;li&gt;可能得到的是局部最优解，而不是全局最优解，所以需要
    &lt;ul&gt;
      &lt;li&gt;选好梯度下降的起始点&lt;/li&gt;
      &lt;li&gt;选好梯度下降的步伐&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;同时要防止overfitting
    &lt;ul&gt;
      &lt;li&gt;需要regularization for neural network&lt;/li&gt;
      &lt;li&gt;Early Stopping，在某个中间点就停下来。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Deep Learning&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deep neural network
    &lt;ul&gt;
      &lt;li&gt;每一层找出不同的内容，即每层做一点点的东西&lt;/li&gt;
      &lt;li&gt;多层之间的结果合并&lt;/li&gt;
      &lt;li&gt;给出结果&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;通过每层来做一些简单的东西，然后多层合并，最终可以做复杂的运算&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;difficult structure decisions: 
        &lt;ul&gt;
          &lt;li&gt;解决方法之一是加上人对某个领域的理解&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;high model complexity: 
        &lt;ol&gt;
          &lt;li&gt;no big worries if big enough data&lt;/li&gt;
          &lt;li&gt;regularization towards noise-tolerant,like dropout, denoising&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;hard optimization
        &lt;ul&gt;
          &lt;li&gt;careful initialization to avoid bad local minimun called pre-training&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;huge computational complexity
        &lt;ul&gt;
          &lt;li&gt;novel hardware/architecture: like mini-batch with GPU&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Autoencoder
    &lt;ul&gt;
      &lt;li&gt;information-preserving encoding&lt;/li&gt;
      &lt;li&gt;usefulness of approximating identity function&lt;/li&gt;
      &lt;li&gt;首先先查找每一层之间维度的抽取&lt;/li&gt;
      &lt;li&gt;然后在一层给维度编码&lt;/li&gt;
      &lt;li&gt;在另一层给相同维度解码&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Denoising Autoencoder
    &lt;ul&gt;
      &lt;li&gt;this is one of regularization&lt;/li&gt;
      &lt;li&gt;加上一些条件使得每一层之间的连接没有那么多&lt;/li&gt;
      &lt;li&gt;可能Early stopping的效果更好&lt;/li&gt;
      &lt;li&gt;杂絮越多，资料越少，越容易overfitting
        &lt;ol&gt;
          &lt;li&gt;直接的想法是，想办法删除杂絮&lt;/li&gt;
          &lt;li&gt;另外特殊的想法是，把杂絮加到资料中&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;我们的目标是创建强壮的程序&lt;/li&gt;
      &lt;li&gt;即使是资料中有杂絮，也能有好的输出&lt;/li&gt;
      &lt;li&gt;所以我们可以输入有杂絮的资料，然后返回干净的资料&lt;/li&gt;
      &lt;li&gt;所以我们可以把干净的资料变为干净的资料&lt;/li&gt;
      &lt;li&gt;而且我们更可以把不干净的资料变为干净的资料&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;principal Component Analyze&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Decision Tree and Random Forest</title>
   <link href="http://zhou-dong.github.io/machine/learning/decision/tree/random/forest/2015/03/20/forest"/>
   <updated>2015-03-20T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine/learning/decision/tree/random/forest/2015/03/20/forest</id>
   <content type="html">&lt;p&gt;Decision Tree&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先要考虑tree停下来的条件&lt;/li&gt;
  &lt;li&gt;可以用binary tree&lt;/li&gt;
  &lt;li&gt;Build subtree&lt;/li&gt;
  &lt;li&gt;final return&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;C &amp;amp; RT 算法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;避免overfitting&lt;/li&gt;
  &lt;li&gt;Regularization by Pruning&lt;/li&gt;
  &lt;li&gt;E in 要低，而且叶子节点也不要太多&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以pruning（修剪）decision tree&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;比adaboost要有效率一些&lt;/li&gt;
  &lt;li&gt;adaboost每次都是全部切分&lt;/li&gt;
  &lt;li&gt;C &amp;amp; RT在局部切分，会更有效率一些&lt;/li&gt;
  &lt;li&gt;adaboost和decision tree的切分结果可能会不同&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Random Forest&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bagging + Decision Tree&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bagging first, then Decision Tree&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;先对资料随机抽样，比如可以从很多个特征中，抽取一定的特征做成一棵树&lt;/li&gt;
  &lt;li&gt;通过上面，可以变成一个低纬度的subspace处理&lt;/li&gt;
  &lt;li&gt;希望做成不一样的tree，然后再把他们合起来&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;找到low-dimensional的投影平面&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;out of bag estimate&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以用这些没有被使用的维度来判断结果好不好&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Feature Selection：怎么选择适当的特征，或者适当的输入&lt;/li&gt;
  &lt;li&gt;从多个维度中更有效的选取资料
    &lt;ul&gt;
      &lt;li&gt;如，年龄和生日这两个资料重复了&lt;/li&gt;
      &lt;li&gt;还有有些资料在我们的算法中是不需要的&lt;/li&gt;
      &lt;li&gt;通过算法自动降维，或者自动转换&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;可以降低计算复杂度&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以更好得避免overfitting&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;选择本身是有计算复杂度的&lt;/li&gt;
  &lt;li&gt;可能会选到不好的维度，而删除了好的维度&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果维度选择错误的话，可能会更加的overfitting&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;相当于是一个组合爆炸的问题&lt;/li&gt;
  &lt;li&gt;可以给每个维度打一个分数，然后找出里面分值最高的维度&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;permutation test&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;比decision tree的效果要平滑很多&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gradient Boosted Decision Tree&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;adaboost + Decision Tree&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Regression</title>
   <link href="http://zhou-dong.github.io/machine/learning/regression/2015/03/19/regression"/>
   <updated>2015-03-19T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine/learning/regression/2015/03/19/regression</id>
   <content type="html">&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;kernel Logistic Regression&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Support Vector Regression&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Kernel Ridge Regression: 利用kernel regression代替linear regression&lt;/li&gt;
      &lt;li&gt;Support Vector Regression Primal&lt;/li&gt;
      &lt;li&gt;即使是分割曲线相同，但是支撑点的个数可能不同，所以最后预测的复杂度也不同。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Aggregation</title>
   <link href="http://zhou-dong.github.io/machine/learning/aggregation/adaboost/2015/03/19/aggregation"/>
   <updated>2015-03-19T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine/learning/aggregation/adaboost/2015/03/19/aggregation</id>
   <content type="html">&lt;p&gt;Aggregation&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;融合各种方法在一起来提高分类效果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Blending：混合各种方法在一起. 各个算法的参数求均值。&lt;/p&gt;

&lt;p&gt;Linear blending：把各个算法的结果做线性组合。
    - LinMod + hypothesees as transform + constrains&lt;/p&gt;

&lt;p&gt;Bagging：边学习，边blending&lt;/p&gt;

&lt;p&gt;Adaptive Boosting&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;逐步增强，逐步添加限制条件。&lt;/li&gt;
  &lt;li&gt;可以通过增强或者惩罚来达到。&lt;/li&gt;
  &lt;li&gt;可以在犯过错的地方强调一下。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Diversity By Re-weighting&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;根据不同的部分给不同的weight&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adaptive Boosting Algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一刀一刀的切，放大错误的，缩小正确的，逐渐优化分类器&lt;/li&gt;
  &lt;li&gt;scaling factor&lt;/li&gt;
  &lt;li&gt;放大错误的&lt;/li&gt;
  &lt;li&gt;缩小正确的&lt;/li&gt;
  &lt;li&gt;做成功的应用是人脸识别&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Machine Learning Techniques Course Design</title>
   <link href="http://zhou-dong.github.io/machine/learning/svm/2015/03/18/course-design"/>
   <updated>2015-03-18T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine/learning/svm/2015/03/18/course-design</id>
   <content type="html">&lt;p&gt;Three major techniques surrouding &lt;code&gt;feature transforms&lt;/code&gt;（特征转换）:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Support Vector Machine (SVM) model (支撑向量机)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adaptive Boosting (AdaBoost) model（逐步增强法）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning model（深度学习）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Support Vector Machine</title>
   <link href="http://zhou-dong.github.io/machine/learning/svm/2015/03/18/SVM"/>
   <updated>2015-03-18T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/machine/learning/svm/2015/03/18/SVM</id>
   <content type="html">&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Linear Support Vector Machine&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;why use linear support vector machine:
        &lt;ul&gt;
          &lt;li&gt;PLA depending on randomness&lt;/li&gt;
          &lt;li&gt;tolerate more noise&lt;/li&gt;
          &lt;li&gt;more robust to overfitting&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;how to implement
        &lt;ol&gt;
          &lt;li&gt;w classifiles every (&lt;script type=&quot;math/tex&quot;&gt;x_n, y_n&lt;/script&gt;) correctly&lt;/li&gt;
          &lt;li&gt;fatness(w) = min distance(&lt;script type=&quot;math/tex&quot;&gt;x_n, w&lt;/script&gt;)&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;v_1x_1 + v_2x_2 = 0&lt;/script&gt;.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;method:
        &lt;ul&gt;
          &lt;li&gt;求两点之间的中锤线&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;steps:
        &lt;ul&gt;
          &lt;li&gt;一个平面到一个点的距离&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dual Support Vector Machine&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;每个点，到平面的距离，就相当于求每个点在平面上的投影&lt;/li&gt;
      &lt;li&gt;而且需要考虑的是对偶问题&lt;/li&gt;
      &lt;li&gt;利用lagrange来约束计算的复杂度&lt;/li&gt;
      &lt;li&gt;转化为解对偶的问题&lt;/li&gt;
      &lt;li&gt;找出在边界上并且大于0的点，作为support vectors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kernel Support Vector Machine&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Kernel Trick: 简化计算的复杂度&lt;/li&gt;
      &lt;li&gt;Polynomial Kernel: 二次转化的优化&lt;/li&gt;
      &lt;li&gt;Gaussian Kernel: 在SVM上利用Gaussian kernel优化计算，泰勒展开是实现&lt;/li&gt;
      &lt;li&gt;Comparison of Kernels&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sofe-Margin Support Vector Machine&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Motivation and Primal Problem: 为了避免overfiting，允许有杂绪。&lt;/li&gt;
      &lt;li&gt;记录每个点，违反的程度，而不是记录违反点的个数。&lt;/li&gt;
      &lt;li&gt;Dual Problem: 就是是soft也有可能会有overfitting&lt;/li&gt;
      &lt;li&gt;多项式的分割会更灵活&lt;/li&gt;
      &lt;li&gt;Message behind Soft-Margin&lt;/li&gt;
      &lt;li&gt;Model Selection: 可以选高斯kernel，也可以用其他的kernel来修改参数的值&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Neumann Kernal</title>
   <link href="http://zhou-dong.github.io/graphical/data/mining/2015/03/16/graphical-data-mining"/>
   <updated>2015-03-16T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/graphical/data/mining/2015/03/16/graphical-data-mining</id>
   <content type="html">
&lt;p&gt;Neumann Kernal&lt;/p&gt;

&lt;p&gt;NK: Diffusion Factor - Equation &amp;amp; Effect&lt;/p&gt;

&lt;p&gt;Neumann Kernel defines two matrices incorporating a diffusion factor:&lt;/p&gt;

&lt;p&gt;page 157&lt;/p&gt;

&lt;p&gt;HITS: is special case&lt;/p&gt;

&lt;p&gt;NK: is the generational&lt;/p&gt;

&lt;p&gt;Shared Nearest Neighbor(SNN) K-Nearest&lt;/p&gt;

&lt;p&gt;K 邻近&lt;/p&gt;

&lt;p&gt;邻近算法，或者说K最近邻(kNN，k-NearestNeighbor)分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。&lt;/p&gt;

&lt;p&gt;kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合。&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Jekyll Steps</title>
   <link href="http://zhou-dong.github.io/2015/03/13/jekyll-steps"/>
   <updated>2015-03-13T00:00:00-05:00</updated>
   <id>http://zhou-dong.github.io/2015/03/13/jekyll-steps</id>
   <content type="html">
&lt;p&gt;Create an jekyll project:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize new jekyll project: 
    &lt;ul&gt;
      &lt;li&gt;jekyll new troy-cssa&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Start jekyll project: 
    &lt;ul&gt;
      &lt;li&gt;jekyll server&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Default address: 
    &lt;ul&gt;
      &lt;li&gt;http://localhost:4000/&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Intro to jekyll project&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;_config.yml&lt;/li&gt;
  &lt;li&gt;_layouts&lt;/li&gt;
  &lt;li&gt;_posts&lt;/li&gt;
  &lt;li&gt;_site
    &lt;ul&gt;
      &lt;li&gt;jekyll will generate files into this folder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;css&lt;/li&gt;
  &lt;li&gt;index.html&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Notes for people-to-people</title>
   <link href="http://zhou-dong.github.io/2015/03/02/people-to-people"/>
   <updated>2015-03-02T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/03/02/people-to-people</id>
   <content type="html">
&lt;h4 id=&quot;natural-language-processing&quot;&gt;Natural Language Processing:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Stop word(should we eliminate stop word)&lt;/li&gt;
  &lt;li&gt;Word Tokenization
    &lt;ul&gt;
      &lt;li&gt;用自然语言分析，最归一化，如data mining == data mine, Nosql = NOSQL, &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;weight-of-the-attributes&quot;&gt;Weight of The Attributes:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Company Name Have &lt;code&gt;negative&lt;/code&gt; Weight&lt;/li&gt;
  &lt;li&gt;Others have the &lt;code&gt;positive&lt;/code&gt; Weight&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;cold-start-problem&quot;&gt;Cold start Problem&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;If most of the key words have the TF of 0, our result will not go will.&lt;/li&gt;
  &lt;li&gt;Answer: We initialize all the words with small weight to smooth the data.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Play with Galois Field</title>
   <link href="http://zhou-dong.github.io/matrix/python/2015/03/01/galois-field"/>
   <updated>2015-03-01T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/matrix/python/2015/03/01/galois-field</id>
   <content type="html">
&lt;h4 id=&quot;decsciption&quot;&gt;Decsciption:&lt;/h4&gt;

&lt;p&gt;Galois Field 2: has just two element 0 and 1&lt;/p&gt;

&lt;p&gt;Addition is like exclusive-or:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
 
    \begin{array}{c | c c } + &amp; 0 &amp; 1 \\
        \hline 
        0 &amp; 0 &amp; 1 \\
        1 &amp; 1 &amp; 0 \\
    \end{array}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Multiplication is like ordinary mutipication:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
 
    \begin{array}{c | c c } \times &amp; 0 &amp; 1 \\
        \hline 
        0 &amp; 0 &amp; 0 \\
        1 &amp; 0 &amp; 1 \\
    \end{array}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;And: &lt;script type=&quot;math/tex&quot;&gt; a \cdot (b + c) = a \cdot b + a \cdot c &lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;application&quot;&gt;Application:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Encription&lt;/li&gt;
  &lt;li&gt;Network coding&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>CS-5549 Midterm Review</title>
   <link href="http://zhou-dong.github.io/2015/03/01/cs-5549-midterm-review"/>
   <updated>2015-03-01T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/03/01/cs-5549-midterm-review</id>
   <content type="html">
&lt;h2 id=&quot;sorting-method&quot;&gt;Sorting Method&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Sort Name&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Description&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Best Case&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Worst Case&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Average Case&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BubbleSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;比较相邻的元素，第一个比第二个大就交换位置。对每个元素重复上一个步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;SelectionSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;每次查找剩下元素中最小的元素，然后放在已经排序好的前面序列的最后一位&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;InsertionSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;将当前元素插入到比它大的元素前,现实中比Bubble Sort，Selection Sort更有效&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GnomeSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;比较相邻元素如果第2个比第1个小替换位置并继续与前面的元素比较直到遇到比它大的。对每个元素重复上一个步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ShellSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;比较第i个和第i+n/2个元素，并继续与前i+n/2个元素比较，重复前面步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Depends on Gap Sequence&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;QuickSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1.找出pivot 2.从数组两边找出比pivot大和小的替换位置，直到大、小元素相遇确定pivot位置，循环上面的步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MergeSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;一半元素之间进行比较，然后合并。递归调用&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HeapSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;先建立一棵树，然后依次从数种取出root，heapify tree，再取出root直到数为空&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BucketSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;以最大数初始化空数组，然后循环要排序的数组，把下标为元素的值设置为1，打印初始数组&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CountingSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Bucketsort的优化版，先bucketsort，然后查看每个元素前面有多少个元素比它小，然后排序&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;RadixSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;一次从最后一位数取模，然后放在bucket中，然后再除以10取模，重复前面步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(N)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(kN)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;— — —&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;conclusion&quot;&gt;Conclusion:&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Heapsort、Mergesort会占用额外的空间。&lt;/li&gt;
  &lt;li&gt;Bucketsort、Countingsort、Radixsort要占用额外的空间，尤其是bucketsort和countingsort，占用空间不可控。而且对小数和分数很难支持。&lt;/li&gt;
  &lt;li&gt;一般排序的时候，使用的还是comparison，因为它对小数和分数有很好的支持，而且它的空间负责度也低。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;medians-and-order-statistics&quot;&gt;Medians and Order Statistics&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;同时找出最大值和最小值，有两种方法：
    &lt;ol&gt;
      &lt;li&gt;循环整个数组，一个元素与最大值比较一次，与最小值比较一次。&lt;/li&gt;
      &lt;li&gt;先比较两个元素，然后小的与最小值比较，大的与最大值比较。这样每两个数比较3次。
        &lt;ul&gt;
          &lt;li&gt;奇数个元素，从第2个元素开始循环&lt;/li&gt;
          &lt;li&gt;偶数个元素，从第3个元素开始循环&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Randomized Selection
    &lt;ol&gt;
      &lt;li&gt;与Quicksort相似，先找pivot，然后进行一轮排序&lt;/li&gt;
      &lt;li&gt;比较pivot是否在要查找的元素的位置：
        &lt;ul&gt;
          &lt;li&gt;如果是返回pivot&lt;/li&gt;
          &lt;li&gt;如果pivot的位置比要找元素的位置靠前，在后半个数组使用&lt;code&gt;Quicksort&lt;/code&gt;查找&lt;/li&gt;
          &lt;li&gt;如果pivot的位置比要找元素的位置靠后，在前半个数组使用&lt;code&gt;Quicksort&lt;/code&gt;查找&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Mideum of Mideum
    &lt;ul&gt;
      &lt;li&gt;作用：为了优化Quicksort和Randomized-Selection，我们需要找到中位数来做pivot&lt;/li&gt;
      &lt;li&gt;步骤：
        &lt;ol&gt;
          &lt;li&gt;把数组分成最小5份&lt;/li&gt;
          &lt;li&gt;在每份使用Insertion sort找出中位数&lt;/li&gt;
          &lt;li&gt;在这五份中位数中找出中位数&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;做为quicksort的中位数&lt;/li&gt;
      &lt;li&gt;Worst Case：
        &lt;ol&gt;
          &lt;li&gt;5份数据的第一份里面找出的是最小的20% = n/5,中位数等于 n/5/2 = 10%&lt;/li&gt;
          &lt;li&gt;在5份数据中的中位数，最少有多少个数小于中位数：3 * 10% = 30%&lt;/li&gt;
          &lt;li&gt;For large n, 3[n/10] &lt;script type=&quot;math/tex&quot;&gt;\le&lt;/script&gt; n/4&lt;/li&gt;
          &lt;li&gt;So at least n/4 elements &lt;script type=&quot;math/tex&quot;&gt;\le&lt;/script&gt; x&lt;/li&gt;
          &lt;li&gt;Similarly: at least n/4 elements &lt;script type=&quot;math/tex&quot;&gt;\ge&lt;/script&gt; x&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;recursion&quot;&gt;Recursion&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Telescoping&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt; T(n) = aT(n/b) + f(n) &lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;Example: Let: &lt;script type=&quot;math/tex&quot;&gt; a=2, \ b=2, \ f(n) = 1 &lt;/script&gt;&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th style=&quot;text-align: center&quot;&gt;Step&lt;/th&gt;
          &lt;th style=&quot;text-align: left&quot;&gt;Function One&lt;/th&gt;
          &lt;th style=&quot;text-align: center&quot;&gt;Equal&lt;/th&gt;
          &lt;th&gt;Functin Two&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 2T(n/2) + 1 &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^1T(n/2^1) + 1 &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 4T(n/4) + 1 + 1 &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^2T(n/2^2) + 2 &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 8T(n/8) + 1 + 1 + 1 &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^3T(n/2^3) + 3 &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = \ \ \ \ \ \ \  \vdots &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \ \ \ \ \ \ \  \vdots &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = nT(n/n) + \log_{2} n &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\log_{2}n}T(n/2^{\log_{2}n}) + \log_{2} n &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;Step1 + Step2 + &lt;script type=&quot;math/tex&quot;&gt; \cdots &lt;/script&gt; + Step5 :
  &lt;script type=&quot;math/tex&quot;&gt; T(n) = nT(1)  + \sum_{i=0}^{\log_{2}n} i \le n\log_2 n = n \lg_n&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Master Theorem&lt;/strong&gt; &lt;/p&gt;

    &lt;p&gt;Let a &lt;script type=&quot;math/tex&quot;&gt; \ge &lt;/script&gt; 1 and b &amp;gt; 1 be constants, let f(n) be a function. &lt;code&gt;T(n) = aT(n/b) + f(n)&lt;/code&gt; ;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = O(n^{\log_{b} a - \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a })&lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(n^{\log_{b} a}) &lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a} \lg n) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Omega(n^{\log_{b} a + \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &lt;/script&gt; &amp;gt; 0 , and if &lt;script type=&quot;math/tex&quot;&gt; af(n/b) \le cf(n)&lt;/script&gt; for some constant c &amp;lt; 1 and all sufficiently large n, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(f(n))&lt;/script&gt;.&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Examples: &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  2T(n/2) + n^4 &lt;/script&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; a = 2, \ b = 2, \ f(n) = n^4 &lt;/script&gt; ,&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\log_{b} a} = n^{\log_{2} 2} = n^1 &lt;/script&gt; ,&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; f(n) = n^4 = \Omega(n^{\log_{b}a + \epsilon})  = \Omega(n^{1 + 3}) &lt;/script&gt; ,&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \epsilon = 3  &lt;/script&gt; ,&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \therefore \  T(n) = \Theta(n^4) &lt;/script&gt; .&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;datastructure&quot;&gt;Datastructure&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Binary Tree
    &lt;ul&gt;
      &lt;li&gt;one root&lt;/li&gt;
      &lt;li&gt;every node has no parent&lt;/li&gt;
      &lt;li&gt;every node can have at most two children&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Complete Binary Tree
    &lt;ul&gt;
      &lt;li&gt;Is Binary Tree&lt;/li&gt;
      &lt;li&gt;In every level, except possibly the last, is completely filled&lt;/li&gt;
      &lt;li&gt;Basic for HeapSort&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Binary Search Tree
    &lt;ul&gt;
      &lt;li&gt;Is Binary Tree&lt;/li&gt;
      &lt;li&gt;Left child is small&lt;/li&gt;
      &lt;li&gt;Right child is bigger&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Avl Tree
    &lt;ul&gt;
      &lt;li&gt;Is Binary Search Tree&lt;/li&gt;
      &lt;li&gt;Balanced Tree&lt;/li&gt;
      &lt;li&gt;left child level is less than or eq 1 to right level&lt;/li&gt;
      &lt;li&gt;compore to Red Black Tree more balanced&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Red Black Tree
    &lt;ul&gt;
      &lt;li&gt;Is Binary Search Tree&lt;/li&gt;
      &lt;li&gt;Balanced Tree&lt;/li&gt;
      &lt;li&gt;Use 5 rules to make sure tree is Balanced&lt;/li&gt;
      &lt;li&gt;Popular in memory, compare to Avl Tree has less rotations&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;B Tree
    &lt;ul&gt;
      &lt;li&gt;Not Binary Tree&lt;/li&gt;
      &lt;li&gt;One node has more than two children&lt;/li&gt;
      &lt;li&gt;Self balanced tree&lt;/li&gt;
      &lt;li&gt;Popular in databases&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;B Plus Tree
    &lt;ul&gt;
      &lt;li&gt;Enhanced B Tree&lt;/li&gt;
      &lt;li&gt;All value instored in leafs&lt;/li&gt;
      &lt;li&gt;Leaf connected to next and above&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;big-o-notation&quot;&gt;Big O Notation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; O &lt;/script&gt; : Less than (Worst Situation)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; o &lt;/script&gt; : Less or Equal&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \Omega &lt;/script&gt; : Bigger than (Best Situation)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \omega &lt;/script&gt; : Big or Equal&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta &lt;/script&gt; : Between { &lt;script type=&quot;math/tex&quot;&gt; O,\ \ \Omega &lt;/script&gt; }&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dynamic-programming&quot;&gt;Dynamic Programming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;What situation we will use dynamic Programming
    &lt;ol&gt;
      &lt;li&gt;Can be divided into small parts&lt;/li&gt;
      &lt;li&gt;Small parts have &lt;code&gt;Optimal Structure&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;Prove or&lt;/li&gt;
          &lt;li&gt;Persuade Or Convince&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Equation&lt;/li&gt;
      &lt;li&gt;Build Table&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Longest common subsequence
    &lt;ul&gt;
      &lt;li&gt;Two Rules:
        &lt;ol&gt;
          &lt;li&gt;If same, shoulder += 1&lt;/li&gt;
          &lt;li&gt;If not same, choose bigger one from both sides&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Create Table:
  &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

  X = {B A D C B A B} \\
  Y = {A C D B C A} \\
  \begin{array}{|c|c|c|c|c|c|c|}
  \hline
  0 &amp;x_i &amp; B &amp; A &amp; D &amp; C &amp; B &amp; A &amp; B \\
  \hline
  y_i&amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
  \hline
  A  &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
  \hline
  C  &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 \\
  \hline
  D  &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 \\
  \hline
  B  &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 3 \\
  \hline
  C  &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 \\
  \hline
  A  &amp; 0 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 4 &amp; 4 \\
  \hline
  \end{array}
   %]]&gt;&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;Decode:
        &lt;ul&gt;
          &lt;li&gt;A D C A&lt;/li&gt;
          &lt;li&gt;A D B A&lt;/li&gt;
          &lt;li&gt;A C B A&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Matrix-chain multiplication
    &lt;ul&gt;
      &lt;li&gt;i must less than j&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_1 = (30 \times 35) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_2 = (35 \times 15) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_3 = (15 \times 5) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_4 = (5 \times 10) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_5 = (10 \times 20) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_6 = (20 \times 25) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;Tables:
  &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

  \begin{array}{|c|c|c|c|c|c|c|}
   \hline
  -- &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6  \\
  \hline
  6  &amp; 15125 &amp; 10500 &amp; 5375 &amp; 3500 &amp; 5000 &amp; 0  \\
  \hline
  5  &amp; 11875 &amp; 7125 &amp; 2500 &amp; 1000 &amp; 0 &amp; -  \\
  \hline
  4  &amp; 9375 &amp; 4375 &amp; 750 &amp; 0 &amp; - &amp; -  \\
  \hline
  3  &amp; 7875 &amp; 2625 &amp; 0 &amp; - &amp; - &amp; -  \\
  \hline
  2  &amp; 15750 &amp; 0 &amp; - &amp; - &amp; - &amp; -  \\
  \hline
  1  &amp; 0 &amp; - &amp; - &amp; - &amp; - &amp; -  \\
  \hline
  \end{array}
   %]]&gt;&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(1,2) = min(1,1) + min(2,2) + p_0 \times p_1 \times p_2 = 0 + 0 + 30 * 35 * 15 = 15750 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(2,3) = min(2,2) + min(3,3) + p_1 \times p_2 \times p_3 = 0 + 0 + 35 * 15 * 5 = 2625 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(3,4) = min(3,3) + min(4,4) + p_2 \times p_3 \times p_4 = 0 + 0 + 15 * 5 * 10 = 750 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(4,5) = min(4,4) + min(5,5) + p_3 \times p_4 \times p_5 = 0 + 0 + 5 * 10 * 20 = 1000 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(5,6) = min(5,5) + min(6,6) + p_4 \times p_5 \times p_6 = 0 + 0 + 10 * 20 * 25 = 5000 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;
   min(1,3) = min(1,1) + min(2,3) + p_0 \times p_1 \times p_3 = 0 + 2625 + 30 * 35 * 5 = 2625 + 5250 = 7875 \\
   min(1,3) = min(1,2) + min(3,3) + p_0 \times p_2 \times p_3 = 15750 + 30 * 15 * 5 = 18000
&lt;/script&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Play with complex numbers</title>
   <link href="http://zhou-dong.github.io/python/matrix/2015/02/28/playing-with-complex-number"/>
   <updated>2015-02-28T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/python/matrix/2015/02/28/playing-with-complex-number</id>
   <content type="html">
&lt;h4 id=&quot;complex-number-as-points-in-the-complex-plane&quot;&gt;Complex number as points in the complex plane&lt;/h4&gt;

&lt;p&gt;Can interpret &lt;em&gt;real&lt;/em&gt; and &lt;em&gt;imaginary&lt;/em&gt; parts of a complex number as &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; coordinates.
Thus can interpret a complex number as a &lt;em&gt;point&lt;/em&gt; in the plane.&lt;/p&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
import matplotlib.pyplot as plt
import numpy as np

number_list = [2+2j, 3+2j, 1.75+1j, 2+1j, 2.25+1j, 2.5+1j, 2.75+1j, 3+1j, 3.25+1j]
for number in number_list:
    plt.scatter(number.real, number.imag)
plt.title(&quot;Interpert Complex Number&quot;)
plt.xlabel(&quot;Real number&quot;)
plt.ylabel(&quot;Imaginary number&quot;)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;complex-numbers-as-arrows&quot;&gt;Complex numbers as arrows&lt;/h4&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
z = -6 + 5j
plt.title(&quot;Complex as Arrow&quot;)
plt.xlabel(&quot;Real Number&quot;)
plt.ylabel(&quot;Imaginary Number&quot;)
plt.arrow(0, 0, z.real, z.imag)
plt.xlim(-10,10)
plt.ylim(-10,10)
plt.grid(True)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;add-two-complex-numbers&quot;&gt;Add two complex numbers&lt;/h4&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
z = x + y
plt.title(&quot;Complex Composition&quot;)
plt.xlabel(&quot;Real Number&quot;)
plt.ylabel(&quot;Imaginary Number&quot;)
plt.arrow(0, 0, x.real, x.imag, color=&#39;g&#39;)
plt.arrow(0, 0, y.real, y.imag, color=&#39;b&#39;)
plt.arrow(0, 0, z.real, z.imag, color=&#39;r&#39;)
plt.xlim(-3,6)
plt.ylim(-3,6)
plt.grid(True)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;multiply-complex-numbers&quot;&gt;Multiply complex numbers&lt;/h4&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
z = time * complex_number
plt.title(&quot;Multiply Complex&quot;)
plt.xlabel(&quot;Real Number&quot;)
plt.ylabel(&quot;Imaginary Number&quot;)
plt.arrow(0, 0, complex_number.real, complex_number.imag, color=&#39;b&#39;)
plt.arrow(0, 0, z.real, z.imag, color=&#39;y&#39;)
plt.xlim(-3,6)
plt.ylim(-3,6)
plt.grid(True)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;rotate-ninty-degree&quot;&gt;Rotate ninty degree&lt;/h4&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
 z = 1j * complex_number
plt.title(&quot;Multiply Complex&quot;)
plt.xlabel(&quot;Real Number&quot;)
plt.ylabel(&quot;Imaginary Number&quot;)
plt.arrow(0, 0, complex_number.real, complex_number.imag, color=&#39;b&#39;)
plt.arrow(0, 0, z.real, z.imag, color=&#39;y&#39;)
plt.xlim(-3,3)
plt.ylim(-3,3)
plt.grid(True)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;rotate-with-theta-degree&quot;&gt;Rotate with &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt; degree&lt;/h4&gt;
&lt;p&gt;Use: &lt;strong&gt;Euler’s formula&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>CS-6649 Brief Note of Bioinformatics Project</title>
   <link href="http://zhou-dong.github.io/2015/02/28/brief-note"/>
   <updated>2015-02-28T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/02/28/brief-note</id>
   <content type="html">
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.scipy.org/&quot;&gt;SciPy&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Description: &lt;a href=&quot;http://www.scipy.org/&quot;&gt;SciPy&lt;/a&gt; (pronounced “Sigh Pie”) is a Python-based ecosystem of open-source software for mathematics, science, and engineering. Some core packages: 
        &lt;ul&gt;
          &lt;li&gt;NumPy: Base N-dimensional array package&lt;/li&gt;
          &lt;li&gt;SciPy library: Fundamental library for scientific computing&lt;/li&gt;
          &lt;li&gt;Matplotlib: Comprehensive 2D Plotting&lt;/li&gt;
          &lt;li&gt;IPython: Enhanced Interactive Console&lt;/li&gt;
          &lt;li&gt;Sympy: Symbolic mathematics&lt;/li&gt;
          &lt;li&gt;pandas: Data structures &amp;amp; analysis&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://prody.csb.pitt.edu/&quot;&gt;ProDy&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://prody.csb.pitt.edu/&quot;&gt;ProDy&lt;/a&gt; is a free and open-source Python package for protein structural dynamics analysis.
        &lt;ul&gt;
          &lt;li&gt;Structure analysis&lt;/li&gt;
          &lt;li&gt;Dynamics analysis&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Use pip to install
        &lt;ul&gt;
          &lt;li&gt;pip install nose&lt;/li&gt;
          &lt;li&gt;pip install numpy&lt;/li&gt;
          &lt;li&gt;pip install -U ProDy &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ks.uiuc.edu/Research/vmd/&quot;&gt;VMD&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;VMD is a molecular visualization program for displaying, animating, and analyzing large biomolecular systems using 3-D graphics and built-in scripting.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.ks.uiuc.edu/Development/Download/download.cgi?PackageName=VMD&quot;&gt;Download Page&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Introduction to complex numbers</title>
   <link href="http://zhou-dong.github.io/python/matrix/2015/02/27/complex-numbers"/>
   <updated>2015-02-27T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/python/matrix/2015/02/27/complex-numbers</id>
   <content type="html">
&lt;p&gt;Solutions to &lt;script type=&quot;math/tex&quot;&gt; x^2 = -1 &lt;/script&gt; ?&lt;br /&gt;
Mathematicians invented &lt;em&gt;i&lt;/em&gt; to be one solution.&lt;/p&gt;

&lt;p&gt;Example: &lt;script type=&quot;math/tex&quot;&gt; x^2 = -1 &lt;/script&gt; &lt;em&gt;solution is&lt;/em&gt; &lt;script type=&quot;math/tex&quot;&gt; x = 3i &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Numbers such as &lt;script type=&quot;math/tex&quot;&gt; i, -i, 3i, 2.17i &lt;/script&gt; are called &lt;strong&gt;imaginary&lt;/strong&gt; numbers.&lt;/p&gt;

&lt;p&gt;Solution to &lt;script type=&quot;math/tex&quot;&gt; (x-1)^2  = -9 ? \ x = 1 + 3i &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;A real number plus an imaginary number is a &lt;strong&gt;complex number&lt;/strong&gt;.&lt;br /&gt;
A real number has &lt;strong&gt;real part&lt;/strong&gt; and an &lt;strong&gt;imgianary part&lt;/strong&gt;.&lt;/p&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
# (x-1)**2 = -9, x = 1 + 3j
x = 1 + 3j

print x
print (x-1)**2
print type(x)

# ax + b = c
def solve(a, b, c):
    return (c-b)/a

# 10x + 5 = 30
print solve(10.0, 5.0, 30.0)

# (10 + 5i)x + 5 = 20
print solve(10+5j, 5.0, 20.0)
&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>The Function and the Field</title>
   <link href="http://zhou-dong.github.io/matrix/python/2015/02/26/basic-math-intro"/>
   <updated>2015-02-26T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/matrix/python/2015/02/26/basic-math-intro</id>
   <content type="html">
&lt;h4 id=&quot;set-terminology-and-notation&quot;&gt;Set terminology and Notation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Set: and unordered collection of objects. Example: &lt;script type=&quot;math/tex&quot;&gt; \{ X, Y, Z \}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \in &lt;/script&gt;: indicates than an object belong to a set (equivalently, that the set contains the object). For example, &lt;script type=&quot;math/tex&quot;&gt; X \in \{X, Y, Z\}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A \subseteq B &lt;/script&gt;: Read this as “A is a subset of B”. This measn A and B are sets, and every element of A is aslo an element of B.&lt;/li&gt;
  &lt;li&gt;A = B: Two sets are equal if they contain the exactly the same elements. (There is no order among elements of a set.)
    &lt;ul&gt;
      &lt;li&gt;A convenient way to prove that A and B are equal is to prove that each is a subset of the other. The proof often consists two parts:
        &lt;ol&gt;
          &lt;li&gt;a proof that &lt;script type=&quot;math/tex&quot;&gt; A \subseteq B, &lt;/script&gt; and&lt;/li&gt;
          &lt;li&gt;a proof that &lt;script type=&quot;math/tex&quot;&gt; B \subseteq A &lt;/script&gt;.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;set-expressions&quot;&gt;Set expressions:&lt;/h4&gt;

&lt;p&gt;In Mathese, we could write “the set of nonegative numbers” like that: &lt;script type=&quot;math/tex&quot;&gt; \{ x \in R: \  x \ge 0 \} &lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The colon(“:”) stands for “such that”.&lt;/li&gt;
  &lt;li&gt;There are two parts of this expression:
    &lt;ul&gt;
      &lt;li&gt;the part before the colon: This part specifies where the elements of the set come from, and introduces a variable or variables that can be used in the second part.&lt;/li&gt;
      &lt;li&gt;the part after the colon: This gives a rule that restricts which elements specified in the first part actually get to make it into the set. &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The analogous python expression is set &lt;code&gt;comprehension&lt;/code&gt;:&lt;/li&gt;
  &lt;li&gt;Python code:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
    S = {-4, 4, -3, 3, -2, 2, -1, 1, 0}
    result = {x for x in S if x &amp;gt;= 0}
    print result
    result: set([0, 1, 2, 3, 4])
&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;you might see just &lt;script type=&quot;math/tex&quot;&gt; \{ x: x \ge 0 \}&lt;/script&gt;. For example: 
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \{ x: (x+1)(x-2) = 0 \}&lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;This time, the set consists of just two numbers, -1 and 2.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;set-terminology-and-notation-cartesian-product&quot;&gt;Set terminology and notation: Cartesian product&lt;/h4&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; A \times B&lt;/script&gt; is the set of all pairs &lt;script type=&quot;math/tex&quot;&gt; (a, b) &lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt; a \in A&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; b \in B&lt;/script&gt;&lt;br /&gt;
Example: for &lt;script type=&quot;math/tex&quot;&gt; A = \{ 1, 2 \}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; B = \{ x, y \}, A \times B&lt;/script&gt; is &lt;script type=&quot;math/tex&quot;&gt;\{(1,x),(2,x)(1,y)(2,y)\} &lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;tuples-in-set-expressions&quot;&gt;Tuples in set expressions&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \{ (x,y) \in R \times R: y = x^2 &lt;/script&gt; } &lt;code&gt;equal&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt; \{ (x,y): y = x^2\} &lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \{(x,y,z) \in R \times R \times R: x \ge 0, y \ge 0, z \ge 0 \} &lt;/script&gt;. &lt;code&gt;equal&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt; \{(x,y,z): x \ge 0, y \ge 0, z \ge 0\} &lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;the-function&quot;&gt;The function&lt;/h4&gt;

&lt;p&gt;Informally, for each input element in a set A, a function assigns a single output element from another set B.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A is called the &lt;code&gt;domain&lt;/code&gt; of the function&lt;/li&gt;
  &lt;li&gt;B is called the &lt;code&gt;co-domain&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: The output of a given input is called the &lt;em&gt;image&lt;/em&gt; of the input. The image of &lt;em&gt;q&lt;/em&gt; under &lt;em&gt;a&lt;/em&gt; function &lt;em&gt;f&lt;/em&gt; is denoted &lt;em&gt;f(q)&lt;/em&gt;.&lt;br /&gt;
If &lt;em&gt;f(q) = r&lt;/em&gt;, we say &lt;em&gt;q&lt;/em&gt; maps to &lt;em&gt;r&lt;/em&gt; under &lt;em&gt;f&lt;/em&gt;. In Mathese, we write this as &lt;script type=&quot;math/tex&quot;&gt; q \mapsto r &lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The set from which all the outputs are chosen is called the co-domain.&lt;br /&gt;
We write: &lt;script type=&quot;math/tex&quot;&gt; f: D \to F &lt;/script&gt;&lt;br /&gt;
when we want to say that &lt;strong&gt;f&lt;/strong&gt; is a function with domain &lt;strong&gt;D&lt;/strong&gt; and co-domain &lt;strong&gt;F&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: The &lt;em&gt;image&lt;/em&gt; of a function is the set of all images of inputs. Mathese: Im &lt;em&gt;f&lt;/em&gt;.&lt;br /&gt;
Example: Cosine Function &lt;strong&gt;cos(x)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;cos: &lt;script type=&quot;math/tex&quot;&gt; R \to R &lt;/script&gt;, which means that domain is &lt;script type=&quot;math/tex&quot;&gt;R&lt;/script&gt; and the co-domain is &lt;script type=&quot;math/tex&quot;&gt;R&lt;/script&gt;&lt;br /&gt;
The image of &lt;em&gt;cos(x)&lt;/em&gt;, Im &lt;em&gt;cos&lt;/em&gt;, is &lt;script type=&quot;math/tex&quot;&gt; \{ x \in R: -1 \le x \le 1\}&lt;/script&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: For sets F and D, &lt;script type=&quot;math/tex&quot;&gt;F^D&lt;/script&gt; denotes all functions from D to F.&lt;/p&gt;

&lt;h4 id=&quot;identity-function-and-composition&quot;&gt;Identity function and composition&lt;/h4&gt;

&lt;p&gt;Indentity function: for any domain &lt;script type=&quot;math/tex&quot;&gt; D, id_D: D \to D&lt;/script&gt;, maps each domain element &lt;em&gt;d&lt;/em&gt; to itself.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: For functions &lt;script type=&quot;math/tex&quot;&gt; f: A \to B &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; g: B \to C &lt;/script&gt;, the &lt;em&gt;functional composition&lt;/em&gt; of &lt;em&gt;f&lt;/em&gt; and &lt;em&gt;g&lt;/em&gt; is the function:&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt; (g \ o \ f) : A \to C &lt;/script&gt; defined by &lt;script type=&quot;math/tex&quot;&gt; (g \ o \ f)(x) = g(f(x))&lt;/script&gt;.&lt;br /&gt;
Example: Composition of &lt;script type=&quot;math/tex&quot;&gt; g(y) = y^2 &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; f(x) = x +1 &lt;/script&gt; is &lt;script type=&quot;math/tex&quot;&gt; (g \ o \ f)(x) = (x+1)^2&lt;/script&gt;.&lt;br /&gt;
Proposition: &lt;script type=&quot;math/tex&quot;&gt; h \ o \ (g \ o \ f) = (h \ o \ g ) \ o \ f&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;functional-inverse&quot;&gt;Functional inverse&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Functions &lt;em&gt;f&lt;/em&gt; and &lt;em&gt;g&lt;/em&gt; are functional inverses if &lt;em&gt;f o g&lt;/em&gt; and &lt;em&gt;g o f&lt;/em&gt; are defined and are indentity functions.&lt;br /&gt;
Invertible functions are &lt;strong&gt;one-to-one&lt;/strong&gt;.&lt;br /&gt;
Invertible functions are &lt;strong&gt;onto&lt;/strong&gt;.&lt;br /&gt;
&lt;strong&gt;Function Invertibility Theorem:&lt;/strong&gt; A function &lt;em&gt;f&lt;/em&gt; is invertible if and only if it is one-to-one and onto.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Orthogonality</title>
   <link href="http://zhou-dong.github.io/2015/02/22/orthogonality"/>
   <updated>2015-02-22T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/02/22/orthogonality</id>
   <content type="html">
&lt;p&gt;正交，也就是在二维空间或者三维空间的垂直&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果有正交的sub dimensional的话，那么在矩阵的运算中，就可以极大的简化计算量。&lt;/li&gt;
  &lt;li&gt;在矩阵的运算中，就不需要高斯消去法了&lt;/li&gt;
  &lt;li&gt;只需要在各个dimension中各自求解&lt;/li&gt;
  &lt;li&gt;因为各个维度之间是没有影响的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;正交化的步骤&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;求linear dependent的matrix的basis&lt;/li&gt;
  &lt;li&gt;用其中的一个vector做标准，来正交化其它的basis&lt;/li&gt;
  &lt;li&gt;把正交化以后的新的basis做normalization，即长度都为1&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;orthogonal projection&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对subspace做orthogonal projection&lt;/li&gt;
  &lt;li&gt;对一个向量，在某个subspace做投影&lt;/li&gt;
  &lt;li&gt;把一个向量decomposition&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;orthogonal complement&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个向量与两一个subspace中的所有向量都垂直&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;向量与subspace之间的orthogonality&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;即这个向量到这个平面的距离&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;求这个subspace的orthogonal basis，&lt;/li&gt;
  &lt;li&gt;求这个向量在这些orthogonal basis上的投影&lt;/li&gt;
  &lt;li&gt;这个向量减去在subspace上的投影，就是向量到空间的距离&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;用这个方式，可以求线性回归的问题&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Eigenvalues, Eigenvectors, and Diagonaliztion</title>
   <link href="http://zhou-dong.github.io/eigenvalue/eigenvector/2015/02/20/eigenvalues"/>
   <updated>2015-02-20T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/eigenvalue/eigenvector/2015/02/20/eigenvalues</id>
   <content type="html">
&lt;p&gt;(A - XI_n)v = 0&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;有些矩阵在实数的范围内没有eigenvalue&lt;/li&gt;
  &lt;li&gt;eigenvectors之间必须是垂直的&lt;/li&gt;
  &lt;li&gt;如果一个eigenvector不在某个eigenspace里面，那么它们之间应该是垂直的&lt;/li&gt;
  &lt;li&gt;eigenvecotrs应该是矩阵在向量空间中，各个维度的basic vector的投影的值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;characteristic polynomial&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先建立特征多项式 characteristic polynomial&lt;/li&gt;
  &lt;li&gt;求解特征方程式 characteristic equation&lt;/li&gt;
  &lt;li&gt;通过方程式的答案来求出eigenvector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;diagonalization of matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对角矩阵&lt;/li&gt;
  &lt;li&gt;通过矩阵的对角化，来简化矩阵相乘的复杂度&lt;/li&gt;
  &lt;li&gt;如果能找到N个indenpent的矩阵，就能使这个矩阵对角化&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>CS-5549 Assignment 4</title>
   <link href="http://zhou-dong.github.io/2015/02/20/cs-5549-assignment-4"/>
   <updated>2015-02-20T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/02/20/cs-5549-assignment-4</id>
   <content type="html">
&lt;h4 id=&quot;question-&quot;&gt;Question :&lt;/h4&gt;
&lt;p&gt;Show the R-B trees that result after successively inserting the keys 41, 38, 31, 12, 19, 8 into an initially empty R-B tree. &lt;/p&gt;

&lt;p&gt;Answer:&lt;/p&gt;

&lt;div style=&quot;width:70%&quot;&gt;

  &lt;img alt=&quot;red-black-tree&quot; style=&quot;width:100%&quot; src=&quot;/images/Red-Black-Tree.png&quot; /&gt;

&lt;div&gt;
&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Matrices Mutiplication</title>
   <link href="http://zhou-dong.github.io/matrix/2015/02/16/matrices-and-linear-transformations"/>
   <updated>2015-02-16T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/matrix/2015/02/16/matrices-and-linear-transformations</id>
   <content type="html">
&lt;p&gt;对角矩阵： (diagonal matrix)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对角矩阵首先是方阵&lt;/li&gt;
  &lt;li&gt;两个对角矩阵相乘，符合交换律&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对称矩阵：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;矩阵的转置，还是原矩阵&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;利用矩阵的反阵inverse可以实现相当于矩阵的除法&lt;/p&gt;

&lt;p&gt;invertible 矩阵的反转&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ax = b&lt;/li&gt;
  &lt;li&gt;A^-1 (Ax) = A^-1 b&lt;/li&gt;
  &lt;li&gt;A^-1 A x = A^-1 b&lt;/li&gt;
  &lt;li&gt;I_n x = A^-1 b&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;x = A^-1 b&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;可反转的矩阵也是方阵&lt;/li&gt;
  &lt;li&gt;如果一个矩阵可以反转，那么它最多只有一个反转矩阵&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Elementary matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In mathematics, an elementary matrix is a matrix which differs from the identity matrix by one single elementary row operation.&lt;/li&gt;
  &lt;li&gt;利用elementary matrix和其它矩阵相乘，可以对矩阵做一些运算（个人理解为精确的运算）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;reduced row echelon form是唯一存在的&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;More inverse of Matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;要判断一个矩阵是不是inverse的，可以看它的reduced row echelon是不是I_n，如果是那这个矩阵就是inverse的，反之就不是&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Invertable matrix theorem&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A in invertible&lt;/li&gt;
  &lt;li&gt;The reduced row echelon form is I_n&lt;/li&gt;
  &lt;li&gt;The rank of A equal n&lt;/li&gt;
  &lt;li&gt;The span of the columns of A is R^n&lt;/li&gt;
  &lt;li&gt;The equation Ax = b is consistant for every b in R^n&lt;/li&gt;
  &lt;li&gt;The nullity of A is equal 0&lt;/li&gt;
  &lt;li&gt;The column of A linear indenpendent&lt;/li&gt;
  &lt;li&gt;The only Ax = 0 is 0&lt;/li&gt;
  &lt;li&gt;A is a product of elementary matrix A是多个elementary matrix的相乘&lt;/li&gt;
  &lt;li&gt;There exists an n * n matrix B such that BA = I_n&lt;/li&gt;
  &lt;li&gt;There exists an n * n matrix C such that AC = I_n&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Linear Transformnations and Matrices&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;找出matrix transformation or linear transformation的standard matrix，就是把单位矩阵或者说单位向量依次带进去求解。&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Intro to Matrices, Vectors, Equations, set</title>
   <link href="http://zhou-dong.github.io/matric/vector/linear/set/gaussian/2015/02/16/definitions-in-linear-algebra"/>
   <updated>2015-02-16T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/matric/vector/linear/set/gaussian/2015/02/16/definitions-in-linear-algebra</id>
   <content type="html">
&lt;p&gt;&lt;strong&gt;零矩阵 != 零矩阵&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;零矩阵是有维度的，只是各个维度的值都为0&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;矩阵 乘以 0 =  零矩阵&lt;/p&gt;

&lt;p&gt;A * 0 != B * 0&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;因为矩阵A和矩阵B的维度可能不一样&lt;/li&gt;
  &lt;li&gt;所以它们生成的零矩阵可能会不一样&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;矩阵的转换：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A矩阵的transpose：A矩阵的行列转换&lt;/li&gt;
  &lt;li&gt;两个矩阵和的转置，等于两个矩阵分别转置然后再相加&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;vectors&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;row vector&lt;/li&gt;
  &lt;li&gt;column vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;向量的加减和系数积 其实和矩阵是一样的&lt;/p&gt;

&lt;p&gt;Standard Vectors&lt;/p&gt;

&lt;p&gt;向量空间中的标准向量&lt;/p&gt;

&lt;p&gt;矩阵 * 向量&lt;/p&gt;

&lt;p&gt;矩阵 向量 相乘： 结果为一个 向量&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;单位向量、单位矩阵&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在一个向量空间中，我们可以定义各个维度单位为1的向量为这个维度的单位向量。&lt;/li&gt;
  &lt;li&gt;所以在一个N维的向量空间中，就会有个N个单位矩阵&lt;/li&gt;
  &lt;li&gt;这N个单位矩阵，按次序组成的矩阵就叫做identity matrix&lt;/li&gt;
  &lt;li&gt;由于我们知道，identity matrix在向量空间中的各个维度的值都为1，所以：&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;identity matrix和任何向量相乘，都会不改变向量的大小&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Stochastic Matrx&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在矩阵中，一列的值相加等于1&lt;/li&gt;
  &lt;li&gt;[0.85 0.03]&lt;/li&gt;
  &lt;li&gt;[0.15 0.97]&lt;/li&gt;
  &lt;li&gt;可以用这种矩阵来表示百分比的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rotation Matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;用向量空间来表示一个向量空间中旋转的角度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sytem of linear equations: （联立方程式）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个方程叫做linear equation&lt;/li&gt;
  &lt;li&gt;多个方程组合起来：system 藕粉 linear equations&lt;/li&gt;
  &lt;li&gt;方程式可能会有多个解，这些解的集合我们叫做solution set&lt;/li&gt;
  &lt;li&gt;Gaussian Elimination
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;所有的pivot position的上下都为0&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ax = b&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Elementary Row Operations&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;interchange&lt;/li&gt;
  &lt;li&gt;multiply nonzero scalar&lt;/li&gt;
  &lt;li&gt;add a mutiple of one row to another&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;augmented matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;把变量和结果放在同一个矩阵中求解。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Set theory&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;set中是没有顺序的&lt;/li&gt;
  &lt;li&gt;union set 合集&lt;/li&gt;
  &lt;li&gt;intersection set 交集&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;difference set 两个集合相减&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;有限多元素的集合&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;无限多元素的集合&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;R^2 不是 R^3 的子集&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;一个判断一个向量的集合是否可以span出整个空间中的所有元素&lt;/li&gt;
  &lt;li&gt;只要找出整个集合中的向量，无法random出空间中的一个向量就可以了&lt;/li&gt;
  &lt;li&gt;一个集合中，如果两个向量是平行的或者是重合的，那么这两个向量在span的时候，作用是一样的&lt;/li&gt;
  &lt;li&gt;可以证明两个集合互为对方的子集&lt;/li&gt;
  &lt;li&gt;所以在整个集合中，每个向量都应该是独特的。&lt;/li&gt;
  &lt;li&gt;如果在一个set中，一个向量可以是别的向量的线性组合，那么这个向量就可以被移除掉。&lt;/li&gt;
  &lt;li&gt;判断集合中的向量是否线性相依&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Linear dependence 线性相依 L.D&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果其中的一些向量或者其实的两个向量，能组合出0向量，说明其中有的向量是线性相依的&lt;/li&gt;
  &lt;li&gt;如果解中，有一个向量是free variable那么说明这个向量是L.D&lt;/li&gt;
  &lt;li&gt;Ax = 0 有除了0向量外的其它解&lt;/li&gt;
  &lt;li&gt;Ax = b 可能有许多解&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Linear Independence L.I&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不存在一组系数，使得集合里面任何向量之间的组合都不为0向量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;创建一组(L.I) set&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;创建一非零向量&lt;/li&gt;
  &lt;li&gt;第二个向量不能与第一个向量平行&lt;/li&gt;
  &lt;li&gt;以后添加的向量，不能是前面向量的线性组合&lt;/li&gt;
  &lt;li&gt;向量个数最多是m个&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Achieved Courses</title>
   <link href="http://zhou-dong.github.io/2015/02/16/achieved-courses"/>
   <updated>2015-02-16T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/02/16/achieved-courses</id>
   <content type="html">
&lt;h3 id=&quot;online-courses&quot;&gt;Online Courses&lt;/h3&gt;

&lt;h4 id=&quot;coursera&quot;&gt;Coursera:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;R Programming
    &lt;ul&gt;
      &lt;li&gt;Start Date: Feb 01, 2015&lt;/li&gt;
      &lt;li&gt;End Date: Feb 10, 2015&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/zhou-dong/r-study&quot;&gt;Notes and Code&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Johns Hopkins&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;機器學習基石 (Machine Learning Foundations)
    &lt;ul&gt;
      &lt;li&gt;Start Date: Jan 31, 2015&lt;/li&gt;
      &lt;li&gt;End Date: Feb 15, 2015&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://zhou-dong.github.io/2015/02/15/revised-all/&quot;&gt;Simple Roadmap&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;National Taiwan University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;機器學習技法 (Machine Learning Techniques)
    &lt;ul&gt;
      &lt;li&gt;Start Date: March 17, 2015&lt;/li&gt;
      &lt;li&gt;End Date: March 21, 2015&lt;/li&gt;
      &lt;li&gt;National Taiwan University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;An Introduction to Interactive Programming in Python (Part 1)
    &lt;ul&gt;
      &lt;li&gt;Start Date: 02/13 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/10 2015&lt;/li&gt;
      &lt;li&gt;Rice University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Coding the Matrix: Linear Algebra through Computer Science Applications
    &lt;ul&gt;
      &lt;li&gt;Start Date: 02/02/2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/08/2015&lt;/li&gt;
      &lt;li&gt;language: python &lt;/li&gt;
      &lt;li&gt;Brown University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Programming for Everybody (Python)
    &lt;ul&gt;
      &lt;li&gt;Start Date: 02/02 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/14 2015&lt;/li&gt;
      &lt;li&gt;Some of chapters are useful&lt;/li&gt;
      &lt;li&gt;University of Michigan&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;An Introduction to Interactive Programming in Python (Part 2)
    &lt;ul&gt;
      &lt;li&gt;Start Date: 04/09 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/18 2015&lt;/li&gt;
      &lt;li&gt;Rice University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pattern Discovery in Data Mining
    &lt;ul&gt;
      &lt;li&gt;Start Date: 04/10 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/12 2015&lt;/li&gt;
      &lt;li&gt;Not detailed enough, so don’t like so much&lt;/li&gt;
      &lt;li&gt;The University of Illinois at Urbana-Champaign&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Web Application Architectures
    &lt;ul&gt;
      &lt;li&gt;Start Date: 04/12 2015&lt;/li&gt;
      &lt;li&gt;End Date:04/14 2015&lt;/li&gt;
      &lt;li&gt;Use Ruby on rails to implement Web server&lt;/li&gt;
      &lt;li&gt;The University of New Mexico&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Text Retrieval and Search Engines
    &lt;ul&gt;
      &lt;li&gt;Start Date: 04/15 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/18 2015&lt;/li&gt;
      &lt;li&gt;I like this course, easily understand.&lt;/li&gt;
      &lt;li&gt;The University of Illinois at Urbana-Champaign&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Introduction to Recommender Systems
    &lt;ul&gt;
      &lt;li&gt;Start Date: 05/11 2015&lt;/li&gt;
      &lt;li&gt;End Date: 05/11 2015&lt;/li&gt;
      &lt;li&gt;No coding thing, just basic thing of Recommender System&lt;/li&gt;
      &lt;li&gt;The University of Minnesota &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Practical Machine Learning
    &lt;ul&gt;
      &lt;li&gt;Start Date: 17/07 2015&lt;/li&gt;
      &lt;li&gt;End Date: 18/07 2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data Visualization
    &lt;ul&gt;
      &lt;li&gt;Start Date: 23/07 2015&lt;/li&gt;
      &lt;li&gt;End Date:&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;计算导论与C语言基础
    &lt;ul&gt;
      &lt;li&gt;Start Date: 07/24 2015&lt;/li&gt;
      &lt;li&gt;End Date:08/09 2015&lt;/li&gt;
      &lt;li&gt;确实是非常好的一门课程,尤其是刚开始对计算机的历史的介绍，和图灵机院里的介绍！&lt;/li&gt;
      &lt;li&gt;授课学校：北京大学&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;C程序设计进阶
    &lt;ul&gt;
      &lt;li&gt;Start Date: 08/06 2015&lt;/li&gt;
      &lt;li&gt;End Date: 08/09/2015&lt;/li&gt;
      &lt;li&gt;授课学校：北京大学&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Android 手持系统的移动应用
    &lt;ul&gt;
      &lt;li&gt;Start Date: 08/18 2015&lt;/li&gt;
      &lt;li&gt;End Date: 08/20 2015&lt;/li&gt;
      &lt;li&gt;University of Maryland, College Park&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Machine Learning
    &lt;ul&gt;
      &lt;li&gt;Start Date: 15/08 2015&lt;/li&gt;
      &lt;li&gt;End Date: 18/11 2015&lt;/li&gt;
      &lt;li&gt;Standford University&lt;/li&gt;
      &lt;li&gt;Andrwe Ng&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;机器学习基础：案例研究
    &lt;ul&gt;
      &lt;li&gt;Start Date: 10/15 2015&lt;/li&gt;
      &lt;li&gt;End Date:&lt;/li&gt;
      &lt;li&gt;华盛顿大学&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Machine Learning in Practise&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;The Data Scientist’s Toolbox
    &lt;ul&gt;
      &lt;li&gt;Johns Hopkins&lt;/li&gt;
      &lt;li&gt;Start Date: 12/11 2015&lt;/li&gt;
      &lt;li&gt;End Date:&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Machine Learning: Regression
    &lt;ul&gt;
      &lt;li&gt;华盛顿大学&lt;/li&gt;
      &lt;li&gt;Start Date: 11/30/2015&lt;/li&gt;
      &lt;li&gt;End Date: 12/31/2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;edex&quot;&gt;Edex:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;MITx: 6.00.1x Introduction to Computer Science and Programming Using Python
    &lt;ul&gt;
      &lt;li&gt;Start Date: 01/07 2015&lt;/li&gt;
      &lt;li&gt;End Date: 09/04 2015&lt;/li&gt;
      &lt;li&gt;Almost finish all of them, some of them I think already know, so skip&lt;/li&gt;
      &lt;li&gt;MIT&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;youtube&quot;&gt;Youtube:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;線性代數 (Not Finished All, Just lec01-lec-13)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLe94oLfiYuBCN-1N9aHJVjqO0K_Ug0VwZ&quot;&gt;URL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Start Date: Jan 04, 2015&lt;/li&gt;
      &lt;li&gt;End Date: Feb 10, 2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bioinformatcs (Introduction to bioinformatics)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;/bioinformatics/2015/03/27/intro/&quot;&gt;URL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Start Date: March 25 2015&lt;/li&gt;
      &lt;li&gt;End Date: March 28 2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;台大開放課程-線性代數-蘇柏青(I really like this course!)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLw7ltASAuhMTZPgepJqpj_7Dv0AmIHJyJ&quot;&gt;URL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Start Date: March 31 2015&lt;/li&gt;
      &lt;li&gt;End Date: April 08 2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Node.js Tutorial for Beginners
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=-u-j7uqU7sI&amp;amp;index=1&amp;amp;list=PL6gx4Cwl9DGBMdkKFn3HasZnnAqVjzHn_&quot;&gt;URL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Start Date: July 13 2015&lt;/li&gt;
      &lt;li&gt;End Date: July 15 2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;android开发零基础入门教程
    &lt;ul&gt;
      &lt;li&gt;高明鑫&lt;/li&gt;
      &lt;li&gt;Start Date: Aug 26 2015&lt;/li&gt;
      &lt;li&gt;End Date: Aug 29 2015&lt;/li&gt;
      &lt;li&gt;非常适合有一定web开发基础的人学习&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;codecademy&quot;&gt;Codecademy&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Python&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HTML &amp;amp; CSS&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;JavaScript&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make a Website (HTML css Bootstrap)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jQuery&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make an Interactive Website(Javascript and JQuery)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learn Ruby on Rails&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learn the Command Line&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;colledge&quot;&gt;Colledge&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;CS3329/CS5549-TBAA (Analysis of Algorithms)
    &lt;ul&gt;
      &lt;li&gt;2015 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Zhong&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Speical Topics CS6649-TXAD (Bioinformatics Algorithm)
    &lt;ul&gt;
      &lt;li&gt;2015 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Zhong&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Special Topics CS6649-TXAA (Graphical Data Mining)
    &lt;ul&gt;
      &lt;li&gt;2015 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Mago&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Speical Topics CS-6648-TBAA (Optimization Modeling)
    &lt;ul&gt;
      &lt;li&gt;2015 Summer Semester&lt;/li&gt;
      &lt;li&gt;Dr. Mago&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CS-5545-TXAA (Computer Architecture)
    &lt;ul&gt;
      &lt;li&gt;2015 Fall Semester&lt;/li&gt;
      &lt;li&gt;Dr. Zhong&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Special Topics CS-6649-TRAB (Advantaged Networking)
    &lt;ul&gt;
      &lt;li&gt;2015 Fall Semester&lt;/li&gt;
      &lt;li&gt;Dr. Kumar&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Special Topics CS6649-TRAA (Probabilistic Graphical Models)
    &lt;ul&gt;
      &lt;li&gt;2015 Fall Semester&lt;/li&gt;
      &lt;li&gt;Dr. Karen Hovsepian&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Computer Vision CS-6632-TXAA
    &lt;ul&gt;
      &lt;li&gt;2016 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Karen Hovsepian&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Computer Graphics CS-6666-TXAA
    &lt;ul&gt;
      &lt;li&gt;2016 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Yanjun Zhao&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Operating Systems Principles
    &lt;ul&gt;
      &lt;li&gt;2016 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Karen Hovsepian&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;145-146-413:1234&lt;/p&gt;

&lt;p&gt;singer-eminme&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Three Learning Principles</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/02/15/three-learning-principles"/>
   <updated>2015-02-15T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/02/15/three-learning-principles</id>
   <content type="html">
&lt;h4 id=&quot;occams-razor&quot;&gt;Occam’s Razor&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;History:
    &lt;ul&gt;
      &lt;li&gt;An explanation of the data should be made as simple as possible, but no simpler. –Albert Einstein&lt;strong&gt;?&lt;/strong&gt;(1879-1955)&lt;/li&gt;
      &lt;li&gt;entia non sunt mutiplicanda praeter necessitatem (entities must not be mutiplied &lt;strong&gt;beyond necessity&lt;/strong&gt;) –William of Occam (1287-1347)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Definition:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Occam’s razor&lt;/strong&gt; for trimming down unnessary explanation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Explain:
    &lt;ul&gt;
      &lt;li&gt;The simplest model that fits the data is aslo the most plausible.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;One word:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Simple is Better&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;sampling-bias&quot;&gt;Sampling Bias&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Description:
    &lt;ul&gt;
      &lt;li&gt;If the data is sampled in a &lt;strong&gt;biased&lt;/strong&gt; way, learning will produce a similarly biased outcome.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Practical rule of thumb:
    &lt;ul&gt;
      &lt;li&gt;match test scenario as much as possible&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;data-snooping&quot;&gt;Data Snooping&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Data snooping
    &lt;ul&gt;
      &lt;li&gt;careful about &lt;strong&gt;your brain’s “model complexity”&lt;/strong&gt;.&lt;/li&gt;
      &lt;li&gt;shall be decided &lt;strong&gt;without “snooping” data&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;If data set has affected any step in the learning process, its ability to assess the outcome has been compromised.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dealing with data snooping
    &lt;ul&gt;
      &lt;li&gt;truth - &lt;strong&gt;very hard to avoid&lt;/strong&gt;, unless being extrnmely honest&lt;/li&gt;
      &lt;li&gt;extremely honest: &lt;strong&gt;lock your test data in safe&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;less honest: &lt;strong&gt;reserve validation and use cautiously&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;be blind: avoid making modeling decision by data&lt;/li&gt;
      &lt;li&gt;be suspicious: interpret research results (including your own)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Revised Course</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/02/15/revised-all"/>
   <updated>2015-02-15T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/02/15/revised-all</id>
   <content type="html">
&lt;h4 id=&quot;three-related-fields&quot;&gt;Three Related Fields&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Data mining&lt;/li&gt;
  &lt;li&gt;Artifical Intelligence&lt;/li&gt;
  &lt;li&gt;Statistics&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-theoretical-bounds&quot;&gt;Three Theoretical Bounds&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Hoeffding&lt;/li&gt;
  &lt;li&gt;Muti-Bin Hoeffding&lt;/li&gt;
  &lt;li&gt;VC&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-linear-models&quot;&gt;Three Linear Models&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;PLA, pocket&lt;/li&gt;
  &lt;li&gt;Linear regression&lt;/li&gt;
  &lt;li&gt;Logistic regression&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-key-tools&quot;&gt;Three Key Tools&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Feature Transform&lt;/li&gt;
  &lt;li&gt;Regularization&lt;/li&gt;
  &lt;li&gt;Validation &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-learning-principles&quot;&gt;Three Learning Principles&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Occam’s Razer&lt;/li&gt;
  &lt;li&gt;Sampling Bias&lt;/li&gt;
  &lt;li&gt;Data Snooping &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-future-directions&quot;&gt;Three Future Directions&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;More Transform&lt;/li&gt;
  &lt;li&gt;More Regularization&lt;/li&gt;
  &lt;li&gt;Less Label&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Regularization, Validation</title>
   <link href="http://zhou-dong.github.io/regularization/validation/2015/02/15/regularization-validation"/>
   <updated>2015-02-15T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/regularization/validation/2015/02/15/regularization-validation</id>
   <content type="html">
&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Description:
    &lt;ol&gt;
      &lt;li&gt;我们可以把&lt;script type=&quot;math/tex&quot;&gt;E(in)&lt;/script&gt;和regularizer加在一起&lt;/li&gt;
      &lt;li&gt;minimizes augmented error, where the added regularizer effectively limits model complexity&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Regression with Constraint
    &lt;ol&gt;
      &lt;li&gt;Constraint&lt;/li&gt;
      &lt;li&gt;Softer constraint&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;validation&quot;&gt;Validation&lt;/h3&gt;

&lt;h4 id=&quot;model-selection-problemi-so-many-models&quot;&gt;Model selection problemi, so many models:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Classification:
    &lt;ul&gt;
      &lt;li&gt;PLA&lt;/li&gt;
      &lt;li&gt;pocket&lt;/li&gt;
      &lt;li&gt;linear regression&lt;/li&gt;
      &lt;li&gt;logistic regression&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;transform:
    &lt;ul&gt;
      &lt;li&gt;linear&lt;/li&gt;
      &lt;li&gt;quadratic&lt;/li&gt;
      &lt;li&gt;poly-10&lt;/li&gt;
      &lt;li&gt;Legendre-poly-10&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;regularizer
    &lt;ul&gt;
      &lt;li&gt;L2 regularizer&lt;/li&gt;
      &lt;li&gt;L1 regularizer&lt;/li&gt;
      &lt;li&gt;symmetry regularizer &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;validation-1&quot;&gt;Validation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Description:
    &lt;ul&gt;
      &lt;li&gt;留一份手中的资料做测试集。&lt;/li&gt;
      &lt;li&gt;legeal cheeting&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; E_{val}(h) &lt;/script&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Method: 
    &lt;ul&gt;
      &lt;li&gt;Leave-one-out Cross Validation&lt;/li&gt;
      &lt;li&gt;V-Flod Cross Validation &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Training, Generaliztion, VC</title>
   <link href="http://zhou-dong.github.io/machine-learning/vc-dimension/2015/02/14/traing-testing"/>
   <updated>2015-02-14T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/vc-dimension/2015/02/14/traing-testing</id>
   <content type="html">
&lt;h4 id=&quot;traing-versus-testing&quot;&gt;1. Traing versus Testing&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Effective number of Lines:
    &lt;ul&gt;
      &lt;li&gt;some time we can not dichot a set&lt;/li&gt;
      &lt;li&gt;how many lines can dichot a set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dichotomies: Mini-hypotheses
    &lt;ul&gt;
      &lt;li&gt;dichotomy set: depend on inputs&lt;/li&gt;
      &lt;li&gt;growth function: remove dependence by taking max of all possible&lt;/li&gt;
      &lt;li&gt;finite, upper-bounded by &lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;growth function for positive pays&lt;/li&gt;
      &lt;li&gt;Convex set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Break Point
    &lt;ul&gt;
      &lt;li&gt;growth function: max number of dichotmies&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;theory-of-generaliztion&quot;&gt;2. Theory of Generaliztion&lt;/h4&gt;

&lt;p&gt;Description: 举一反三&lt;/p&gt;

&lt;p&gt;Detail:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;REstriction of Break Point
    &lt;ul&gt;
      &lt;li&gt;bounding function: maximum number of length-N vectors with(o,x) while “no shatter” any length-k subvectors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pictorial Proof&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;vc-dimension&quot;&gt;3. VC Dimension&lt;/h4&gt;

&lt;p&gt;Description: maximum non-break point. 一个集合，在vc dimension在这个点上可以shatter某N个点&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;positive rays: &lt;script type=&quot;math/tex&quot;&gt; d_{vc} = 1 &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;positive intervals: &lt;script type=&quot;math/tex&quot;&gt; d_{vc} = 2 &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;positive convex sets: &lt;script type=&quot;math/tex&quot;&gt; d_{vc} = \infty &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;2D perceptrons: &lt;script type=&quot;math/tex&quot;&gt; d_{vc} = 3 &lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Linear Regression, Logistic Regression</title>
   <link href="http://zhou-dong.github.io/machine-learning/regression/2015/02/14/linear-regression"/>
   <updated>2015-02-14T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/regression/2015/02/14/linear-regression</id>
   <content type="html">
&lt;h4 id=&quot;linear-regression&quot;&gt;Linear Regression&lt;/h4&gt;

&lt;p&gt;Description: 在二维空间找出一条线，或者三维空间找出一个面,分割这个Set。 &lt;/p&gt;

&lt;p&gt;Mathese: &lt;script type=&quot;math/tex&quot;&gt; E_{in}(W) = \frac{1}{N} \sum_{n=1}^N (w^Tx_n - y_n)^2&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Popular/historical error measure: squared error &lt;/p&gt;

&lt;p&gt;How to minimize the &lt;script type=&quot;math/tex&quot;&gt; E_{in} (W) &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Matrix: &lt;script type=&quot;math/tex&quot;&gt; min E_{in}(W) = \frac{1}{N} \begin{Vmatrix} Xw - y \end{Vmatrix}^2 &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;他是一个convex function，所以我们能找到极值点。&lt;/p&gt;

&lt;p&gt;应该是求导值（或者梯度的意思）应该是0.&lt;/p&gt;

&lt;p&gt;求导个人理解是曲线加速的方向。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;在向量空间中求出梯度为0的点&lt;/em&gt;就应该是极值点。&lt;/p&gt;

&lt;h4 id=&quot;linear-classification-vs-linear-regression&quot;&gt;Linear Classification vs. Linear Regression&lt;/h4&gt;

&lt;p&gt;可以用Linear Rregression来做Linear classification&lt;/p&gt;

&lt;p&gt;可以现在用linear regression现在初步的分割数据，然后再用linear classification&lt;/p&gt;

&lt;h4 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h4&gt;

&lt;p&gt;It is kind of soft binary classification.&lt;/p&gt;

&lt;p&gt;linear regression的数据可以看成是logistic regression有noise的数据。&lt;/p&gt;

&lt;p&gt;Dcription: 预测某件事发生的概率。&lt;/p&gt;

&lt;p&gt;Convert the score to estimated probability by logistic function.&lt;/p&gt;

&lt;p&gt;把值转化成概率的函数。
&lt;script type=&quot;math/tex&quot;&gt; 
\theta(s) = \frac{e^s}{1+ e^s} = \frac{1}{1+e^{-s}}
&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Gradient Descent&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;greedy approch&lt;/li&gt;
  &lt;li&gt;Taylor Expansion&lt;/li&gt;
  &lt;li&gt;choise of n: don’t &lt;strong&gt;too smally&lt;/strong&gt;, don’t &lt;strong&gt;too large&lt;/strong&gt;, &lt;strong&gt;just right&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Stochastic gradient descent: random pick a gradient&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Linear and Nonlinear Classification</title>
   <link href="http://zhou-dong.github.io/machine-learning/linear/classification/2015/02/14/linear-classification"/>
   <updated>2015-02-14T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/linear/classification/2015/02/14/linear-classification</id>
   <content type="html">
&lt;h4 id=&quot;linear-classification&quot;&gt;Linear Classification&lt;/h4&gt;

&lt;p&gt;Basic: &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;One class at a Time&lt;/li&gt;
  &lt;li&gt;Combine Binary Classifiers&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Improve:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;One class at a Time&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Soft&lt;/strong&gt; combine Binary Classifiers&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Enhance:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Sum of all the probability equal 1&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;One class at a Time&lt;/li&gt;
  &lt;li&gt;Soft combine Classifiers&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One versus&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Two class&lt;/strong&gt; at a time compare&lt;/li&gt;
  &lt;li&gt;Combine &lt;strong&gt;Pairwise&lt;/strong&gt; Classifiers&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;nonlinear-classification&quot;&gt;Nonlinear Classification&lt;/h4&gt;

&lt;p&gt;Circular Separable:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Equtation:
&lt;script type=&quot;math/tex&quot;&gt; 
  h(x) = sign(r \ -1 \cdot x_1^2 -1 \cdot x_2^2)  \\
  h(x) = sign(r \cdot 1 + \ (-1) \cdot x_1^2 + (-1) \cdot x_2^2) \\ 
  h(x) = sign(w_0z_0 + w_1z_1 + w_2z_2) \\
  h(x) = sign(w^Tz)
&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;特征的换：可以把一个平面内的点与圆半径的距离映射到向量空间中去.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Linear hypotheses in Z-space: circle, ellipse, hyperbola, constant&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Machine Learning Type</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/02/08/type-of-machine-learning"/>
   <updated>2015-02-08T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/02/08/type-of-machine-learning</id>
   <content type="html">
&lt;h4 id=&quot;learning-with-different-output-space&quot;&gt;Learning with Different Output Space&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Binary Classification&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;credit approve/disapprove&lt;/li&gt;
      &lt;li&gt;email spam/non-spam&lt;/li&gt;
      &lt;li&gt;patient sick/not sick&lt;/li&gt;
      &lt;li&gt;ad profitable/not profitable&lt;/li&gt;
      &lt;li&gt;answer correct/incorrect&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Muticlass Classification
    &lt;ul&gt;
      &lt;li&gt;written digits: 0, 1, …, 9&lt;/li&gt;
      &lt;li&gt;pictures: apple, orange, strawberry&lt;/li&gt;
      &lt;li&gt;emails: spam, primary, social, promotion, update(Google)&lt;/li&gt;
      &lt;li&gt;recognition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regression&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; y \in R&lt;/script&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Structured Learning
    &lt;ul&gt;
      &lt;li&gt;natural language process (NLP)&lt;/li&gt;
      &lt;li&gt;protein data&lt;/li&gt;
      &lt;li&gt;speech data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;learning-with-different-data-label&quot;&gt;Learning with Different Data Label&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Supervised&lt;/li&gt;
  &lt;li&gt;Unsupervised
    &lt;ul&gt;
      &lt;li&gt;articles to topics&lt;/li&gt;
      &lt;li&gt;consumer profiles to consumer groups&lt;/li&gt;
      &lt;li&gt;density estimation&lt;/li&gt;
      &lt;li&gt;outlier detection&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Semi-supervised&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reinforcement Learning&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;training ad system&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;black jack agent&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;learning-with-different-protocol&quot;&gt;Learning with Different Protocol&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Batch Learning (duck feeding)&lt;/li&gt;
  &lt;li&gt;Online Learning (passive sequdential)&lt;/li&gt;
  &lt;li&gt;Active Learning (question asking)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;learning-with-different-input-space&quot;&gt;Learning with Different Input Space&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;concrete&lt;/li&gt;
  &lt;li&gt;Raw Features&lt;/li&gt;
  &lt;li&gt;Abstract Features&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Perceptron Hypothesis</title>
   <link href="http://zhou-dong.github.io/machine-learning/perceptron/2015/02/07/machine-learning-perceptron"/>
   <updated>2015-02-07T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/perceptron/2015/02/07/machine-learning-perceptron</id>
   <content type="html">
&lt;h4 id=&quot;lecture-1-the-learning-problem&quot;&gt;Lecture 1: The learning problem&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A &lt;/script&gt; takes &lt;script type=&quot;math/tex&quot;&gt; D &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; H &lt;/script&gt; to get &lt;script type=&quot;math/tex&quot;&gt; g &lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Math Sign&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Definition&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Detail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; A &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Learning Algorithm&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;–&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; D:(x_1, y_1), \cdots, (x_n, y_n) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;training examples&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;historical records&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; H &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Hypothesis set&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;–&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; g \approx f &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;final hypothesis&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;“learned” formula to be useds&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f: X \rightarrow Y &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;unknown target function&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;ideal credit approval formula&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;lecture-2-learning-to-answer-yesno&quot;&gt;Lecture 2: Learning to answer &lt;strong&gt;Yes/No&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Perceptron Hyphothesis Set&lt;/li&gt;
  &lt;li&gt;Perceptron Learning Algorithm (PLA)&lt;/li&gt;
  &lt;li&gt;Guarantee of PLA&lt;/li&gt;
  &lt;li&gt;Non-Separable Data&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;a-simple-hypothesis-set-the-perceptron&quot;&gt;A Simple Hypothesis Set: the “perceptron”&lt;/h4&gt;
&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt; x = (x_1, x_2, \cdots, x_d) &lt;/script&gt; &lt;strong&gt;features of customer&lt;/strong&gt;, computer a weight &lt;code&gt;score&lt;/code&gt; and&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;approve credit if &lt;script type=&quot;math/tex&quot;&gt; \sum_{i=1}^d w_i x_i &gt; threshold &lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;deny credit if &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
 \sum_{i=1}^d w_i x_i &lt;  threshold  %]]&gt;&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; y : \{ +1(good), -1(bad) \}, &lt;/script&gt; &lt;strong&gt;0&lt;/strong&gt; ignored - linear formula &lt;script type=&quot;math/tex&quot;&gt; h \in H &lt;/script&gt; are&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 h(x) = sign((\sum_{i=1}^d w_i x_i) - threshold ) \\
 \ \ \ \ \ \ = sign((\sum_{i=1}^d w_i x_i) + (-threshold) \cdot (+1)) \\
 \ \ \ \ \ \ = sign((\sum_{i=1}^d w_i x_i) + w_0 \cdot x_0 ) \\
 \ \ \ \ \ \ = sign(\sum_{i=0}^d w_i x_i) \\
 \ \ \ \ \ \ = sign(w^T x) 
&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; h(x) = sign(w_0 + w_1x_1 + w_2x_2 + \cdots + w_nx_n) &lt;/script&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;perceptron-learning-algorithm&quot;&gt;Perceptron Learning Algorithm&lt;/h4&gt;
&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt; t = 0, 1, 2, \cdots &lt;/script&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;find a mistake of &lt;script type=&quot;math/tex&quot;&gt; w_t &lt;/script&gt; called &lt;script type=&quot;math/tex&quot;&gt; (x_{n(t)}, y_{n(t)}) &lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; sign(w_{t}^T x_{n(t)}) \neq y_{n(t)}&lt;/script&gt;.&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;(try to) correct the mistake by
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; w_{t+1} \leftarrow w_{t} + y_{n(t)}x_{n(t)} &lt;/script&gt;.&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;until no more mistake
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;return last &lt;script type=&quot;math/tex&quot;&gt; w \ (called \ w_{PLA}) \ as \  g&lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;section&quot;&gt;中文解释&lt;/h4&gt;
&lt;p&gt;在不断的循环中:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果在第t轮的循环中发现&lt;script type=&quot;math/tex&quot;&gt; w_t &lt;/script&gt;对一个点&lt;script type=&quot;math/tex&quot;&gt; (x_{n(t)}, y_{n(t)}) &lt;/script&gt;的判断是错误的，即：&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; sign(w_{t}^T x_{n(t)}) \neq y_{n(t)}&lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;加入这个点&lt;script type=&quot;math/tex&quot;&gt; (x_{n(t)}, y_{n(t)}) &lt;/script&gt;对&lt;script type=&quot;math/tex&quot;&gt; w_t &lt;/script&gt;进行修正，即：&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; w_{t+1} \leftarrow w_{t} + y_{n(t)}x_{n(t)} &lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;直到没有错误点为止，返回结果&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt;g = \ w \ (called \ w_{PLA})&lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;guarantee-of-pla&quot;&gt;Guarantee of PLA&lt;/h4&gt;

&lt;h5 id=&quot;linear-separable--d-leftrightarrow--exists-perfect-wt-such-that-yn--signwtt-xn&quot;&gt;Linear Separable &lt;script type=&quot;math/tex&quot;&gt; D \Leftrightarrow &lt;/script&gt; &lt;strong&gt;exists perfect&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt; such that &lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt;y_n = sign(w_t^T x_n)&lt;/script&gt;&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt; perfect hence every &lt;script type=&quot;math/tex&quot;&gt;x_n&lt;/script&gt; correctly away from line:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; y_{n(t)} w_f^T x_{n(t)} \ge  min \ y_n w_f^T x_n &gt; 0 &lt;/script&gt; by updating with any &lt;script type=&quot;math/tex&quot;&gt; (x_{n(t)}, y_{n(t)}) &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; w_f^T w_{t+1} = w_f^T(w_t + y_{n(t)} x_{n(t)}) \ge w_f^T w_t + min \ y_n w_f^T x_n &gt; w_f^T w_t + 0 &lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;wt-changed-only-when-mistake--wt--dose-not-grow-too-fast&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt; changed only when mistake (&lt;script type=&quot;math/tex&quot;&gt; w_t &lt;/script&gt; Dose Not Grow Too Fast)&lt;/h5&gt;

&lt;h5 id=&quot;section-1&quot;&gt;两个向量内积越大夹角越小(长度不变的情况下)。&lt;/h5&gt;

&lt;h4 id=&quot;non-separable-data&quot;&gt;Non-Separable Data&lt;/h4&gt;

&lt;h5 id=&quot;learning-with-noisy-data&quot;&gt;Learning with &lt;strong&gt;Noisy Data&lt;/strong&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Line with Noise Tolerance
    &lt;ul&gt;
      &lt;li&gt;找出一条犯错误最少的分割线&lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;NP-hard to solve, unfortunately&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;使用贪心算法&lt;strong&gt;pocket&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;保存当前为止最好的分割线&lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt;然后和其它策略想比较，如果更好就更新。&lt;/li&gt;
      &lt;li&gt;不会自动停下来，所以需要设置挺下来的条件。(PLA是会自己停下来的)。&lt;/li&gt;
      &lt;li&gt;效率比PLA要差。(PLA每次找一个点来修正，可是&lt;strong&gt;pocket&lt;/strong&gt;会每次都对比所有的点来确认哪次效果更好)。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>BTree Graph</title>
   <link href="http://zhou-dong.github.io/2015/02/05/b-tree"/>
   <updated>2015-02-05T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/02/05/b-tree</id>
   <content type="html">
&lt;div style=&quot;width:100%&quot;&gt;

&lt;!--
  &lt;img alt=&quot;b-tree&quot; style=&quot;width:100%&quot; src=&quot;http://zhou-dong.github.io/images/b-tree.jpg&quot;/&gt;
--&gt;

  &lt;img alt=&quot;b-tree&quot; style=&quot;width:100%&quot; src=&quot;/images/b-tree.jpg&quot; /&gt;

&lt;div&gt;


&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Analysis of Decision Tree</title>
   <link href="http://zhou-dong.github.io/decision/tree/2015/02/02/decision-tree-analysis"/>
   <updated>2015-02-02T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/decision/tree/2015/02/02/decision-tree-analysis</id>
   <content type="html">
&lt;h4 id=&quot;definition-of-decision-tree-from-wikipedia&quot;&gt;Definition of Decision Tree (From Wikipedia):&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm.&lt;/li&gt;
  &lt;li&gt;Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;sort-preformance&quot;&gt;Sort Preformance:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; n! &lt;/script&gt; ;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;search-performance&quot;&gt;Search Performance:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg n &lt;/script&gt; ;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Elementary Matrix Operations and Elementary Matrix</title>
   <link href="http://zhou-dong.github.io/elementary/matrix/2015/02/01/elementary-matrix-operations"/>
   <updated>2015-02-01T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/elementary/matrix/2015/02/01/elementary-matrix-operations</id>
   <content type="html">
&lt;h4 id=&quot;elementary-matrix-operations-and-systems-of-linear-equations&quot;&gt;Elementary Matrix operations and Systems of Linear Equations&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; A_{m \times n} x_{n \times 1} = b_{m \times 1} &lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;elementary-rowcolumn-operations&quot;&gt;Elementary row(column) operations:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;列（行）交换&lt;/li&gt;
  &lt;li&gt;列（行）乘 - 非0纯量&lt;/li&gt;
  &lt;li&gt;某列（行）非0纯量加到另一列（行）&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;ex&quot;&gt;EX:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

A = \begin{pmatrix} 1 &amp; 3 &amp; 5 \\ 2 &amp; 4 &amp; 6 \end{pmatrix} \\
A_1 = \begin{pmatrix} 2 &amp; 4 &amp; 6 \\ 1 &amp; 3 &amp; 5 \end{pmatrix} \\
A_2 = \begin{pmatrix} -2 &amp; -6 &amp; -10 \\ 2 &amp; 4 &amp; 6 \end{pmatrix}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;elementary-matrix-from-wikipedia&quot;&gt;Elementary matrix (From Wikipedia):&lt;/h4&gt;
&lt;p&gt;In mathematics, an elementary matrix is a matrix which differs from the identity matrix by one single elementary row operation. The elementary matrices generate the general linear group of invertible matrices. Left multiplication (pre-multiplication) by an elementary matrix represents elementary row operations, while right multiplication (post-multiplication) represents elementary column operations. &lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;基本矩阵或者初等矩阵&lt;/h4&gt;
&lt;p&gt;线性代数中，初等矩阵（又称为基本矩阵）是一个与单位矩阵只有微小区别的矩阵。具体来说，一个n阶单位矩阵E经过一次初等行变换或一次初等列变换所得矩阵称为n阶初等矩阵。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;若一矩陣可由單位矩陣經過一次基本列運算而得，則稱此矩陣為基本矩陣。&lt;/li&gt;
  &lt;li&gt;必須進行超過1次基本列運算才能得到的矩陣，就不算是基本矩陣了。&lt;/li&gt;
  &lt;li&gt;它是由&lt;code&gt;單位矩陣&lt;/code&gt;來的，所以必須是個 n*n 的方陣。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;operations&quot;&gt;Operations:&lt;/h4&gt;
&lt;p&gt;初等矩阵分为3种类型，分别对应着3种不同的行/列变换。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;两行（列）互换: (&lt;script type=&quot;math/tex&quot;&gt; R_i \leftrightarrow R_j &lt;/script&gt;)&lt;/li&gt;
  &lt;li&gt;把某行（列）乘以一非零常数: (&lt;script type=&quot;math/tex&quot;&gt; kR_i \rightarrow R_i \ \  k \ne 0 &lt;/script&gt;)&lt;/li&gt;
  &lt;li&gt;把第i行（列）加上第j行（列）的k倍(&lt;script type=&quot;math/tex&quot;&gt; R_i + kR_j = R_i &lt;/script&gt;)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;operation-one-&quot;&gt;Operation One 性质：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;逆矩阵即自身：&lt;script type=&quot;math/tex&quot;&gt; T_{ij}^{-1} = T_{ij} &lt;/script&gt;。&lt;/li&gt;
  &lt;li&gt;因为单位矩阵的行列式为1，故 &lt;script type=&quot;math/tex&quot;&gt; \vert T_{ij}\vert =-1&lt;/script&gt;。与其他相同大小的方阵A亦有一下性质：&lt;script type=&quot;math/tex&quot;&gt; \vert T_{ij}A \vert = - \vert A \vert  &lt;/script&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;operation-two-&quot;&gt;Operation Two 性质：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;逆矩阵为&lt;script type=&quot;math/tex&quot;&gt; T_{i}(m)^{-1} = T_{i}(\frac{1}{m})&lt;/script&gt;。&lt;/li&gt;
  &lt;li&gt;此矩阵及其逆矩阵均为对角矩阵。&lt;/li&gt;
  &lt;li&gt;其行列式&lt;script type=&quot;math/tex&quot;&gt; \vert T_{i}(m) \vert =m&lt;/script&gt;。故对于一等大方阵A有&lt;script type=&quot;math/tex&quot;&gt; \vert T_{i}(m)A \vert =m \vert A \vert&lt;/script&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;operation-three-&quot;&gt;Operation Three 性质：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;逆矩阵具有性质&lt;script type=&quot;math/tex&quot;&gt;T_{ij}(m)^{-1}=T_{ij}(-m)&lt;/script&gt;。&lt;/li&gt;
  &lt;li&gt;此矩阵及其逆矩阵均为三角矩阵。&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \vert T_{ij}(m)\vert=1&lt;/script&gt;。故对于一等大方阵A有：&lt;script type=&quot;math/tex&quot;&gt; \vert T_{ij}(m)A \vert = \vert A \vert &lt;/script&gt;。&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Change of Coordinate Matrix</title>
   <link href="http://zhou-dong.github.io/coordinate/2015/02/01/change-of-coordinate-matrix"/>
   <updated>2015-02-01T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/coordinate/2015/02/01/change-of-coordinate-matrix</id>
   <content type="html">
&lt;h4 id=&quot;section&quot;&gt;个人的理解：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;我自己的理解是，在同一个向量空间中，使用&lt;code&gt;不同的基底&lt;/code&gt;来表示同一个&lt;code&gt;线性函数&lt;/code&gt;或者&lt;code&gt;向量&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;注意，在同一个向量空间中，使用&lt;code&gt;不同的基底&lt;/code&gt;，对函数表达的结果是不一样的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;数学公式表示：&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

 \dbinom{x&#39;}{y&#39;} = \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix} \dbinom{x}{y} \\
 [I]_{\beta}^{\beta&#39;}  = \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix} \\
 x&#39; = x\cos{\theta} + y\sin{\theta} \\
 y&#39; = -x\sin{\theta} + y\cos{\theta}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What is Machine Learning</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/01/31/what-is-machine-learning"/>
   <updated>2015-01-31T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/01/31/what-is-machine-learning</id>
   <content type="html">
&lt;h4 id=&quot;machine-learning-acquiring-skill&quot;&gt;Machine Learning: acquiring skill&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;observations –&amp;gt; learning –&amp;gt; skill&lt;/li&gt;
  &lt;li&gt;date –&amp;gt; ML –&amp;gt; skil&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;skill&quot;&gt;Skill:&lt;/h4&gt;
&lt;p&gt;Improving some performance measure with experience computed from data.&lt;/p&gt;

&lt;h4 id=&quot;use-scenarios&quot;&gt;Use Scenarios:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Can not progam the system manually
    &lt;ul&gt;
      &lt;li&gt;Navigation of Mars&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Human can not define the solution easily
    &lt;ul&gt;
      &lt;li&gt;speech/visual recognition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Need rapid decisions than human can not do
    &lt;ul&gt;
      &lt;li&gt;high-frequency trading&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;need to be user-oriented in massive scale
    &lt;ul&gt;
      &lt;li&gt;consumer-targeted marketing (different consumer use different strategy)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;key-essecnce-of-machine-learning&quot;&gt;Key Essecnce of Machine Learning&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Some &lt;code&gt;underlying pattern&lt;/code&gt; to be learned&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;No&lt;/code&gt; programmable (easy) definition&lt;/li&gt;
  &lt;li&gt;Somehow there is &lt;code&gt;data&lt;/code&gt; about the pattern&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Machine Learning with Other Fields</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/01/31/machine-learning-with-other-fields"/>
   <updated>2015-01-31T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/01/31/machine-learning-with-other-fields</id>
   <content type="html">
&lt;h5 id=&quot;definition-of-machine-learning&quot;&gt;Definition of Machine Learning:&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Use &lt;code&gt;data&lt;/code&gt; to compute &lt;code&gt;hypothesis&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt; that approximates &lt;code&gt;target&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt;\ f&lt;/script&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;relation-with-data-mining&quot;&gt;Relation with Data Mining&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;use &lt;code&gt;huge&lt;/code&gt; data to find property that is interesting.&lt;/li&gt;
  &lt;li&gt;ML = DM (usually what KDD cups does).&lt;/li&gt;
  &lt;li&gt;DM can help ML, and vice versa.&lt;/li&gt;
  &lt;li&gt;Traditional DM also focus on &lt;code&gt;efficent computation in large database&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;relation-with-artifical-intelligence&quot;&gt;Relation with Artifical Intelligence&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;AI: Compute something that show intelligent behavior.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ML can realize AI&lt;/code&gt;, among other routers.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;relation-with-statistics&quot;&gt;Relation With Statistics&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Statistics: use data to make inference about unknown process.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt; is an inference outcome; &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is something unknown.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Statistics can be used to achieve ML&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Traditional statistics also focus on &lt;code&gt;provable results with math assumption&lt;/code&gt;, and care less about &lt;code&gt;computation&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Introduction of ML Course</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/01/31/course-introduction"/>
   <updated>2015-01-31T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/01/31/course-introduction</id>
   <content type="html">
&lt;h4 id=&quot;study-informantion&quot;&gt;Study Informantion:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Begin with Basic knowledge and mixture of:
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;Philosophical illustrations&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;Math calculaton&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Key theory&lt;/li&gt;
      &lt;li&gt;Core techniques&lt;/li&gt;
      &lt;li&gt;Usage in practice&lt;/li&gt;
      &lt;li&gt;Hopefully joke&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Others
    &lt;ul&gt;
      &lt;li&gt;Let students feel the environments of TAI DA&lt;/li&gt;
      &lt;li&gt;Story like (enjoy)&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;Improved with Quiz&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Compontents of Machine Learning</title>
   <link href="http://zhou-dong.github.io/machine-learning/2015/01/31/components-machine-learning"/>
   <updated>2015-01-31T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/machine-learning/2015/01/31/components-machine-learning</id>
   <content type="html">
&lt;h4 id=&quot;basic-notations&quot;&gt;Basic Notations:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;input: &lt;script type=&quot;math/tex&quot;&gt; x \in X&lt;/script&gt; (customer application)&lt;/li&gt;
  &lt;li&gt;output: &lt;script type=&quot;math/tex&quot;&gt; y \in Y&lt;/script&gt; (good/bad after approving credit card)&lt;/li&gt;
  &lt;li&gt;target function: 
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; f: X \rightarrow Y &lt;/script&gt; (&lt;code&gt;ideal&lt;/code&gt; credit approval formula)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;hypothesis: &amp;lt;=&amp;gt; skill with hopefully good performance:
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; g: X \rightarrow Y &lt;/script&gt; (&lt;code&gt;learned&lt;/code&gt; formula to be used)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; \{(x_n,y_n)\} \ \ from \ \ f \rightarrow [ML] \rightarrow g &lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;final-hypothsis--g-approx-f-&quot;&gt;Final hypothsis: &lt;script type=&quot;math/tex&quot;&gt; g \approx f &lt;/script&gt;&lt;/h4&gt;

&lt;h4 id=&quot;definiton&quot;&gt;Definiton:&lt;/h4&gt;
&lt;p&gt;Trainint examples(&lt;code&gt;data&lt;/code&gt;) –&amp;gt; learning algorithm(&lt;code&gt;A&lt;/code&gt;) –&amp;gt; &lt;code&gt;final hypothsis&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt; g \approx f &lt;/script&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>HeapSort Performance</title>
   <link href="http://zhou-dong.github.io/2015/01/29/heapsort-performance"/>
   <updated>2015-01-29T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/01/29/heapsort-performance</id>
   <content type="html">
&lt;h4 id=&quot;steps-of-heapsort&quot;&gt;Steps of HeapSort:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Create a CompleteBinaryTree Meanwhile heapify the tree.&lt;/li&gt;
  &lt;li&gt;Remove the root from the tree.&lt;/li&gt;
  &lt;li&gt;Switch the last leaf to the root.&lt;/li&gt;
  &lt;li&gt;Heapify the tree.&lt;/li&gt;
  &lt;li&gt;Recurisive the steps from 2 to 4 until tree is empty.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;master-theorem&quot;&gt;Master Theorem&lt;/h4&gt;
&lt;p&gt;Let a &lt;script type=&quot;math/tex&quot;&gt; \ge &lt;/script&gt; 1 and b &amp;gt; 1 be constants, let f(n) be a function. &lt;code&gt;T(n) = aT(n/b) + f(n)&lt;/code&gt; ;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = O(n^{\log_{b} a - \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a })&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(n^{\log_{b} a}) &lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a} \lg n) &lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Omega(n^{\log_{b} a + \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, and if &lt;script type=&quot;math/tex&quot;&gt; af(n/b) \le cf(n)&lt;/script&gt; for some constant c &amp;lt; 1 and all sufficiently large n, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(f(n))&lt;/script&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;evaluation-with-master-theorem&quot;&gt;Evaluation with Master Theorem:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Heapify the n elements tree from the laste leaf will cost steps n.&lt;/li&gt;
  &lt;li&gt;EveryTime change the position from leaf to root will cost steps 1.&lt;/li&gt;
  &lt;li&gt;EveryTime Heapify the tree from root to leaf will cost step &lt;script type=&quot;math/tex&quot;&gt; \lg n&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Result: &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n \lg n) &lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>QuickSort Performance</title>
   <link href="http://zhou-dong.github.io/2015/01/28/quicksort-performance"/>
   <updated>2015-01-28T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/01/28/quicksort-performance</id>
   <content type="html">
&lt;h4 id=&quot;description-of-quicksort&quot;&gt;Description of QuickSort:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Find a pivot.&lt;/li&gt;
  &lt;li&gt;Scan the elements of array from the end, and compare each with pivot if it is bigger than pivot stop remember element.&lt;/li&gt;
  &lt;li&gt;Scan the elements of array from the begin, and compare each with pivot if it is smaller than pivot stop and remember element.&lt;/li&gt;
  &lt;li&gt;Switch two elements of step 2 and step 3.&lt;/li&gt;
  &lt;li&gt;keep doing step 2-4 until pivot in the middle, which means all the elements in the left of pivot smaller than pivot and all the elements in the right side of pivot bigger than pivot.&lt;/li&gt;
  &lt;li&gt;Recursive doing the 1-5, until all the number sorted.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;summary&quot;&gt;Summary:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;It is kind of &lt;code&gt;divide and conquer&lt;/code&gt; method.&lt;/li&gt;
  &lt;li&gt;I think it is similar with ShellSort but more effiency.&lt;/li&gt;
  &lt;li&gt;ShellSort every time change two place of elements, so it is better than sort one element by one time.&lt;/li&gt;
  &lt;li&gt;QuickSort every time change two place of elements meanwhile fixed one position of the element, it is brilliant.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;master-theorem&quot;&gt;Master Theorem:&lt;/h4&gt;
&lt;p&gt;Let a &lt;script type=&quot;math/tex&quot;&gt; \ge &lt;/script&gt; 1 and b &amp;gt; 1 be constants, let f(n) be a function. &lt;code&gt;T(n) = aT(n/b) + f(n)&lt;/code&gt; ;  &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = O(n^{\log_{b} a - \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a })&lt;/script&gt;.  &lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(n^{\log_{b} a}) &lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a} \lg n) &lt;/script&gt;.  &lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Omega(n^{\log_{b} a + \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, and if &lt;script type=&quot;math/tex&quot;&gt; af(n/b) \le cf(n)&lt;/script&gt; for some constant c &amp;lt; 1 and all sufficiently large n, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(f(n))&lt;/script&gt;.  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;evaluation-with-master-theorem&quot;&gt;Evaluation with Master Theorem:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The most balance cast: pivot is the middle large of the array&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prove: &lt;script type=&quot;math/tex&quot;&gt;
   T(n) = aT(n/b) + f(n) \\ 
   a = 2 \\
   b = 2 \\
   f(n) = n \\
   T(n) = 2T(n/2) + n \\
   n^{\log_b a} = n^{\log_2 2} = n ^1 = n \\
   f(n) = n^{\log_b a} \\
   T(n) = \Theta(n \log_n)
&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Already sorted cast: pivot is the smallest or biggest of the array&lt;/li&gt;
  &lt;li&gt;Prove: &lt;script type=&quot;math/tex&quot;&gt;
   T(n) = T(n-1) + f(n) \\
   T(n) = O(n^2)
&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;improvement&quot;&gt;Improvement:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Every time choose there elments.&lt;/li&gt;
  &lt;li&gt;Choose middle one to be the pivot.&lt;/li&gt;
  &lt;li&gt;Just can improve, but can not avoid worst cast.&lt;/li&gt;
  &lt;li&gt;Best middle elements, the performance wiill be &lt;script type=&quot;math/tex&quot;&gt; n \lg n &lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;One method: we can random pick the pivot, so in chance, we can avoid the bad case.&lt;/li&gt;
  &lt;li&gt;There are some methods to find the middle, we will be talk later.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Invertible Matrix</title>
   <link href="http://zhou-dong.github.io/identity-matrix/2015/01/28/invertible-matrix"/>
   <updated>2015-01-28T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/identity-matrix/2015/01/28/invertible-matrix</id>
   <content type="html">
&lt;h4 id=&quot;definition&quot;&gt;Definition:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; AB = BA = I_n &lt;/script&gt;  &lt;/p&gt;

&lt;h5 id=&quot;identity-matrix--identity-matrix-is-an-square-matrix-&quot;&gt;Identity Matrix ( Identity Matrix is an Square Matrix ):&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

 I_n = \begin{pmatrix} 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp;  \cdots &amp; 1 \end{pmatrix}_{n \times n} \\
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;properties&quot;&gt;Properties:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 I_mA_{mn} = A_{mn}I_n = A \\
 (T_1 T_2)^{-1} = T_2^{-1} T_1^{-1} \\
 [T^{-1}]_{\gamma}^{\beta} = ([T]_{\gamma}^{\beta})^{-1}
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;such-that-&quot;&gt;Such that :&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 T = I_{V} \\
 U = I_{W} \\
 [UT]_{\beta} = [U]_{\gamma}^{\beta} [T]_{\beta}^{\gamma}
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;总结：&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;只要是维度相同，那么可以看成是同类的矩阵。&lt;/li&gt;
  &lt;li&gt;只有方正才有逆矩阵，但不一定所有的方正都有你矩阵。&lt;/li&gt;
  &lt;li&gt;如果存在逆矩阵，就把这举证叫做可逆矩阵或者非奇异矩阵。&lt;/li&gt;
  &lt;li&gt;两个矩阵相乘的几何意义可以理解为，把一个矩阵的元素表达在另一个矩阵里。&lt;/li&gt;
  &lt;li&gt;个人觉得可逆矩阵可以理解为在两个维度相同的矩阵中，用不同的基底把元素表达出来。&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Matrices</title>
   <link href="http://zhou-dong.github.io/2015/01/27/matrix-mutiply"/>
   <updated>2015-01-27T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/01/27/matrix-mutiply</id>
   <content type="html">
&lt;h4 id=&quot;definition&quot;&gt;Definition:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
  A = (A_{ij})_{mn} \\
  B = (B_{ij})_{np} \\
  AB = C = (C_{ij})_{mp} \\
  C_{ij} = \sum_{k=1}^n A_{ik}B_{kj} \  (A的第i行和B的第j列的内积)  
&lt;/script&gt;  &lt;/p&gt;

&lt;h4 id=&quot;example&quot;&gt;Example:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

 A = \begin{pmatrix} 1 &amp; 3 &amp; 5 \\ 4 &amp; 2 &amp; 7 \end{pmatrix}_{2 \times 3} \\
 B = \begin{pmatrix} 2 &amp; 8 &amp; 7 \\ 3 &amp; 6 &amp; 12 \\ 9 &amp; 4 &amp; 10 \end{pmatrix}_{3 \times 3} \\
 AB = \begin{pmatrix}56 &amp; 46 &amp; 93 \\ 77 &amp; 72 &amp; 122 \end{pmatrix}_{2 \times 3}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;properties-of-the-product-of-the-matrix&quot;&gt;Properties of the product of the Matrix:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
(AB)^t = B^tA^t \\
A(B_1 + B_2) = AB_1 + AB_2 \\
(A_1 + A_2)B = A_1B + A_2B \\
\alpha(AB) = A \alpha B = AB \alpha \\
I_mA_{mn} = A_{mn}I_n = A
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;square-matrix&quot;&gt;Square Matrix:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

I_n = \begin{pmatrix} 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp;  \cdots &amp; 1 \end{pmatrix}_{n \times n}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;matrix-tanspose&quot;&gt;Matrix tanspose:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

A = \begin{pmatrix} 1 &amp; 3 &amp; 5 \\ 4 &amp; 2 &amp; 7 \end{pmatrix}_{2 \times 3} \\
A^t = \begin{pmatrix} 1 &amp; 4 \\ 3 &amp; 2 \\ 5 &amp; 7 \end{pmatrix}_{3 \times 2}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Algorithm Assignment Two</title>
   <link href="http://zhou-dong.github.io/2015/01/23/algorithm-assignment-two"/>
   <updated>2015-01-23T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/01/23/algorithm-assignment-two</id>
   <content type="html">
&lt;h4 id=&quot;master-theorem&quot;&gt;Master Theorem&lt;/h4&gt;

&lt;p&gt;Let a &lt;script type=&quot;math/tex&quot;&gt; \ge &lt;/script&gt; 1 and b &amp;gt; 1 be constants, let f(n) be a function. &lt;code&gt;T(n) = aT(n/b) + f(n)&lt;/code&gt; ;  &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = O(n^{\log_{b} a - \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a })&lt;/script&gt;.  &lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(n^{\log_{b} a}) &lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a} \lg n) &lt;/script&gt;.        &lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Omega(n^{\log_{b} a + \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, and if &lt;script type=&quot;math/tex&quot;&gt; af(n/b) \le cf(n)&lt;/script&gt; for some constant c &amp;lt; 1 and all sufficiently large n, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(f(n))&lt;/script&gt;.    &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;recurrence-examples&quot;&gt;4-1 Recurrence examples&lt;/h4&gt;
&lt;p&gt;Give asymptotic upper and lower bounds for T(n) in each of the following recurrences. Assume that T(n) is constant for n &lt;script type=&quot;math/tex&quot;&gt; \le &lt;/script&gt; 2. Make your bounds as tight as possible, and justify your answers.&lt;/p&gt;

&lt;h5 id=&quot;a--tn----2tn2--n4-&quot;&gt;a. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  2T(n/2) + n^4 &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; a = 2, \ b = 2, \ f(n) = n^4 &lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\log_{b} a} = n^{\log_{2} 2} = n^1 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; f(n) = n^4 = \Omega(n^{\log_{b}a + \epsilon})  = \Omega(n^{1 + 3}) &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \epsilon = 3  &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \therefore \  T(n) = \Theta(n^4) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;b--tn----tn710--n-&quot;&gt;b. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  T(n7/10) + n &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 1, \ b = 10/7, \ f(n) = n &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{10/7} 1} = n^{0} &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^1 = \Omega(n^{\log_{b}a + \epsilon})  = \Omega(n^{0 + 1}) &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \epsilon = 1 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore \  T(n) = \Theta(n) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;c--tn----16tn4--n2-&quot;&gt;c. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  16T(n/4) + n^2 &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 16, \ b = 4, \ f(n) = n^2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{4} 16} = n^2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^2 &lt;/script&gt;  ; &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore T(n) = \Theta(n^2 \lg n) &lt;/script&gt;. &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;d--tn----7tn3--n2-&quot;&gt;d. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  7T(n/3) + n^2 &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 7, \ b = 3, \ f(n) = n^2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{3} 7} = n^{1.772} &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^2 = \Omega(n^{\log_{b}a + \epsilon})  = \Omega(n^{1.772 + 0.228}) &lt;/script&gt; ;   &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \epsilon = 0.228 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore T(n) = \Theta(n^2) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;e--tn----7tn2--n2-&quot;&gt;e. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  7T(n/2) + n^2 &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 7, \ b = 2, \ f(n) = n^2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{2} 7} = n^{2.8074} &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^2 = \Omega(n^{\log_{b}a - \epsilon})  = \Omega(n^{2.8074 - 0.8074}) &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \epsilon = 0.8074 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore T(n) = \Theta(n^{\log_{2} 7}) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;f--tn----2tn4--sqrtn-&quot;&gt;f. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  2T(n/4) + \sqrt{n} &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 2, \ b = 4, \ f(n) = 1/2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{4} 2} = n^{1/2} &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^{1/2} &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore T(n) = \Theta(n^{1/2} \lg n) = \Theta(\sqrt{n} \lg n) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;g--tn----tn-2--n2-&quot;&gt;g. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  T(n-2) + n^2 &lt;/script&gt;&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\ \ \ \ T(n)  =  T(n-2) + n^2  \\
\ \ \ \ \ \ \ \ \ \ \ = T(n-4) + (n-2)^2 + n^2 \\
\ \ \ \ \ \ \ \ \ \ \ = T(n-6) + (n-4)^2 + (n-2)^2 + n^2 \\
\ \ \ \ \ \ \ \ \ \ \ = T(n-2k) + \sum_{i=0}^{2k-1} (n-2i)^2 ; \ \ (k=n/2) \\
\ \ \ \ \ \ \ \ \ \ \ = T(0) + \sum_{i=0}^{n/2-1} (n^2-4ni-4i^2)^2 \\
\ \ \ \ \therefore T(n) = \Theta(n^3)
&lt;/script&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Function Merge</title>
   <link href="http://zhou-dong.github.io/basis/2015/01/20/function-merge"/>
   <updated>2015-01-20T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/basis/2015/01/20/function-merge</id>
   <content type="html">
&lt;h4 id=&quot;ordered-basis&quot;&gt;Ordered Basis&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; \beta &lt;/script&gt; is an &lt;code&gt;ordered basis&lt;/code&gt; for V, which means that: 
&lt;script type=&quot;math/tex&quot;&gt; \beta = \{u_1, u_2, u_3, \cdots , u_n\}  \ne \beta&#39;\{u_2, u_3, u_1, \cdots, u_n\} &lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;example-1&quot;&gt;Example 1:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; 
 V = P_2(R) \\ 
 \beta = \{1,x,x^2\} \\
 \beta&#39; = \{1, x^2,x\} \\
 v = -2 + 3x + x^2 \in P_2(R) \\
 [v]_{\beta} = \begin{pmatrix} -2 \\ 3 \\1 \end{pmatrix} \\
 [v]_{\beta&#39;} = \begin{pmatrix} -2 \\ 1 \\ 3 \end{pmatrix}
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;matrix-repretation&quot;&gt;Matrix Repretation&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 T(v_j) = \sum_{i=1}^m a_{ij}v_i, \ \ j=1, 2, \cdots, n
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;example-2&quot;&gt;Example 2:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; 
  T: \ \ P_2(R) \rightarrow R \ \  and \ \ T(f(x)) = f(2) \\ 
  f(x) = x^2 \\
  T(x) = 4
&lt;/script&gt;  &lt;/p&gt;

&lt;h4 id=&quot;function--function&quot;&gt;Function + Function&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
(U +T)_x = (U)_x + (T)_x \\
U + T = T + U \\
(U + T)(x) = (T + U)(x)
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;function--times---r-&quot;&gt;Function &lt;script type=&quot;math/tex&quot;&gt; \times  \ R &lt;/script&gt;&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
(\alpha T)(x) = \alpha T(x)
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;function-merge&quot;&gt;Function Merge&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Funcitons can not multiply with each other, they can merge.&lt;/strong&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;
 U \circ T = UT
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;definition&quot;&gt;Definition:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 X \rightarrow  T(x) \rightarrow U(T(x))
&lt;/script&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;V&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \rightarrow &lt;/script&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;W&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;  \rightarrow &lt;/script&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Z&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;U&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; x&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(x)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;U(T(x))&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;some-equation&quot;&gt;Some Equation&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
(T_1 + T_2)U = T_1U + T_2U \\
T(U_1 + U_2) = TU_1 + TU_2 \\
(TU_1)U_2 = T(U_1U_2)
&lt;/script&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Algorithm Assignment One</title>
   <link href="http://zhou-dong.github.io/2015/01/20/algorithm-assignment-one"/>
   <updated>2015-01-20T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2015/01/20/algorithm-assignment-one</id>
   <content type="html">
&lt;h4 id=&quot;notations&quot;&gt;Notations:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; O &lt;/script&gt; : Less than (Worst Situation)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; o &lt;/script&gt; : Less or Equal&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \Omega &lt;/script&gt; : Bigger than (Best Situation)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \omega &lt;/script&gt; : Big or Equal &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta &lt;/script&gt; : Between { &lt;script type=&quot;math/tex&quot;&gt; O,\ \ \Omega &lt;/script&gt; }  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- PDF page 77 --&gt;

&lt;h4 id=&quot;definition-from-book-page-56&quot;&gt;Definition from book (page 56):&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg n = \log_{2} n &lt;/script&gt; (binary logarithm) ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\ln n = \log_{e} n &lt;/script&gt; (natural logarithm) ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^k n = (\lg n)^k &lt;/script&gt; (exponentiation) ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg \lg n = \lg(\lg n) &lt;/script&gt; (composition) .  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- PDF page 79 --&gt;

&lt;h4 id=&quot;definition-of---lg-n---from-book-page-58&quot;&gt;Definition of [ &lt;script type=&quot;math/tex&quot;&gt; \lg^* n &lt;/script&gt; ] from book (page 58):&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2 = 1 &lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 4 = 2 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 16 = 3 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 65536 = 4 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{65536} = 5 &lt;/script&gt; .  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Translated from book by me(Dong Zhou)&lt;/strong&gt;:  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^0} = 1 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^1} = 2 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^2} = 3 &lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^4} = 4 &lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^{16}} = 5 &lt;/script&gt; .&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;assignment-zero&quot;&gt;Assignment Zero:&lt;/h4&gt;

&lt;h5 id=&quot;tn--atnb--fn-&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = aT(n/b) + f(n) &lt;/script&gt;&lt;/h5&gt;

&lt;h5 id=&quot;example-&quot;&gt;Example :&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Let:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt; a=2, \ b=2, \ f(n) = 1 &lt;/script&gt;   &lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Step&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Function One&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Equal&lt;/th&gt;
      &lt;th&gt;Functin Two&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 2T(n/2) + 1 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^1T(n/2^1) + 1 &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 4T(n/4) + 1 + 1 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^2T(n/2^2) + 2 &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 8T(n/8) + 1 + 1 + 1 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^3T(n/2^3) + 3 &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = \ \ \ \ \ \ \  \vdots &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \ \ \ \ \ \ \  \vdots &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = nT(n/n) + \log_{2} n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\log_{2}n}T(n/2^{\log_{2}n}) + \log_{2} n &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;step1--step2---cdots---step5-&quot;&gt;Step1 + Step2 + &lt;script type=&quot;math/tex&quot;&gt; \cdots &lt;/script&gt; + Step5 :&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = nT(1)  + \sum_{i=0}^{\log_{2}n} i &lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;assignment-one&quot;&gt;Assignment One:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Indicate, for each pair of expressions(A, B) in the table below, whether A is &lt;script type=&quot;math/tex&quot;&gt; O, o, \Omega, \omega \ or \ \Theta &lt;/script&gt; of B. Assume that &lt;script type=&quot;math/tex&quot;&gt; k \geq 1, \epsilon &gt; 0, and \ c &gt; 1 &lt;/script&gt; are constants. Your answer should be in the form of the table with “yes” or “no” written in each box.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;   &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    A    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    B    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; O &lt;/script&gt;    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; o &lt;/script&gt;    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; \Omega &lt;/script&gt;    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; \omega &lt;/script&gt;    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; \Theta &lt;/script&gt;    &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;a.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^kn &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^\epsilon &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;b.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^k &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; c^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;c.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \sqrt{n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\sin n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;d.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{n/2} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;e.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\lg c} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; c^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;f.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(n!) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(n^n) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;a-compare-between--lgkn--and--nepsilon-&quot;&gt;a. compare between &lt;script type=&quot;math/tex&quot;&gt; \lg^kn &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; n^\epsilon &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{\lg^k n}{n^\epsilon} = \lim_{n \to \infty} \frac{(\lg n)^k}{n^\epsilon} \approx \lim_{n \to \infty} \frac{\ln (\lg n)^k}{\ln n^\epsilon} = \lim_{n \to \infty} \frac{k \ln(\lg n)}{\epsilon\ln n} = \lim_{n \to \infty} (\frac{k}{\epsilon} \cdot \frac{\ln \lg n}{\ln n})  \approx \lim_{n \to \infty} \frac{\ln \lg n}{\ln n} \approx \lim_{n \to \infty} \frac{\lg n}{ n} = 0 &lt;/script&gt; .&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;b-compare-between--nk--and--cn-&quot;&gt;b. compare between &lt;script type=&quot;math/tex&quot;&gt; n^k &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; c^n &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{n^k}{c^n} \approx \lim_{n \to \infty} \frac{\ln n^k}{\ln c^n} = \lim_{n \to \infty} \frac{k\ln n}{n\ln c} =  \lim_{n \to \infty} (\frac{k}{\ln c} \cdot \frac{\ln n}{n}) \approx  \lim_{n \to \infty} \frac{\ln n}{n} = 0 &lt;/script&gt; .  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;c-compare-between--sqrtn--and--nsin-n-&quot;&gt;c. compare between &lt;script type=&quot;math/tex&quot;&gt; \sqrt{n} &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; n^{\sin n} &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sin n &lt;/script&gt; in range [-1, 1]  &lt;/li&gt;
  &lt;li&gt;when &lt;script type=&quot;math/tex&quot;&gt;\sin n = 1, \lim_{n \to \infty} \frac{n}{n^{1/2}} = \lim_{n \to \infty} n^{1/2} = \infty &lt;/script&gt;  ,&lt;/li&gt;
  &lt;li&gt;when &lt;script type=&quot;math/tex&quot;&gt;\sin n = -1, \lim_{n \to \infty} \frac{n^{-1}}{n^{1/2}} = \lim_{n \to \infty} \frac{1}{n^{3/2}} = 0 &lt;/script&gt;  ,&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;d-compare-between--2n--and--2n2-&quot;&gt;d. compare between &lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; 2^{n/2} &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{2^n}{2^{n/2}}  = \lim_{n \to \infty} 2^{n/2} = \infty &lt;/script&gt;  .&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;e-compare-between--nlg-c--adn---clg-n-&quot;&gt;e. compare between &lt;script type=&quot;math/tex&quot;&gt; n^{\lg c} &lt;/script&gt; adn  &lt;script type=&quot;math/tex&quot;&gt; c^{\lg n} &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;assume &lt;script type=&quot;math/tex&quot;&gt; n^{\lg c} = c^{\lg n} &lt;/script&gt; both side lg  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg n^{\lg c}  = \lg c^{\lg n}&lt;/script&gt;  ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;(\lg c)(\lg n) = (\lg n)(\lg c)&lt;/script&gt; ,   &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;f-compare-between--lgn--and--lgnn-&quot;&gt;f. compare between &lt;script type=&quot;math/tex&quot;&gt; \lg(n!) &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; \lg(n^n) &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg n^n = n\lg n&lt;/script&gt; ;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg (n!) = \lg n + \lg (n-1) + \cdots + \lg 1 = \sum_{i=1}^n \lg i &lt;/script&gt; ;
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^n \lg i \le \sum_{i=1}^n \lg n  = n\lg n&lt;/script&gt; ;   &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg (n!) = O(n\lg n) &lt;/script&gt; ;&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^n \lg i \ge \sum_{i=1 + n/2}^n \lg n/2  = (n/2)\lg (n/2) &lt;/script&gt; ;&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg (n!) = \Omega(n\lg n) &lt;/script&gt; ;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;assigement-two&quot;&gt;Assigement Two:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;a. Rank the following functions by order of growth; that is, find an arrangement &lt;script type=&quot;math/tex&quot;&gt; g_1, g_2, \cdots ,g_{30} &lt;/script&gt; of the functions satisfying &lt;script type=&quot;math/tex&quot;&gt; g_1 = \Omega(g_2), g_2 = \Omega(g_3), \cdots , g_{29} = \Omega(g_{30}) &lt;/script&gt;. Partition your list into equivalence classes such that functions &lt;script type=&quot;math/tex&quot;&gt; f(n) &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; g(n) &lt;/script&gt; are in the same class if and only if &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(g(n)) &lt;/script&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(\lg^* n) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;  2^{\lg^* n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (\sqrt{2})^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^2 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n! &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (\lg n)! &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (\frac{3}{2})^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^3 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^2 n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(n!) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{2^n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{1/\lg n}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \ln\ln n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^* n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\lg\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \ln n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (\lg n)^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; e^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 4^{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (n+1)! &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \sqrt{\lg n}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^*(\lg n) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\sqrt{2\lg n}} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n \lg n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{2^{n+1}}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;answer&quot;&gt;Answer:&lt;/h5&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{2^{n+1}} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;  2^{2^n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;  (n+1)! &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n! &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; e^n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; (\frac{3}{2})^n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\lg\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; (\lg n)^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(n!) &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n^3 &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n^2 &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 4^{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n \lg n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; (\lg n)! &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; (\sqrt{2})^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\sqrt{2\lg n}} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^2 n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \ln n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \sqrt{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \ln\ln n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;  2^{\lg^* n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^* n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^* (\lg n) &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(\lg^* n) &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{1/\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;detail&quot;&gt;Detail:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; \lim_{n \to \infty} \frac{(n+1)!}{2^{2^n}} \approx \lim_{n \to \infty} \frac{\lg (n+1)!}{\lg 2^{2^n}} = \lim_{n \to \infty} \frac{(n+1) + n + \cdots + 1}{2^n} = \lim_{n \to \infty} \frac{(n+1)(n+2)}{2^{n-1}} \le \lim_{n \to \infty} \frac{(n+2)^2}{2^{n-1}} \approx \lim_{n \to \infty} \frac{\lg (n+2)^2}{\lg 2^{n-1}} = \lim_{n \to \infty} \frac{2\lg (n+2)}{n-1}&lt;/script&gt; ,&lt;br /&gt;
 &lt;script type=&quot;math/tex&quot;&gt; \approx \lim_{n \to \infty} \frac{\lg (n + 2)}{n-1}  \approx \lim_{n \to \infty} \frac{\lg n}{n} = 0  &lt;/script&gt;  ;    &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; \lim_{n \to \infty} \frac{n2^n}{e^n} \approx  \lim_{n \to \infty} \frac{\ln n2^n}{\ln e^n} = \lim_{n \to \infty} \frac{\ln n + n\ln 2}{n} = \lim_{n \to \infty} (\frac{\ln n}{n} + \ln 2) \approx \lim_{n \to \infty} \frac{\ln n}{n} = 0 &lt;/script&gt; ;  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{(\lg n)^{\lg n}}{(3/2)^n} \approx \lim_{n \to \infty} \frac{\lg n(\lg \lg n)}{n \lg (3/2)} \approx \lim_{n \to \infty} \frac{\lg n(\lg \lg n)}{n} \le \lim_{n \to \infty} \frac{(\lg n)^2}{n} \approx \lim_{n \to \infty} \frac{2\lg \lg n}{\lg n} \approx \lim_{n \to \infty} \frac{\lg \lg n}{\lg n} \approx \lim_{n \to \infty} \frac{\lg n}{n} = 0 &lt;/script&gt;  ; &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\lg \lg n} = (2^{\lg n })^{\lg \lg n} = 2^{\lg n \lg \lg n} = (2^{\lg \lg n})^{\lg n} = (\lg n)^{\lg n}&lt;/script&gt; ;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; \lim_{n \to \infty} \frac{\lg (n!)}{(\lg n)^{\lg n}} \le \lim_{n \to \infty} \frac{\lg n^n}{(\lg n)^{\lg n}} = \lim_{n \to \infty} \frac{n\lg n}{(\lg n)^{\lg n}} \approx \lim_{n \to \infty} \frac{\lg n + \lg \lg n}{\lg n \lg \lg n} = \lim_{n \to \infty} (\frac{1}{\lg \lg n} + \frac{1}{\lg n}) = 0 &lt;/script&gt; ;  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; 4^{\lg n} = (2^2)^{\lg n} = 2^{2\lg n} =  2^{\lg^{n^2}} = n^2 &lt;/script&gt; ;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\sqrt{2/\lg n}} = (2^{\lg n})^{\sqrt{2/\lg n}} = 2^{\lg n \sqrt{2/\lg n}} = 2^{\sqrt{2\lg n}} &lt;/script&gt; ;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; n = 2^{\lg n} &lt;/script&gt; ; &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{\sqrt{\lg n}}{\ln n} \approx \lim_{n \to \infty} \frac{1/2 \ln \lg n}{\ln \ln n} \approx \lim_{n \to \infty} \frac{\ln \lg n}{\ln \ln n} \approx \lim_{n \to \infty} \frac{\lg n}{\ln n} = 0 &lt;/script&gt; ;  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; (\sqrt{2})^{\lg n} = 2^{1/2 \lg n} = (2^{\lg n})^{1/2} = n^{1/2} = \sqrt{n}&lt;/script&gt; ;  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \lg(\lg^*n) = \lim_{n \to \infty} \lg 5&lt;/script&gt; less than 3 ;   &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \lg^* (\lg n) = \lim_{n \to \infty} \lg^* \lg n &lt;/script&gt; could be 4 or 5 ;    &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{1/{\lg n}} = (2^{\lg n})^{1/{\lg n}} = 2^1 = 2 &lt;/script&gt; ;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;b. Give an example of a single nonnegative function &lt;script type=&quot;math/tex&quot;&gt; f(n) &lt;/script&gt; such that for all functions &lt;script type=&quot;math/tex&quot;&gt; g_i(n) &lt;/script&gt; in part &lt;script type=&quot;math/tex&quot;&gt; (a) &lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt; f(n)&lt;/script&gt; is neither &lt;script type=&quot;math/tex&quot;&gt; O(g_i(n))&lt;/script&gt;  nor &lt;script type=&quot;math/tex&quot;&gt; \Omega(g_i(n)) &lt;/script&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;answer-1&quot;&gt;Answer:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Could be bigger than &lt;script type=&quot;math/tex&quot;&gt; 2^{2n+1} &lt;/script&gt; and less than 1&lt;/strong&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; f(n) = 2^{3n+1}(1 + \sin n) &lt;/script&gt; or&lt;/strong&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; f(n) = 2^{2n+3}(1 + \cos n) &lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Basis and Dimension</title>
   <link href="http://zhou-dong.github.io/basis/dimension/2015/01/07/bases-and-dimension"/>
   <updated>2015-01-07T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/basis/dimension/2015/01/07/bases-and-dimension</id>
   <content type="html">
&lt;h4 id=&quot;linearly-dependent&quot;&gt;Linearly dependent&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
a_1v_1 + a_2v_2 + \cdots + a_nv_n = 0 ; \\
\textstyle \sum_{i=1}^n a_iv_i = 0 ;
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;bases-and-dimension&quot;&gt;Bases and dimension&lt;/h4&gt;

&lt;h5 id=&quot;linearly-idependent-example1&quot;&gt;Linearly Idependent Example1:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V= R^2 \\
\beta = \{(1, 0), (0, 1)\} \\
\beta = \{(1, 0), (1, 1)\} \\
dim(v) = 2
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;linearly-idependent-example2&quot;&gt;Linearly Idependent Example2:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

V = M_{2 \times 3}(R) \\
\beta = 
 \begin{Bmatrix}
  \begin{pmatrix}
   1 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0 
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 1 &amp; 0 \\
   0 &amp; 0 &amp; 0
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 0 &amp; 1 \\
   0 &amp; 0 &amp; 0
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 0 &amp; 0 \\
   1 &amp; 0 &amp; 0
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 0 &amp; 0 \\
   0 &amp; 1 &amp; 0
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 1
  \end{pmatrix}
 \end{Bmatrix} \\
dim(v) = 6
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;linearly-independent-example3&quot;&gt;Linearly Independent Example3:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V = \{0\} \\
\beta = \Phi
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;linearly-independent-example4&quot;&gt;Linearly Independent Example4:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_2(R) = V \\
\beta = \{1, x, x^2\} \\
\beta = \{1, x+1, 2x^2\} \\
dim(V) = 3 
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;linearly-dependent-example5&quot;&gt;Linearly &lt;code&gt;Dependent&lt;/code&gt; Example5:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V= R^2 \\
\beta = \{(1, 0), (0, 1),(1,1)\}
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;基底：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;线性独立是基底的必要条件，但不是充分条件。基底中的各个向量一定线性独立。&lt;/li&gt;
  &lt;li&gt;基底是向量空间最具代表性的一些集，这些集合中的元素不多不少：向量空间中的任何元素都可以用基底&lt;code&gt;唯一&lt;/code&gt;的表达出来。&lt;/li&gt;
  &lt;li&gt;一项向量空间可以有不同的基底。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;理解&lt;code&gt;基底&lt;/code&gt;的选择：&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;需要在向量空间中的每个维度，需要一个向量来代表这个维度
    &lt;ul&gt;
      &lt;li&gt;如果有两个向量、或者多个向量、或者向量乘以某个实数以后，之和为0，那么这些个向量为非线性独立。&lt;/li&gt;
      &lt;li&gt;为了保证用基底&lt;code&gt;唯一&lt;/code&gt;的表示一个向量空间中的元素，每个维度只应该有一个向量。&lt;/li&gt;
      &lt;li&gt;线性独立或者非独立是需找某个维度向量的方法。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;线性独立的向量可能没有覆盖向量空间的所有维度，线性独立的向量集合不一定是&lt;code&gt;基底&lt;/code&gt;。
    &lt;ul&gt;
      &lt;li&gt;基底中的各个向量之间都线性独立。&lt;/li&gt;
      &lt;li&gt;线性独立的向量集合不一定是基底。 &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;一个向量空间可以有不同的基底。&lt;/li&gt;
  &lt;li&gt;非线性独立的例子：
    &lt;ul&gt;
      &lt;li&gt;{(1,1),(2,2)}，用这两个向量不能表达二维空间的所有元素。&lt;/li&gt;
      &lt;li&gt;它的性质是：(1,1)*2 - (2,2) = 0 ;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;线性独立的例子：
    &lt;ul&gt;
      &lt;li&gt;{(0,1),(1,0)}，用这两个向量可以表示集合空间中的所元素。&lt;/li&gt;
      &lt;li&gt;它的性质是：(0,1)n + (1,0)m != 0 ;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Gauss Elimination</title>
   <link href="http://zhou-dong.github.io/guass/2015/01/06/linear-combination"/>
   <updated>2015-01-06T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/guass/2015/01/06/linear-combination</id>
   <content type="html">
&lt;h4 id=&quot;subspace&quot;&gt;Subspace&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V = p(F) = \{a_nx^n + \cdots + a_1x^1 + a_0 : n \in N, a_i \in F, i = 0,1 \cdots n \} \\
W = p_n(F) = \{a_nx^n + \cdots + a_0: n-is-fixed , a_i \in F, i=0,1 \cdots n \} \\
W \in V
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-1&quot;&gt;Example 1:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

define: \\
u_1 = (1,2,1) \\
u_2 = (-2,-4,-2) \\
u_3 = (0,2,3) \\ 
u_4 = (2,0,3) \\
u_5 = (-3,8,16) \\
v = (2,6,8) \\
result: \\
x_1u_1 + x_2u_2 + x_3u_3 + x_4u_4 + x_5u_5 = v \\ 
method 1: \\
x_1 - 2x_2 + 0x_3 + 2x_4 - 3x_5 = 2 \\
2x_1 - 4x_2 + 2x_3 + 0x_4 - 8x_5 = 6 \\
x_1 - 2x_2 + 3x_3 + 3x_4 + 16x_5 = 8 \\
method 2: \\
x_1
\begin{pmatrix}
 1 \\
 2 \\
 1
\end{pmatrix}
+ x_2
\begin{pmatrix}
 -2 \\
 -4 \\
 -2
\end{pmatrix}
+ x_3
\begin{pmatrix}
 0 \\
 2 \\
 3
\end{pmatrix}
+ x_4
\begin{pmatrix}
 2 \\
 0 \\
 3
\end{pmatrix}
+ x_5
\begin{pmatrix}
 -3 \\
 8 \\
 16
\end{pmatrix}
= 
\begin{pmatrix}
 2 \\
 6 \\
 8
\end{pmatrix} \\
\left[\begin{array}{rrrrr|r}
1 &amp; -2 &amp; 0 &amp; 2 &amp; -3 &amp; 2 \\
2 &amp; -4 &amp; 2 &amp; 0 &amp; 8 &amp; 6 \\
1 &amp; -2 &amp; 3 &amp; 3 &amp; 16 &amp; 8
\end{array}\right] 
\Rightarrow 
\left[\begin{array}{rrrrr|r}
1 &amp; -2 &amp; 0 &amp; 2 &amp; -3 &amp; 2 \\
0 &amp; 0 &amp; 2 &amp; -4 &amp; 14 &amp; 2 \\
1 &amp; -2 &amp; 3 &amp; 3 &amp; 16 &amp; 8
\end{array}\right] 
\Rightarrow 
\left[\begin{array}{rrrrr|r}
1 &amp; -2 &amp; 0 &amp; 2 &amp; -3 &amp; 2 \\
0 &amp; 0 &amp; 2 &amp; -4 &amp; 14 &amp; 2 \\
0 &amp; 0 &amp; 3 &amp; 1 &amp; 19 &amp; 6
\end{array}\right]
\Rightarrow
\left[\begin{array}{rrrrr|r}
1 &amp; -2 &amp; 0 &amp; 2 &amp; -3 &amp; 2 \\
0 &amp; 0 &amp; 2 &amp; -4 &amp; 14 &amp; 2 \\
0 &amp; 0 &amp; 0 &amp; 7 &amp; -2 &amp; 3
\end{array}\right]
\Rightarrow \\
1). \ 7x_4 - 2x_5 = 3 \\
2). \ 2x_3 - 4x_4 + 14x_5 = 2 \\
3). \ x_1 - 2x_2 + 2x_4 - 3x_5 = 2
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-2&quot;&gt;Example 2:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

u_1 = x^3 -2x^2 - 5x -3 \\
u_2 = 3x^3 - 5x^2 - 4x - 9 \\
v = 2x^3 - 2x^2 + 12x -6 \\
v = 3x^3 - 2x^2 + 7x + 8 \\
result: \\
x_1u_1 + x_2u_2 = v \\
process: \\
\left[\begin{array}{rr|rr}
 1 &amp; 3 &amp; 2 &amp; 3 \\
 -2 &amp; -5 &amp; -2 &amp; -2 \\
 -5 &amp; -4 &amp; 12 &amp; 7 \\
 -3 &amp; -9 &amp; -6 &amp; 8
 \end{array}\right]
\Rightarrow 
\left[\begin{array}{rr|rr}
 1 &amp; 3 &amp; 2 &amp; 3 \\
 0 &amp; 1 &amp; 2 &amp; 4 \\
 0 &amp; 11 &amp; 22 &amp; 22 \\
 0 &amp; 0 &amp; 0 &amp; 17
 \end{array}\right]
\Rightarrow
\left[\begin{array}{rr|rr}
 1 &amp; 3 &amp; 2 &amp; 3 \\
 0 &amp; 1 &amp; 2 &amp; 4 \\
 0 &amp; 0 &amp; 0 &amp; -22 \\
 0 &amp; 0 &amp; 0 &amp; 17
 \end{array}\right]
\Rightarrow \\
1). \ x_2 = 2 \\
2). \ x_1 + 3x_2 = 2
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;the-first-has-sollution-the-second-not&quot;&gt;The first has sollution the second not.&lt;/h4&gt;
</content>
 </entry>
 
 <entry>
   <title>Introduction of Linear Algebra and Vector space</title>
   <link href="http://zhou-dong.github.io/linear-algebra/vector-space/2015/01/04/intro-vector-space"/>
   <updated>2015-01-04T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/linear-algebra/vector-space/2015/01/04/intro-vector-space</id>
   <content type="html">
&lt;h4 id=&quot;definiton-of-linear-algebra&quot;&gt;Definiton of Linear algebra&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Function&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Is Linear Algebra&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(x) = ax &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(x) = ax + b &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(x) = x^2 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(x) = ax^2 + bxy + cy^2 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(\theta) = sin(\theta) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;vector-space&quot;&gt;Vector space&lt;/h4&gt;

&lt;h4 id=&quot;example-1&quot;&gt;Example 1:&lt;/h4&gt;

&lt;h5 id=&quot;definiton-of-two-dimensional-vector&quot;&gt;Definiton of Two dimensional vector:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
a = (x_1, y_1) ;
b = (x_2, y_2) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;plus&quot;&gt;Plus:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
a + b  = (x_1 + x_2, y_1 + y_2) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;mutiply&quot;&gt;Mutiply:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\alpha \cdot a = (\alpha \cdot x_1, \alpha \cdot y_1) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-2&quot;&gt;Example 2:&lt;/h4&gt;

&lt;h5 id=&quot;definition-of-mulit-dimensional-vector&quot;&gt;Definition of Mulit dimensional vector:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V = 
 \begin{Bmatrix}
  \begin{pmatrix}
   a_1 \\
   \vdots \\
   a_n
  \end{pmatrix}  
  a \in R, 1 \ll i \ll n; 
 \end{Bmatrix} ;
a, b \in V;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;plus-1&quot;&gt;Plus:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
a + b = 
 \begin{pmatrix}
  a_1 + b _1 \\
  \vdots \\
  a_n + b_n
 \end{pmatrix}
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;multiply&quot;&gt;Multiply:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\alpha \cdot a = 
 \begin{pmatrix}
  \alpha \cdot a_1 \\
  \vdots \\
  \alpha \cdot a_n
 \end{pmatrix}
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-3&quot;&gt;Example 3:&lt;/h4&gt;

&lt;h5 id=&quot;definiton-of-matrix&quot;&gt;Definiton of Matrix:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V = 
 \begin{Bmatrix}
  \begin{pmatrix}
   a_{11} \cdots a_{1n} \\
   \vdots \ddots \vdots \\
   a_{m1} \cdots a_{mn}
  \end{pmatrix} ;
  a_{ij} \in R; 1 \ll i \ll n; 1 \ll j \ll m; 
 \end{Bmatrix} 
 ; A = (a_{ij}), B = (b_{ij}) \in V ;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;plus-2&quot;&gt;Plus:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
A + B = (a_{ij} + b_{ij}) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;multiply-1&quot;&gt;Multiply:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\alpha \cdot A = (\alpha \cdot a_{ij}) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-4&quot;&gt;Example 4:&lt;/h4&gt;

&lt;h5 id=&quot;definition-of-function-in-a-vector-space&quot;&gt;Definition of Function in a vector space:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
v = {f(f:S--&gt;F)}
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;plus-3&quot;&gt;Plus:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

f + g = h &lt;==&gt; h(x) = f(x) + g(x);
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;mutiply-1&quot;&gt;Mutiply:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\alpha \in F, f \in V;  (\alpha \cdot f)(s) = \alpha \cdot (f(s)); 
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;theme&quot;&gt;Theme:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
-(ax) = (-a)x = a(-x)
&lt;/script&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>I am back</title>
   <link href="http://zhou-dong.github.io/2014/12/25/merry-christmas"/>
   <updated>2014-12-25T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/12/25/merry-christmas</id>
   <content type="html">
&lt;h3 id=&quot;new-life-begin&quot;&gt;New life begin&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;终于到Troy了，感觉突然就回来了！&lt;/li&gt;
  &lt;li&gt;行李终于在意料之中的没有随航班一起来。不过应该马上回到了。&lt;/li&gt;
  &lt;li&gt;刚才一直在收拾从家里寄过来的书，堆了慢慢的一书架，感觉还是挺骄傲的，同时也为那些不能带来注定要扔掉的书感到遗憾。&lt;/li&gt;
  &lt;li&gt;现在好好整理整理心情，开始做读书计划、生活计划、旅游计划、还有各种计划。然后开始好好生活了。&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Stuck in Dallas</title>
   <link href="http://zhou-dong.github.io/2014/12/24/stack-in-dalls"/>
   <updated>2014-12-24T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/12/24/stack-in-dalls</id>
   <content type="html">
&lt;h3 id=&quot;stuck-in-dallas&quot;&gt;Stuck in Dallas&lt;/h3&gt;

&lt;p&gt;第一天来美国，就被困在Dallas机场了。原因是蒙哥马利当地突然下暴雨，所以航班取消了，导致必须在机场里住一个晚上。而且由于第二天去蒙哥马利的所有的航班都已经满员了，所以check in service的工作人员帮我预定了Waiting list or stanking by，所以只有有人取消航班我才能登机。不过还好，已经通知了学校来接的shuttle bus，也通知了其他人来接我。而且行李也确定了会在明天记到蒙哥马利。幸好早来了几天，所以有时间浪费！中间由于着急，还把毕业证书给弄丢了！不过还好最终找回来了！&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;这次最大的收获：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;想的开了，人生总会遇上各种各样的麻烦，静下心来慢慢处理好就好了，而且好事多磨嘛！&lt;/li&gt;
  &lt;li&gt;用英语跟各种人员沟通的时候，完全没有问题，这也给自己增加了不少信心！&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;still-in-dallas&quot;&gt;Still in Dallas&lt;/h3&gt;
&lt;p&gt;结果第二天的航班也取消了，在Dallas呆了超过24小时，不过还好机场安排了住宿和餐饮。而且住宿的地方很棒。也算是赚了！&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>First day in USA</title>
   <link href="http://zhou-dong.github.io/2014/12/23/transfer-chicago"/>
   <updated>2014-12-23T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/12/23/transfer-chicago</id>
   <content type="html">
&lt;h3 id=&quot;first-arrived-usa&quot;&gt;First arrived USA&lt;/h3&gt;

&lt;p&gt;我对气味本来就是个非常敏感的人，当在芝加哥机场乘坐机场大巴转美国国内航班的时候突然闻到了熟悉的美国的味道，以前的感觉瞬间回来了，好像根本没有离开美国一样，特别恍惚，不知道在国内的8年是梦幻、还是在美国的两年是梦幻、还是现在的我是梦幻。不管怎么样，已经踏上了美国的土地，我会好好生活。&lt;/p&gt;

&lt;h3 id=&quot;the-other-things&quot;&gt;The other things&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;这次来美国与第一次来美国的感觉彻底不一样了，发现美国的人也没那么帅了，美国女孩子也不是都比国内女孩子漂亮了，虽然整体上还是要不好不少。&lt;/li&gt;
  &lt;li&gt;在芝加哥转机到达拉斯的候机厅。对面坐着3个中国人，旁边坐着两个。穿着自以为很时尚的衣服，但我觉得LOW极了，看来我真的老了，已经欣赏不了年轻的时尚了。&lt;/li&gt;
  &lt;li&gt;美国的中国人真的很多，芝加哥机场转机的时候，到处能看到中国人。&lt;/li&gt;
  &lt;li&gt;美国各个种族的人都很多，有穆斯林、说着德语的夫妻、说着西班牙语的工作人员，当然还有各种各样的亚洲面孔：中国人，日本人，韩国人、听不懂来自哪里的亚洲人！&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section&quot;&gt;在飞机上的十几个小时，看完了吴军先生的《文明之光》第一册，一如既往的酣畅淋漓，读好的书籍，却是会让人有酣畅淋漓的感觉。&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;第一章给我的感觉就是磅礴大气，酣畅淋漓。从大爆物质的坍塌、恒星的形成、重元素的释放、行星的形成，到地球的形成，月亮的形成，海洋的形成到地球生物的形成。&lt;/li&gt;
  &lt;li&gt;人类的演化，共同的祖先，来自非洲大陆的人类祖先消灭了其它的人类，最终统治了整个地球。&lt;/li&gt;
  &lt;li&gt;古埃及的文明。&lt;/li&gt;
  &lt;li&gt;美索不达米亚平原的文明。&lt;/li&gt;
  &lt;li&gt;东方中国两河流域的文明。&lt;/li&gt;
  &lt;li&gt;古希腊在科学方面的文明。&lt;/li&gt;
  &lt;li&gt;罗马人对世界的贡献。&lt;/li&gt;
  &lt;li&gt;牛逼的瓷器。&lt;/li&gt;
  &lt;li&gt;欧洲的文艺复兴。&lt;/li&gt;
  &lt;li&gt;以对香料的需求引发的大航海时代的来领。&lt;/li&gt;
  &lt;li&gt;对于我这个自诩为还比较懂一些些历史的人，其实只是知道一些历史的点和故事，希望这本书能从对历史的了解联通起来。&lt;/li&gt;
  &lt;li&gt;本来从历史发展的角度和科学对文明的推动的角度去写历史，就是很好的创意。其实也应该是现在知识分子应该思维的方式。&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Shell of Totem Router</title>
   <link href="http://zhou-dong.github.io/2014/12/04/totem-router-shell"/>
   <updated>2014-12-04T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/12/04/totem-router-shell</id>
   <content type="html">
&lt;h4 id=&quot;routersh&quot;&gt;router.sh&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;Bash&quot;&gt;
#!/bin/sh

RUNNING_USER=root
APP_HOME=/workspace/totem
APP_MAINCLASS=org.x.server.router.RouterServer

CLASSPATH=$APP_HOME
for i in &quot;$APP_HOME&quot;/lib/*.jar; do
CLASSPATH=&quot;$CLASSPATH&quot;:&quot;$i&quot;
done

export MALLOC_CHECK_=0

JAVA_OPTS=&quot;-server -Xms8192m -Xmx8192m -Xmn1024m -Djava.awt.headless=true -XX:MaxPermSize=128m&quot;

psid=0

checkpid()
{
javaps=`$JAVA_HOME/bin/jps -l | grep $APP_MAINCLASS`
if [ -n &quot;$javaps&quot; ]; then
psid=`echo $javaps | awk &#39;{print $1}&#39;`
else
psid=0
fi
echo &quot;psid=$psid&quot;
}


start()
{
checkpid
if [ $psid -ne 0 ]; then
echo &quot;================================&quot;
echo &quot;warn: $APP_MAINCLASS already started! (pid=$psid)&quot;
echo &quot;================================&quot;
else
echo -n &quot;Starting $APP_MAINCLASS ...&quot;
JAVA_CMD=&quot;nohup java $JAVA_OPTS -classpath $CLASSPATH $APP_MAINCLASS &amp;gt; /app/logs/router.log 2&amp;gt;&amp;amp;1 &amp;lt;/dev/null &amp;amp;&quot;
su -c &quot;$JAVA_CMD&quot;
checkpid
if [ $psid -ne 0 ]; then
echo &quot;(pid=$psid) [OK]&quot;
else
echo &quot;[Failed]&quot;
fi
fi
}

stop()
{
checkpid
if [ $psid -ne 0 ]; then
echo -n &quot;Stopping $APP_MAINCLASS ...(pid=$psid) &quot;
kill -9 $psid
if [ $? -eq 0 ]; then
echo &quot;[OK]&quot;
else
echo &quot;[Failed]&quot;
fi
checkpid
if [ $psid -ne 0 ]; then
stop
fi
else
echo &quot;================================&quot;
echo &quot;warn: $APP_MAINCLASS is not running&quot;
echo &quot;================================&quot;
fi
echo &quot;===remove bigqueue&quot;
rm -rf /server/bigqueue/logs/indexlogs/*

}

status()
{
checkpid
if [ $psid -ne 0 ];  then
echo &quot;$APP_MAINCLASS is running! (pid=$psid)&quot;
else
echo &quot;$APP_MAINCLASS is not running&quot;
fi
}

info()
{
echo &quot;System Information:&quot;
echo &quot;****************************&quot;
echo `head -n 1 /etc/issue`
echo `uname -a`
echo
echo &quot;JAVA_HOME=$JAVA_HOME&quot;
echo `$JAVA_HOME/bin/java -version`
echo
echo &quot;APP_HOME=$APP_HOME&quot;
echo &quot;APP_MAINCLASS=$APP_MAINCLASS&quot;
echo &quot;****************************&quot;
}

case &quot;$1&quot; in
&#39;start&#39;)
start
;;
&#39;stop&#39;)
stop
;;
&#39;restart&#39;)
stop
start
;;
&#39;status&#39;)
status
;;
&#39;info&#39;)
info
;;
*)
echo &quot;Usage: $0 {start|stop|restart|status|info}&quot;
exit 1
esac
exit 0

&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Shell of Totem Appserver</title>
   <link href="http://zhou-dong.github.io/2014/12/04/totem-appserver-shell"/>
   <updated>2014-12-04T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/12/04/totem-appserver-shell</id>
   <content type="html">
&lt;h4 id=&quot;appserversh&quot;&gt;appserver.sh&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;Bash&quot;&gt;
#!/bin/sh

UNNING_USER=root
APP_HOME=/workspace/totem
APP_MAINCLASS=org.x.server.app.AppServer

CLASSPATH=$APP_HOME
for i in &quot;$APP_HOME&quot;/lib/*.jar; do
CLASSPATH=&quot;$CLASSPATH&quot;:&quot;$i&quot;
done

export MALLOC_CHECK_=0

if [ `free -g |grep Mem |awk &#39;{print $2}&#39;` -ge  70 ]
   then 
     JAVA_OPTS=&quot;-server -Xms65536m -Xmx65536m -Xmn2048m -Djava.awt.headless=true -XX:MaxPermSize=256m&quot;
   else
     JAVA_OPTS=&quot;-server -Xms24576m -Xmx24576m -Xmn2048m -Djava.awt.headless=true -XX:MaxPermSize=256m&quot;
fi

psid=0

checkpid()
{
javaps=`$JAVA_HOME/bin/jps -l | grep $APP_MAINCLASS`
if [ -n &quot;$javaps&quot; ]; then
psid=`echo $javaps | awk &#39;{print $1}&#39;`
else
psid=0
fi
echo &quot;psid=$psid&quot;
}


start()
{
checkpid
if [ $psid -ne 0 ]; then
echo &quot;================================&quot;
echo &quot;warn: $APP_MAINCLASS already started! (pid=$psid)&quot;
echo &quot;================================&quot;
else
echo -n &quot;Starting $APP_MAINCLASS ...&quot;
JAVA_CMD=&quot;nohup java $JAVA_OPTS -classpath $CLASSPATH $APP_MAINCLASS &amp;gt; /app/logs/appserver.log 2&amp;gt;&amp;amp;1 &amp;lt;/dev/null &amp;amp;&quot;
su -c &quot;$JAVA_CMD&quot;
checkpid
if [ $psid -ne 0 ]; then
echo &quot;(pid=$psid) [OK]&quot;
else
echo &quot;[Failed]&quot;
fi
fi
}

stop()
{
checkpid
if [ $psid -ne 0 ]; then
echo -n &quot;Stopping $APP_MAINCLASS ...(pid=$psid) &quot;
kill -9 $psid
if [ $? -eq 0 ]; then
echo &quot;[OK]&quot;
else
echo &quot;[Failed]&quot;
fi
checkpid
if [ $psid -ne 0 ]; then
stop
fi
else
echo &quot;================================&quot;
echo &quot;warn: $APP_MAINCLASS is not running&quot;
echo &quot;================================&quot;
fi
echo &quot;===remove index lock tlog bigqueue&quot;
rm -f /server/solr/product/data/index/*.lock
rm -rf /server/bigqueue/logs/ModuleQueue/*
rm -rf /server/bigqueue/logs/schedule/*
rm -rf /server/bigqueue/logs/searchlogs/*
}

status()
{
checkpid
if [ $psid -ne 0 ];  then
echo &quot;$APP_MAINCLASS is running! (pid=$psid)&quot;
else
echo &quot;$APP_MAINCLASS is not running&quot;
fi
}

info()
{
echo &quot;System Information:&quot;
echo &quot;****************************&quot;
echo `head -n 1 /etc/issue`
echo `uname -a`
echo
echo &quot;JAVA_HOME=$JAVA_HOME&quot;
echo `$JAVA_HOME/bin/java -version`
echo
echo &quot;APP_HOME=$APP_HOME&quot;
echo &quot;APP_MAINCLASS=$APP_MAINCLASS&quot;
echo &quot;****************************&quot;
}

case &quot;$1&quot; in
&#39;start&#39;)
start
;;
&#39;stop&#39;)
stop
;;
&#39;restart&#39;)
stop
start
;;
&#39;status&#39;)
status
;;
&#39;info&#39;)
info
;;
*)
echo &quot;Usage: $0 {start|stop|restart|status|info}&quot;
exit 1
esac
exit 0
&lt;/code&gt;&lt;/pre&gt;

</content>
 </entry>
 
 <entry>
   <title>Shell of Totem Beanstalk</title>
   <link href="http://zhou-dong.github.io/2014/12/04/beanstalk-shell"/>
   <updated>2014-12-04T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/12/04/beanstalk-shell</id>
   <content type="html">
&lt;h4 id=&quot;startsh&quot;&gt;start.sh&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;Bash&quot;&gt;
#!/bin/sh

LOG_DIR=/app/logs/beanstalk
PID=`ps aux |grep beanstalkd |grep -v grep |awk &#39;{print $2}&#39;`

start()
{
	PID=`ps aux |grep beanstalkd |grep -v grep |awk &#39;{print $2}&#39;`

	if [ -n &quot;$PID&quot; ];
		then 
			echo &quot;.....address already in use......&quot;
			exit
	fi


	if [ -d /app/logs/beanstalk ];
  		then
			echo &quot;begin to start...&quot;
	  	else 
			echo &quot;begin to make log file and start...&quot;
			mkdir -p /app/logs/beanstalk
	fi 

	nohup ./beanstalkd -z 52428800 -l 0.0.0.0 -p 11300  -V &amp;gt;$LOG_DIR/start.log 2&amp;gt;&amp;amp;1 &amp;lt;/dev/null &amp;amp;

	echo &quot;beanstalkd is running...&quot;
}

stop()
{

        if [ -n &quot;$PID&quot; ];
                then
                        echo &quot;stop ...&quot;
			kill -9 $PID
        fi	
}

info()
{
	echo `tail -n 2 $LOG_DIR/start.log`
	exit
}

case &quot;$1&quot; in
	&#39;start&#39;)
		start
		;;
	&#39;stop&#39;)
		stop
		;;
	&#39;restart&#39;)
		stop
		start
		;;
	&#39;info&#39;)
		info
		;;
	*)
		echo &quot;pls type $0 {start|stop|restart|info}&quot;

	exit 1
esac

&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Machine Learning</title>
   <link href="http://zhou-dong.github.io/2014/12/02/machinel-learning"/>
   <updated>2014-12-02T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/12/02/machinel-learning</id>
   <content type="html">
&lt;p&gt;&lt;a href=&quot;http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial&quot;&gt;UFLDL&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ufldl.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B&quot;&gt;UFLDL教程&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning&quot;&gt;Machine Learning - Andrew Ng&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.holehouse.org/mlclass/index.html&quot;&gt;Stanford Machine Learning&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.zhihu.com/question/20691338&quot;&gt;机器学习该怎么入门&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;上海交通大学-开发课程&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>网站技术点</title>
   <link href="http://zhou-dong.github.io/2014/11/30/web-technology"/>
   <updated>2014-11-30T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/11/30/web-technology</id>
   <content type="html">
&lt;h4 id=&quot;dns&quot;&gt;DNS供应商&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;www.godaddy.com&lt;/li&gt;
  &lt;li&gt;www.name.com&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cdn&quot;&gt;CDN服务商&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;蓝汛、网宿、Webluker、帝联、阿里云、安全宝、加速乐、快网、17CDN&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section&quot;&gt;负载均衡&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;LVS&lt;/li&gt;
  &lt;li&gt;NGIX&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;静态文件代理/缓存&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Squid&lt;/li&gt;
  &lt;li&gt;Varnish&lt;/li&gt;
  &lt;li&gt;Ngix&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-2&quot;&gt;前端&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Bootstrap&lt;/li&gt;
  &lt;li&gt;AngularJS&lt;/li&gt;
  &lt;li&gt;Jquery&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-3&quot;&gt;后端&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Express.js&lt;/li&gt;
  &lt;li&gt;Node.js&lt;/li&gt;
  &lt;li&gt;Tomcat + apr&lt;/li&gt;
  &lt;li&gt;Appserver&lt;/li&gt;
  &lt;li&gt;Ruby on Rails&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-4&quot;&gt;消息中间件&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ZeroMQ&lt;/li&gt;
  &lt;li&gt;RocketMQ&lt;/li&gt;
  &lt;li&gt;Netty&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.rabbitmq.com/&quot;&gt;RabbitMQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://activemq.apache.org/&quot;&gt;ActiveMQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/twitter/kestrel&quot;&gt;twitter/jestrel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-5&quot;&gt;存储系统&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;程序内存储
    &lt;ul&gt;
      &lt;li&gt;Ehcache&lt;/li&gt;
      &lt;li&gt;LRU&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/bulldog2011/bigqueue.git&quot;&gt;Bigqueue&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;传统关系型数据库
    &lt;ul&gt;
      &lt;li&gt;Mqsql&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;嵌入式数据库
    &lt;ul&gt;
      &lt;li&gt;LevelDB（LSM）&lt;/li&gt;
      &lt;li&gt;RocketsDB (基于LevelDB内核做二次开发)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分布式数据库
    &lt;ul&gt;
      &lt;li&gt;MongoDB&lt;/li&gt;
      &lt;li&gt;CouchDB&lt;/li&gt;
      &lt;li&gt;Hbase&lt;/li&gt;
      &lt;li&gt;OceanBase&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;内存数据库
    &lt;ul&gt;
      &lt;li&gt;Redis&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分布式图片存储
    &lt;ul&gt;
      &lt;li&gt;TFS&lt;/li&gt;
      &lt;li&gt;FASTDFS&lt;/li&gt;
      &lt;li&gt;MOGILEFS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-6&quot;&gt;搜索产品&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Solr&lt;/li&gt;
  &lt;li&gt;Elasticsearch&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-7&quot;&gt;分布式任务控制&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Zookeeper&lt;/li&gt;
  &lt;li&gt;Dubbo&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-8&quot;&gt;公共产品开发&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;分布式session共享
    &lt;ul&gt;
      &lt;li&gt;Redis&lt;/li&gt;
      &lt;li&gt;Jetty&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分布式Scheduler
    &lt;ul&gt;
      &lt;li&gt;quartz + LevelDB/MongoDB + Zookeeper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-9&quot;&gt;数据收集和分析&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Flume + Log4J&lt;/li&gt;
  &lt;li&gt;Hadoop&lt;/li&gt;
  &lt;li&gt;Spark&lt;/li&gt;
  &lt;li&gt;Strom&lt;/li&gt;
  &lt;li&gt;Mahout&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-10&quot;&gt;爬虫系统&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;防屏蔽
    &lt;ul&gt;
      &lt;li&gt;动态ADSL切换(家庭网络)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;程序开发
    &lt;ul&gt;
      &lt;li&gt;PhantomJs + Node.js&lt;/li&gt;
      &lt;li&gt;Webkit C++ 内核&lt;/li&gt;
      &lt;li&gt;Java Httputil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-11&quot;&gt;系统运维和监控&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Cacti&lt;/li&gt;
  &lt;li&gt;Zabbix&lt;/li&gt;
  &lt;li&gt;Ganglia&lt;/li&gt;
  &lt;li&gt;Zookeepr监控&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-12&quot;&gt;服务器虚拟化&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Docker&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-13&quot;&gt;操作系统&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;服务器操作系统
    &lt;ul&gt;
      &lt;li&gt;CentOS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;开发操作系统
    &lt;ul&gt;
      &lt;li&gt;Macbook&lt;/li&gt;
      &lt;li&gt;Fedora&lt;/li&gt;
      &lt;li&gt;Ubuntu&lt;/li&gt;
      &lt;li&gt;openSUSE&lt;/li&gt;
      &lt;li&gt;Debian&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;vps&quot;&gt;VPS提供商&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;AWS&lt;/li&gt;
  &lt;li&gt;阿里云&lt;/li&gt;
  &lt;li&gt;linode(linux node)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-14&quot;&gt;自然语言处理&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;CRFPP&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.nltk.org/&quot;&gt;NLTK&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-15&quot;&gt;版本控制&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Git + GitHub&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-16&quot;&gt;博客&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Gitpages + Jekyll + markdown&lt;/li&gt;
  &lt;li&gt;Ruby&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-17&quot;&gt;开发语言&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Java&lt;/li&gt;
  &lt;li&gt;Javscript&lt;/li&gt;
  &lt;li&gt;Python&lt;/li&gt;
  &lt;li&gt;C++&lt;/li&gt;
  &lt;li&gt;C Language&lt;/li&gt;
  &lt;li&gt;Ruby&lt;/li&gt;
  &lt;li&gt;R&lt;/li&gt;
  &lt;li&gt;Scala&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>English Vocabulary Thinking</title>
   <link href="http://zhou-dong.github.io/2014/11/30/english-vocabulary"/>
   <updated>2014-11-30T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/11/30/english-vocabulary</id>
   <content type="html">
&lt;h4 id=&quot;section&quot;&gt;不只是长篇的文学作品，&lt;code&gt;文字&lt;/code&gt;或者&lt;code&gt;单词&lt;/code&gt;才是一个名族文化的浓缩和核心。如：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Odyssey：漫长而艰苦的旅程。来自于：特洛伊战争后，奥迪赛和他的小伙伴们经历种种困难终于回到家乡的故事。&lt;/li&gt;
  &lt;li&gt;exodus ：大批的离去。 来自于：圣经故事中的出埃及记。&lt;/li&gt;
  &lt;li&gt;narcissus：水仙花。源于希腊神话中一个叫Narcissus的青年，他因眷恋自己在水中的形象而死去，死后变成了花，人们称之为水仙花。&lt;/li&gt;
  &lt;li&gt;narcissism：自恋，自我陶醉。自恋的Narcissus。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;英语单词就像汉字一样，也是有边旁部首的，只不过英语中叫做&lt;code&gt;词根&lt;/code&gt;、&lt;code&gt;前缀&lt;/code&gt;、&lt;code&gt;后缀&lt;/code&gt;。&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;orthodox：正统的人或事。 ortho：right；dox：opinion。&lt;/li&gt;
  &lt;li&gt;heterodox：异端的、非正统的。hetero：不同的；dox：opinion。&lt;/li&gt;
  &lt;li&gt;paradox：悖论。para：高于、反面；dox：opinion。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-2&quot;&gt;与跟汉字一样，造词和读音是两个系统。&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;metabolism：新陈代谢。读音：[mɪ’tæbəlɪz(ə)m]；造词：mata[改变] + bolism。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-3&quot;&gt;目的：&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;从理论上明确单词的组成。&lt;/li&gt;
  &lt;li&gt;让自己背单词的过程不那么的枯燥。&lt;/li&gt;
  &lt;li&gt;总结自己的收获。&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Study List</title>
   <link href="http://zhou-dong.github.io/2014/11/28/study-list"/>
   <updated>2014-11-28T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/11/28/study-list</id>
   <content type="html">
&lt;h3 id=&quot;program-language&quot;&gt;Program Language&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;C&lt;/li&gt;
  &lt;li&gt;C++&lt;/li&gt;
  &lt;li&gt;Java&lt;/li&gt;
  &lt;li&gt;Python&lt;/li&gt;
  &lt;li&gt;Node.js&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;english-study&quot;&gt;English Study&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;TOEFL&lt;/li&gt;
  &lt;li&gt;GRE&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;master-course&quot;&gt;Master Course&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Natural Language Process&lt;/li&gt;
  &lt;li&gt;Machine Learning&lt;/li&gt;
  &lt;li&gt;Deep Learning&lt;/li&gt;
  &lt;li&gt;Neural Networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tools&quot;&gt;Tools&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Fedora&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other&quot;&gt;Other&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;School Transfer&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;american-life&quot;&gt;American Life&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Credit card apply&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;basic-course&quot;&gt;Basic Course&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;高等数学-上&lt;/li&gt;
  &lt;li&gt;高等数学-下&lt;/li&gt;
  &lt;li&gt;概率论与数理统计&lt;/li&gt;
  &lt;li&gt;算法&lt;/li&gt;
  &lt;li&gt;矩阵计算&lt;/li&gt;
  &lt;li&gt;离散数学&lt;/li&gt;
  &lt;li&gt;信息论&lt;/li&gt;
  &lt;li&gt;凸优化	&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Books</title>
   <link href="http://zhou-dong.github.io/2014/11/27/book-list"/>
   <updated>2014-11-27T00:00:00-06:00</updated>
   <id>http://zhou-dong.github.io/2014/11/27/book-list</id>
   <content type="html">
&lt;ol&gt;
  &lt;li&gt;鸟哥的Linux私房菜服务器架设篇（第二版）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;牧羊少年奇幻之旅&lt;/strong&gt; &lt;/li&gt;
  &lt;li&gt;小王子&lt;/li&gt;
  &lt;li&gt;精通CSS：高级Web标准解决方案（第2版）&lt;/li&gt;
  &lt;li&gt;Java编程思想（第4版）&lt;/li&gt;
  &lt;li&gt;操作系统：精髓与设计原理（原书第6版）&lt;/li&gt;
  &lt;li&gt;人月神话（32周年中文纪念版）&lt;/li&gt;
  &lt;li&gt;编译原理（第2版）&lt;/li&gt;
  &lt;li&gt;程序员修炼之道——从小工到专家&lt;/li&gt;
  &lt;li&gt;代码大全&lt;/li&gt;
  &lt;li&gt;设计模式 可复用面向对象软件的基础&lt;/li&gt;
  &lt;li&gt;计算机程序的构造和解释：原书第2版&lt;/li&gt;
  &lt;li&gt;追风筝的人&lt;/li&gt;
  &lt;li&gt;算法导论(原书第2版)&lt;/li&gt;
  &lt;li&gt;魔术的耳语&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;大卫的伤疤&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;浪潮之巅&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;美国种族简史&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;世界上的另一个你&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lucene实战(第2版)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;这个历史挺靠谱·全三册&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;数学之美&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;如丧——我们终于老得可以谈谈未来&lt;/li&gt;
  &lt;li&gt;百年孤独&lt;/li&gt;
  &lt;li&gt;美国怎么了：一个自由主义者的良知&lt;/li&gt;
  &lt;li&gt;《虎妈战歌》&lt;/li&gt;
  &lt;li&gt;孤独天使&lt;/li&gt;
  &lt;li&gt;傲慢与偏见-Pride and Prejudice（典藏英文原版）&lt;/li&gt;
  &lt;li&gt;生猛的进化心理学&lt;/li&gt;
  &lt;li&gt;带着鲑鱼去旅行&lt;/li&gt;
  &lt;li&gt;宇宙简史—霍金系列讲座精华&lt;/li&gt;
  &lt;li&gt;李敖快意恩仇录&lt;/li&gt;
  &lt;li&gt;霍乱时期的爱情&lt;/li&gt;
  &lt;li&gt;算法竞赛入门经典&lt;/li&gt;
  &lt;li&gt;自控力&lt;/li&gt;
  &lt;li&gt;走进搜索引擎（第2版）&lt;/li&gt;
  &lt;li&gt;拖延心理学&lt;/li&gt;
  &lt;li&gt;编程之美&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;这就是搜索引擎&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;暗时间&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;禅与摩托车维修艺术&lt;/li&gt;
  &lt;li&gt;Hadoop实战&lt;/li&gt;
  &lt;li&gt;Hadoop权威指南&lt;/li&gt;
  &lt;li&gt;MongoDB 权威指南&lt;/li&gt;
  &lt;li&gt;畅游英国&lt;/li&gt;
  &lt;li&gt;不减20斤就别说你瘦了&lt;/li&gt;
  &lt;li&gt;世界通史（彩图）&lt;/li&gt;
  &lt;li&gt;1988——我想和这个世界谈谈&lt;/li&gt;
  &lt;li&gt;人类群星闪耀时&lt;/li&gt;
  &lt;li&gt;《朝圣》&lt;/li&gt;
  &lt;li&gt;牛奶可乐经济学（完整版）&lt;/li&gt;
  &lt;li&gt;不能承受的生命之轻（百万纪念版）&lt;/li&gt;
  &lt;li&gt;算法竞赛入门经典&lt;/li&gt;
  &lt;li&gt;编程珠玑（第2版）&lt;/li&gt;
  &lt;li&gt;正能量&lt;/li&gt;
  &lt;li&gt;史蒂夫·乔布斯传 精装版&lt;/li&gt;
  &lt;li&gt;上帝掷骰子吗？&lt;/li&gt;
  &lt;li&gt;淘宝技术这十年&lt;/li&gt;
  &lt;li&gt;1984.动物庄园&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;三体3：死神永生&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;三体2：黑暗森林&lt;/li&gt;
  &lt;li&gt;三体1：地球往事&lt;/li&gt;
  &lt;li&gt;信息检索导论&lt;/li&gt;
  &lt;li&gt;搜索引擎技术基础&lt;/li&gt;
  &lt;li&gt;Head First 设计模式（中文版）&lt;/li&gt;
  &lt;li&gt;时间简史（插图本）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;构建高性能Web站点&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Effective Java中文版(第2版)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;挪威的森林（村上春树经典著作）&lt;/li&gt;
  &lt;li&gt;把你的英语用起来&lt;/li&gt;
  &lt;li&gt;数据挖掘导论(完整版)&lt;/li&gt;
  &lt;li&gt;机器学习（决战大数据时代！IT技术人员不得不读！）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;历史深处的忧虑：近距离看美国之一&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;总统是靠不住的：近距离看美国之二&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;我也有一个梦想：近距离看美国之三&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;如彗星划过夜空：近距离看美国之四&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;算法（第4版）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Java并发编程实战&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;像自由一样美丽&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;西班牙旅行笔记&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;一路走来一路读&lt;/li&gt;
  &lt;li&gt;离散数学&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Effective Java中文版(第2版)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;从一到无穷大&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;扫起落叶好过冬(林达著)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;黑客与画家&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;重来（更为简单有效的商业思维 ）&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;物理世界奇遇记(中译本）&lt;/li&gt;
  &lt;li&gt;啊哈，灵机一动&lt;/li&gt;
  &lt;li&gt;银河帝国&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;深入浅出Node.js&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;大话处理器&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;七周七语言&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;JavaScript高级程序设计&lt;/li&gt;
  &lt;li&gt;GRE词汇精选&lt;/li&gt;
  &lt;li&gt;深入理解计算机系统&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;重构：改善既有代码的设计&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;TCP/IP 详解(卷1:协议)&lt;/li&gt;
  &lt;li&gt;巴西：未来之国&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;汇编语言(第3版）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;深入理解Java虚拟机&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;推荐系统实践&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;社交网站的数据挖掘与分析&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;信息简史&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;计算机程序设计艺术 卷4A&lt;/li&gt;
  &lt;li&gt;敏捷软件开发——原则、模式与实践&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;维罗妮卡决定去死&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;少女布莱达灵修之旅&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;魔鬼与普里姆小姐&lt;/li&gt;
  &lt;li&gt;波多贝罗的女巫&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;大型网站技术架构&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;大规模分布式存储系统&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;机器学习实战&lt;/li&gt;
  &lt;li&gt;统计自然语言处理&lt;/li&gt;
  &lt;li&gt;啊哈C！思考快你一步&lt;/li&gt;
  &lt;li&gt;统计学习方法&lt;/li&gt;
  &lt;li&gt;大数据日知录：架构与算法&lt;/li&gt;
  &lt;li&gt;大型网站系统与Java中间件实践&lt;/li&gt;
  &lt;li&gt;编程珠玑：续&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;把信送给加西亚&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;万物简史&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;《大设计》&lt;/li&gt;
  &lt;li&gt;量子宇宙&lt;/li&gt;
  &lt;li&gt;啊哈！算法&lt;/li&gt;
  &lt;li&gt;我的简史&lt;/li&gt;
  &lt;li&gt;少有人走的路&lt;/li&gt;
  &lt;li&gt;如何阅读一本书&lt;/li&gt;
  &lt;li&gt;模式识别（第四版）&lt;/li&gt;
  &lt;li&gt;概率论与数理统计习题全解指南 浙大第四版&lt;/li&gt;
  &lt;li&gt;线性代数(原书第7版)&lt;/li&gt;
  &lt;li&gt;高效程序员的45个习惯：敏捷开发修炼之道&lt;/li&gt;
  &lt;li&gt;高等数学 同济第六版(上册)&lt;/li&gt;
  &lt;li&gt;高等数学 同济第六版（下册）&lt;/li&gt;
  &lt;li&gt;数据挖掘导论(完整版)&lt;/li&gt;
  &lt;li&gt;概率论与数理统计 浙大第四版（新版）&lt;/li&gt;
  &lt;li&gt;C++ Primer中文版（第5版）&lt;/li&gt;
  &lt;li&gt;More Effective C++&lt;/li&gt;
  &lt;li&gt;Effective C++&lt;/li&gt;
  &lt;li&gt;Web 前端黑客技术揭秘&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;深入浅出统计学&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;从你的全世界路过：让所有人心动的故事(电子书)&lt;/li&gt;
  &lt;li&gt;向前一步(电子书)&lt;/li&gt;
  &lt;li&gt;全球最美的地方精华特辑.走遍美国(电子书)&lt;/li&gt;
  &lt;li&gt;卡耐基当众演讲的艺术(电子书)&lt;/li&gt;
  &lt;li&gt;你一定爱读的极简欧洲史(电子书) &lt;/li&gt;
  &lt;li&gt;UNIX编程艺术&lt;/li&gt;
  &lt;li&gt;英语阅读参考手册&lt;/li&gt;
  &lt;li&gt;深入浅出数据分析&lt;/li&gt;
  &lt;li&gt;谁说菜鸟不会数据分析&lt;/li&gt;
  &lt;li&gt;果壳中的宇宙·霍金（插图本） &lt;/li&gt;
  &lt;li&gt;文明之光 1-2 套装全2册 &lt;/li&gt;
  &lt;li&gt;线性代数及其应用（原书第3版） &lt;/li&gt;
  &lt;li&gt;Vim实用技巧 &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;信息简史&lt;/strong&gt; &lt;/li&gt;
  &lt;li&gt;MacTalk 人生元编程 &lt;/li&gt;
  &lt;li&gt;Mahout实战 &lt;/li&gt;
  &lt;li&gt;程序员的数学 &lt;/li&gt;
  &lt;li&gt;CPU自制入门 &lt;/li&gt;
  &lt;li&gt;Aha!Gotcha啊哈!原来如此&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;代码整洁之道&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Head First Python（中文版）&lt;/li&gt;
  &lt;li&gt;鸟哥的Linux私房菜 基础学习篇(第三版)&lt;/li&gt;
  &lt;li&gt;此生未完成：一个母亲、妻子、女儿的生命日记&lt;/li&gt;
  &lt;li&gt;白鹿原&lt;/li&gt;
  &lt;li&gt;看见&lt;/li&gt;
  &lt;li&gt;重口味心理学&lt;/li&gt;
  &lt;li&gt;偷影子的人&lt;/li&gt;
  &lt;li&gt;沃顿商学院最受欢迎的谈判课&lt;/li&gt;
  &lt;li&gt;天才在左疯子在右 &lt;/li&gt;
  &lt;li&gt;矩阵分析与应用（第2版）&lt;/li&gt;
  &lt;li&gt;人工智能智能系统指南(原书第2版)&lt;/li&gt;
  &lt;li&gt;挑战程序设计竞赛 （第2版）&lt;/li&gt;
  &lt;li&gt;硅谷百年史——伟大的科技创新与创业历程(1900-2013)&lt;/li&gt;
  &lt;li&gt;数学女孩&lt;/li&gt;
  &lt;li&gt;神似祖先&lt;/li&gt;
  &lt;li&gt;GRE数学高分快速突破&lt;/li&gt;
  &lt;li&gt;大话数据结构&lt;/li&gt;
  &lt;li&gt;大话设计模式&lt;/li&gt;
  &lt;li&gt;挑战编程：程序设计竞赛训练手册&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;信息论基础（原书第2版）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;人工智能（英文版）&lt;/li&gt;
  &lt;li&gt;数据结构与算法分析Java语言描述 第2版&lt;/li&gt;
  &lt;li&gt;阿莱夫&lt;/li&gt;
  &lt;li&gt;带一本书去巴黎&lt;/li&gt;
  &lt;li&gt;历史在你我身边&lt;/li&gt;
  &lt;li&gt;哥德尔、艾舍尔、巴赫：集异璧之大成&lt;/li&gt;
  &lt;li&gt;代码的未来&lt;/li&gt;
  &lt;li&gt;凸优化&lt;/li&gt;
  &lt;li&gt;C++ Primer Plus(第6版)中文版&lt;/li&gt;
  &lt;li&gt;机器学习：实用案例解析&lt;/li&gt;
  &lt;li&gt;具体数学&lt;/li&gt;
  &lt;li&gt;文明之光（三）&lt;/li&gt;
  &lt;li&gt;数学之美（第二版）&lt;/li&gt;
  &lt;li&gt;你不可不知道50个数学知识&lt;/li&gt;
  &lt;li&gt;算法帝国&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 
</feed>
