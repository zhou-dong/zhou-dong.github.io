---
layout: page
title: K-Means
tagline: Unsupervise and Clustering Algorithm
categories: machine-learning

---

Input:

- K (number of clusters)
- Training set {$$x^{(1)},x^{(2)},...,x^{(m)} $$}

$$x^{(i)} \in R^n$$ (drop $$x_0 = 1$$ convention)

Step:

- Randomly initialize K cluster centroid $$\mu_1, \mu_2, ..., \mu_k \in R^n $$
- Repeat
    + for i=1 to m $$c^{(i)} := $$ index (from 1 to K) of cluster centroid closest to $$x_{(i)}, \text{which means find: } \min_k \|x^{(i)}-\mu_k\|$$
    + for k=1 to K $$\mu_k := $$ average (mean) of points assigned to cluster k

Optimization objective:

$$
J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_k) = \frac{1}{m} \sum_{i=1}^m \| x^{(i)}-\mu_{c^{(i)}}\|^2 \\
\min_{c^{(1)},...,c^{(m)},\mu_1,...,\mu_k} = J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_k)
$$

Choosing the Number of Clusters:

- Choosing more numbers of clusters could reduce local Optimization
- Use "Elbow method" to find the K which is the numbers of clusters

Elbow method

- K值越大，各个点到centroid的距离之和越小
- 当随着K值的增加，距离之和下降的不明显的话，就没有必要再增加K值了
