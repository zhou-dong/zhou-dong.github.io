---
layout: page
title: Notes of Maching Learning
categories: machine-learning
---

1. Linear Regression
  - Gradient Descent
  - Normal Equation

2. Logstic Regression
6. 在计算logistic Regression的cost function的时候，需要使用极大似然

7. Regularzation

参数越小，cursive就越平滑
software: octave

为了梯度下降的效率更高，可以按比例的归一化数据
logstic regression是分类算法，而不是回归算法。
mohammed.alsafi313@gmail.com

Aug 25, 2015

1. 神经网络
    - 分层次逐渐求解
2. 神经网络的应用


神经网路：

1. 逐层的求解
2. 计算出cost function，是训练最优值，
    - 可以使用逻辑回归、
    - 梯度下降
3. 使用back propagation，来计算梯度的值
4. 最常用的神经网络是三层神经网络：
    1. 输入层
    2. 隐含层
    3. 输出层
5. 如果有多个“隐含层”，那各个隐含层的变量数目相同。

- Support Vector machine
- Nerual Networks
- K-Means
- DIMENSIONALITY REDUCTION
    - Principal Component Analysis(PCA)

- recommendation system
    - content base recommendation system
    - collaborative filtering

- Online Learning
- Map reduce

- Photo OCR
- Pipline in machine learning

- finish the course

---

255 - 256

13.14

A and B


- CPI (cycle per instruction)
- MIPS (millions of instructions per second)
- Throughput
- artifical data synthesis
